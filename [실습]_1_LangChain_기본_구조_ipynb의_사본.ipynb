{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a435919b",
      "metadata": {
        "id": "a435919b"
      },
      "source": [
        "# [실습] LangChain 기본 구조\n",
        "\n",
        "\n",
        "LangChain을 활용하여 파이썬 프로그램 내에서 LLM을 활용해 보겠습니다.   \n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zRMq7KwVC4Ws",
      "metadata": {
        "id": "zRMq7KwVC4Ws"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d593fea",
      "metadata": {
        "id": "3d593fea"
      },
      "source": [
        "## 라이브러리 설치  \n",
        "`langchain_openai`, `langchain_google_genai` 등의 라이브러리를 이용해 provider별 모델을 활용합니다.     \n",
        "`langchain_huggingface`를 통해 오픈 모델을 연동할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf68e6c0",
      "metadata": {
        "collapsed": true,
        "id": "bf68e6c0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community openai langchain_openai rich"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bdf221f",
      "metadata": {
        "id": "3bdf221f"
      },
      "source": [
        "## API 키 설정   \n",
        "OpenAI의 GPT 모델을 사용하기 위해, API 키를 환경 변수에 등록합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wChFFR3NAUu6",
      "metadata": {
        "id": "wChFFR3NAUu6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13da3542",
      "metadata": {
        "id": "13da3542"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b4252b",
      "metadata": {
        "id": "b3b4252b"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36b0c4ab",
      "metadata": {
        "id": "36b0c4ab"
      },
      "source": [
        "LLM은 `ChatOpenAI`, `ChatGoogleGenerativeAI`와 같은 클래스로 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89b1573c",
      "metadata": {
        "id": "89b1573c"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model = 'gpt-4.1-mini',\n",
        "\n",
        "#                  # 최대 출력 토큰 수\n",
        "#                  max_tokens = 4096,\n",
        "\n",
        "#                  # 디코딩 파라미터(샘플링 확률 조절)\n",
        "\n",
        "#                  temperature = 0.6,\n",
        "#                  # 0~2 사이의 값, 낮을수록 높은 확률의 토큰 위주 출력\n",
        "#                  top_p = 0.9,\n",
        "#                  # 누적 확률 기준 0.9 내 토큰만 선택\n",
        "#                  # top_k = 20\n",
        "#                  # 확률 기준 상위 20개 토큰만 선택 (OpenAI에서는 미적용)\n",
        "\n",
        "#                  )\n",
        "\n",
        "llm  = ChatOpenAI(model='gpt-5-mini',\n",
        "                  max_tokens=8192,\n",
        "                  # Thinking 시간 설정('low','medium','high')\n",
        "                  reasoning_effort='low'\n",
        "                  )\n",
        "# GPT-5는 디코딩 파라미터 설정이 제한적"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58c80c88",
      "metadata": {
        "id": "58c80c88"
      },
      "outputs": [],
      "source": [
        "from rich import print as rprint\n",
        "# 구조체는 rich를 통해 출력\n",
        "\n",
        "rprint(llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dead1f5",
      "metadata": {
        "id": "2dead1f5"
      },
      "source": [
        "## Prompt\n",
        "\n",
        "LLM에 입력할 프롬프트는 다음의 방법으로 전달됩니다.\n",
        "\n",
        "1. 단순 문자열\n",
        "2. 랭체인 메시지 클래스\n",
        "3. 프롬프트 템플릿과 입력 변수\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "977ce129",
      "metadata": {
        "id": "977ce129"
      },
      "source": [
        "### 1. 단순 문자열   \n",
        "\n",
        "LLM은 `invoke()`를 통해 실행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d97eb36",
      "metadata": {
        "id": "7d97eb36"
      },
      "outputs": [],
      "source": [
        "question = '''\n",
        "# Instructions\n",
        "최신 정보를 바탕으로 답변하세요.\n",
        "현재 시장에 출시되었거나 학계에 발표된 LLM들 중에서, 기술적 완성도, 적용 범위의 광범위성, 그리고 혁신적인 기여도 측면에서 \"가장 발전된\"이라고 불릴 만한 모델들은 무엇입니까?\n",
        "200자 정도의 결과물을 작성하세요.\n",
        "\n",
        "# Output Format\n",
        "다음 사항을 포함하여, 후보 모델들에 대해 짧게 개조식으로 작성하세요:\n",
        "1.  해당 LLM의 이름과 출시 시기, 개발 주체\n",
        "2.  주요 기술적 특징 (예: 아키텍처, 학습 방식, 파라미터 규모 등)\n",
        "3.  다른 모델들과 비교했을 때 두드러지는 강점 또는 차별점\n",
        "4.  어떤 근거(예: 공개된 벤치마크 결과, 논문, 실제 적용 사례 등)로 그렇게 판단하는지 설명\n",
        "5.  해당 모델이 앞으로 어떤 영향을 미칠 것으로 예상되는지에 대한 간략한 전망\n",
        "'''\n",
        "\n",
        "response = llm.invoke(question)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faab851c",
      "metadata": {
        "id": "faab851c"
      },
      "source": [
        "출력 형식은 AIMessage 클래스입니다.   \n",
        "반대로, 입력 문자열은 HumanMessage 클래스로 변환되어 전달됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0e052a4",
      "metadata": {
        "id": "b0e052a4"
      },
      "outputs": [],
      "source": [
        "rprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feec1222",
      "metadata": {
        "id": "feec1222"
      },
      "source": [
        "메타데이터를 통해 토큰 사용량도 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055a3eb7",
      "metadata": {
        "id": "055a3eb7"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72da0409",
      "metadata": {
        "id": "72da0409"
      },
      "source": [
        "스트리밍을 통해 출력할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d567c92",
      "metadata": {
        "id": "1d567c92"
      },
      "outputs": [],
      "source": [
        "for chunk in llm.stream(question):\n",
        "    print(chunk.content, end='')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca0134c",
      "metadata": {
        "id": "9ca0134c"
      },
      "source": [
        "batch를 통해 여러 개의 입력을 병렬적으로 처리할 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5ca284d",
      "metadata": {
        "id": "d5ca284d"
      },
      "outputs": [],
      "source": [
        "topics = ['LLM이 무엇의 약자인가요? 20단어 이내로 답변하세요.',\n",
        "          'LLM이랑 GPT랑 다른 건가요? 20단어 이내로 답변하세요.',\n",
        "          'BERT와 GPT는 뭐가 다른가요? 20단어 이내로 답변하세요.']\n",
        "results = llm.batch(topics)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff71b2d4",
      "metadata": {
        "id": "ff71b2d4"
      },
      "source": [
        "reasoning 모델은 답변을 생성하기 전,   \n",
        "생각(Thinking) 토큰을 먼저 생성하여 답변을 준비합니다.   \n",
        "논리적 사고가 필요한 수학, 코딩 등의 문제에서 높은 성능을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dd2040a",
      "metadata": {
        "id": "9dd2040a"
      },
      "outputs": [],
      "source": [
        "# 생각 과정 출력은 현재 제한된 공개\n",
        "reasoning = {\n",
        "    \"effort\": \"low\",  # 'low', 'medium', 'high'\n",
        "    \"summary\": \"detailed\",  # 'detailed', 'auto', None\n",
        "}\n",
        "\n",
        "reasoning_llm = ChatOpenAI(model = 'gpt-5-mini',\n",
        "                           max_tokens = 4096,\n",
        "\n",
        "                           # reasoning_effort='low', # 'low', 'medium', 'high'\n",
        "                           # 생각 과정 출력은 현재 제한된 공개\n",
        "                           model_kwargs={\"reasoning\": reasoning}\n",
        "                           )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e809e875",
      "metadata": {
        "id": "e809e875"
      },
      "outputs": [],
      "source": [
        "response = reasoning_llm.invoke(question)\n",
        "rprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1248f0f8",
      "metadata": {
        "id": "1248f0f8"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1e560fe",
      "metadata": {
        "id": "c1e560fe"
      },
      "source": [
        "search-preview 모델은 검색 기능이 탑재된 모델입니다.   \n",
        "해당 모델은 항상 웹 검색을 먼저 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da254d98",
      "metadata": {
        "id": "da254d98"
      },
      "outputs": [],
      "source": [
        "question = '''\n",
        "# Instructions\n",
        "2025년 10월 기준의 최신 정보를 바탕으로 답변하세요.\n",
        "현재 시장에 출시되었거나 학계에 발표된 LLM들 중에서, 기술적 완성도, 적용 범위의 광범위성, 그리고 혁신적인 기여도 측면에서 \"가장 발전된\"이라고 불릴 만한 모델들은 무엇입니까?\n",
        "400자 정도의 결과물을 작성하세요.\n",
        "출처 링크를 명시하세요.\n",
        "\n",
        "# Output Format\n",
        "다음 사항을 포함하여, 후보 모델들에 대해 짧게 개조식으로 작성하세요:\n",
        "1.  해당 LLM의 이름과 출시 시기, 개발 주체\n",
        "2.  주요 기술적 특징 (예: 아키텍처, 학습 방식, 파라미터 규모 등)\n",
        "3.  다른 모델들과 비교했을 때 두드러지는 강점 또는 차별점\n",
        "4.  어떤 근거(예: 공개된 벤치마크 결과, 논문, 실제 적용 사례 등)로 그렇게 판단하는지 설명\n",
        "5.  해당 모델이 앞으로 어떤 영향을 미칠 것으로 예상되는지에 대한 간략한 전망\n",
        "'''\n",
        "\n",
        "search_llm = ChatOpenAI(model = 'gpt-4o-search-preview', max_tokens = 4096)\n",
        "\n",
        "response = search_llm.invoke(question)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "039fc0bd",
      "metadata": {
        "id": "039fc0bd"
      },
      "outputs": [],
      "source": [
        "rprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83fffebd",
      "metadata": {
        "id": "83fffebd"
      },
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0752e51c",
      "metadata": {
        "id": "0752e51c"
      },
      "source": [
        "Human Message 이외에도, 많은 LLM은 챗봇의 작동 방식을 결정하는 System Message를 지원합니다.\n",
        "\n",
        "System Message는 보통 전체 대화의 첫 번째로 들어갑니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf2afb4",
      "metadata": {
        "id": "bbf2afb4"
      },
      "source": [
        "### 2. Message 클래스 전달하기   \n",
        "클래스를 직접 생성하고 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e8a6a13",
      "metadata": {
        "id": "5e8a6a13"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "messages = [\n",
        "    # SystemMessage('당신은 매우 논리적이고, 다양한 관점을 고려합니다.'),\n",
        "    SystemMessage('당신은 답변을 세 문장으로만 합니다.'),\n",
        "    HumanMessage('LLM이 인간을 대체할 수 있을까?')\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce27c430",
      "metadata": {
        "id": "ce27c430"
      },
      "source": [
        "AIMessage를 함께 전달하는 방식으로, 멀티-턴 대화를 수행할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4RJrL5dZiktm",
      "metadata": {
        "id": "4RJrL5dZiktm"
      },
      "outputs": [],
      "source": [
        "messages.append(response)\n",
        "messages.append(HumanMessage('완전히 대체하는 건 언제가 될까?'))\n",
        "# System, Human, AI, Human\n",
        "\n",
        "response2 = llm.invoke(messages)\n",
        "response2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "775dd0f5",
      "metadata": {
        "id": "775dd0f5"
      },
      "source": [
        "### 3. Prompt Template\n",
        "\n",
        "프롬프트 템플릿을 사용하면, 정해진 템플릿에 입력 변수의 공간을 설정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2585b0a2",
      "metadata": {
        "id": "2585b0a2"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22354ac0",
      "metadata": {
        "id": "22354ac0",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "explain_prompt = PromptTemplate(template = \"\"\"LLM과 {subject}의 공통점을 5문장으로 설명하세요.\"\"\")\n",
        "prompt = explain_prompt.format(subject = \"트랜스포머 네트워크\")\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ef1d3c",
      "metadata": {
        "id": "e7ef1d3c"
      },
      "outputs": [],
      "source": [
        "response = llm.invoke(prompt)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57a650ca",
      "metadata": {
        "id": "57a650ca"
      },
      "source": [
        "입력 변수가 여러 개일 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a2bc2a2",
      "metadata": {
        "id": "1a2bc2a2"
      },
      "outputs": [],
      "source": [
        "explain_template = \"{topic}에 대해 {style}로 설명하세요.\"\n",
        "explain_prompt2 = PromptTemplate(template = explain_template)\n",
        "\n",
        "prompt = explain_prompt2.format(topic='LLM의 미래', style='부정적인 전망으')\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5448adc8",
      "metadata": {
        "id": "5448adc8"
      },
      "outputs": [],
      "source": [
        "llm.invoke(prompt).content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e28d4ed",
      "metadata": {
        "id": "4e28d4ed"
      },
      "source": [
        "System, AI 등의 메시지를 포함하기 위해서는 ChatPromptTemplate를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yA82Zgf9ssZ7",
      "metadata": {
        "id": "yA82Zgf9ssZ7"
      },
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate([\n",
        "    (\"system\", '당신은 항상 이모지로만 대답합니다.'),\n",
        "    (\"user\", '{topic}에 대해 설명해주세요.')\n",
        "    # 역할은 4개 (user = human), (ai = assistant)\n",
        "]\n",
        ")\n",
        "prompt = chat_prompt.format_messages(topic='랭체인')\n",
        "prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcd27ac1",
      "metadata": {
        "id": "fcd27ac1"
      },
      "outputs": [],
      "source": [
        "llm.invoke(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cbe4374",
      "metadata": {
        "id": "8cbe4374"
      },
      "source": [
        "Few-Shot Prompt Template은 프롬프트에 예시를 추가할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1e86b21",
      "metadata": {
        "id": "c1e86b21"
      },
      "outputs": [],
      "source": [
        "# 예시 : Prompt Example 2개\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    # input_variables=[\"question\", \"answer\"],\n",
        "    template=\"질문: {question}\\n답변: {answer}\"\n",
        ")\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"question\": \"고객 불만을 어떻게 처리해야 하나요?\",\n",
        "        \"answer\": \"1) 경청하기 2) 공감 표현 3) 해결책 제시 4) 후속 조치\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"회의를 효율적으로 진행하려면?\",\n",
        "        \"answer\": \"1) 명확한 안건 설정 2) 시간 관리 3) 참여 유도 4) 결론 정리\"\n",
        "    }\n",
        "]\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"다음 예시를 참고해서 답변해주세요:\",\n",
        "    suffix=\"질문: {input}\\n답변:\",\n",
        ")\n",
        "\n",
        "\n",
        "print(few_shot_prompt.format(input=\"휴가 신청은 어떻게 해야 하나요?\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22fb94a6",
      "metadata": {
        "id": "22fb94a6"
      },
      "outputs": [],
      "source": [
        "question = \"휴가 신청은 어떻게 해야 하나요?\"\n",
        "X = few_shot_prompt.format(input=question)\n",
        "print(llm.invoke(X).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b220f79a",
      "metadata": {
        "id": "b220f79a"
      },
      "source": [
        "Chat Message에 Few Shot을 적용하는 경우, 아래와 같이 나타납니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2aa2e0e",
      "metadata": {
        "id": "c2aa2e0e"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
        "\n",
        "example_prompt = ChatPromptTemplate(\n",
        "        [\n",
        "        (\"human\", \"{question}\"),\n",
        "        (\"ai\", \"{answer}\"),\n",
        "    ]\n",
        ")\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "few_shot_prompt.format_messages()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94960365",
      "metadata": {
        "id": "94960365"
      },
      "outputs": [],
      "source": [
        "final_prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        (\"system\", \"다음 예시를 참고하여 같은 형식으로 답변하세요.\"),\n",
        "        few_shot_prompt,\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "final_prompt.format_messages(input=\"휴가 신청은 어떻게 해야 하나요?\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "702650d9",
      "metadata": {
        "id": "702650d9"
      },
      "source": [
        "### 멀티모달 프롬프트 전달하기\n",
        "\n",
        "멀티모달 모델은 이미지의 URL이나 실제 파일을 프롬프트에 전달할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b784ced1",
      "metadata": {
        "id": "b784ced1"
      },
      "outputs": [],
      "source": [
        "# 예제 이미지: 타임테이블\n",
        "\n",
        "import base64\n",
        "import httpx\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "image_url = \"https://cloud.google.com/static/vertex-ai/generative-ai/docs/multimodal/images/timetable.png\"\n",
        "\n",
        "response = httpx.get(image_url)\n",
        "image_data = base64.b64encode(response.content).decode(\"utf-8\")\n",
        "\n",
        "with open('timetable.png', 'wb') as file:\n",
        "    file.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b290c877",
      "metadata": {
        "id": "b290c877"
      },
      "source": [
        "이미지 URL을 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68b81a6",
      "metadata": {
        "id": "c68b81a6"
      },
      "outputs": [],
      "source": [
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"이 그림에 대해 설명해주세요.\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": image_url},\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "ai_msg = llm.invoke([message])\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14675cb0",
      "metadata": {
        "id": "14675cb0"
      },
      "source": [
        "오프라인 파일은 조금 복잡한 포맷으로 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a04d584",
      "metadata": {
        "id": "5a04d584"
      },
      "outputs": [],
      "source": [
        "with open('./timetable.png', 'rb') as image_file:\n",
        "    image_data = base64.b64encode(image_file.read()).decode('utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2605ede",
      "metadata": {
        "id": "d2605ede"
      },
      "outputs": [],
      "source": [
        "# 멀티모달 모델의 프롬프팅은 조금 더 구체적이어야 합니다.\n",
        "\n",
        "message = HumanMessage(\n",
        "    content=[\n",
        "        {\"type\": \"text\", \"text\": \"이 그림에 적힌 장소와 시간을 모두 찾아서 표 형태로 출력하세요. 총 몇 개입니까?\"},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_data}\"},\n",
        "        },\n",
        "    ]\n",
        ")\n",
        "\n",
        "ai_msg = llm.invoke([message])\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ffc4b86",
      "metadata": {
        "id": "9ffc4b86"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
