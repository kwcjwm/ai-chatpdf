{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kwcjwm/ai-chatpdf/blob/main/%5B%EC%8B%A4%EC%8A%B5%5D_2_LangChain%EC%9D%84_%EC%9D%B4%EC%9A%A9%ED%95%9C_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EB%A5%98%EC%99%80_%EC%A0%84%EC%B2%98%EB%A6%AC_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a435919b",
      "metadata": {
        "id": "a435919b"
      },
      "source": [
        "# [ì‹¤ìŠµ] LangChainì„ ì´ìš©í•œ ë°ì´í„° ë¶„ë¥˜ì™€ ì „ì²˜ë¦¬\n",
        "\n",
        "LangChain Expression Language(LCEL)ëŠ” ë­ì²´ì¸ì—ì„œ ì²´ì¸ì„ êµ¬ì„±í•˜ëŠ” ë¬¸ë²•ì…ë‹ˆë‹¤.    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "230aadd4",
      "metadata": {
        "id": "230aadd4"
      },
      "source": [
        "## ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜  \n",
        "\n",
        "ë­ì²´ì¸ OpenAIì™€ Google ëª¨ë“ˆì„ ì„¤ì¹˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf68e6c0",
      "metadata": {
        "id": "bf68e6c0",
        "scrolled": true,
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd91ecae-61c2-4452-a9cc-55d57aa76fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-3.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Collecting dotenv\n",
            "  Downloading dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
            "Collecting arxiv\n",
            "  Downloading arxiv-2.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.79)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.35)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.44)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.26.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_google_genai-2.1.11-py3-none-any.whl.metadata (6.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.10-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.8-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_google_genai-2.1.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from dotenv) (1.1.1)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
            "Downloading arxiv-2.2.0-py3-none-any.whl (11 kB)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=bc7dd75d20a8310f04835b74dca70ffea9574bd5c74b49bb23700517d86a9158\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, filetype, requests, pymupdf, mypy-extensions, marshmallow, feedparser, dotenv, typing-inspect, arxiv, dataclasses-json, langchain_openai, langchain_google_genai, langchain_community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed arxiv-2.2.0 dataclasses-json-0.6.7 dotenv-0.9.9 feedparser-6.0.12 filetype-1.2.0 langchain_community-0.3.31 langchain_google_genai-2.0.10 langchain_openai-0.3.35 marshmallow-3.26.1 mypy-extensions-1.1.0 pymupdf-1.26.5 requests-2.32.5 sgmllib3k-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community google-generativeai langchain_google_genai langchain_openai openai dotenv arxiv pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "A59cI3UHz9l2",
      "metadata": {
        "id": "A59cI3UHz9l2"
      },
      "source": [
        "## Gemini APIì™€ dotenv ì¤€ë¹„í•˜ê¸°\n",
        "\n",
        "\n",
        "Google API í‚¤ë¥¼ ë“±ë¡í•˜ê³  ì…ë ¥í•©ë‹ˆë‹¤.   \n",
        "êµ¬ê¸€ ê³„ì • ë¡œê·¸ì¸ í›„ `https://aistudio.google.com`  ì— ì ‘ì†í•˜ë©´, API í‚¤ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.   \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### [ì‹¤ìŠµ] dotenv ì‚¬ìš©í•˜ê¸°\n",
        "\n",
        "ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ì—, íŒŒì´ì¬ ì½”ë“œì— API í‚¤ë¥¼ ì§ì ‘ ë„£ëŠ” ê²ƒì€ ë³´ì•ˆ ë“±ì˜ ìœ„í—˜ì´ í½ë‹ˆë‹¤.   \n",
        "ì´ì— ë”°ë¼, ì™¸ë¶€ íŒŒì¼ì— í‚¤ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¤ëŠ” `dotenv` ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.   \n",
        "\n",
        "ì½”ë©ì—ì„œ ì„ì˜ì˜ íŒŒì¼ì„ ìƒì„±í•˜ì—¬, 'env'ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì €ì¥í•˜ê³    \n",
        "`GOOGLE_API_KEY=\"API í‚¤\"`   \n",
        "`OPENAI_API_KEY=\"API í‚¤\"`\n",
        "\n",
        "ë¥¼ ì €ì¥í•˜ì„¸ìš”.   \n",
        "ì´í›„ ì•„ë˜ í‚¤ë¥¼ ì‹¤í–‰í•´ Trueê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13da3542",
      "metadata": {
        "id": "13da3542",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7e930b-2bf7-4cd7-8b8f-6edfb5b1b04f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API í‚¤ í™•ì¸\n",
            "Google API í‚¤ í™•ì¸\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('env', override=True)\n",
        "# 'env'íŒŒì¼ì—ì„œ í‚¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "# (ê¸°ë³¸ê°’: '.env', override=Trueë¥¼ í†µí•´ ê¸°ì¡´ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë®ì–´ì“°ê¸° ê°€ëŠ¥)\n",
        "\n",
        "if os.environ.get('OPENAI_API_KEY'):\n",
        "    print('OpenAI API í‚¤ í™•ì¸')\n",
        "if os.environ.get('GOOGLE_API_KEY'):\n",
        "    print('Google API í‚¤ í™•ì¸')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O3sXHIXyuafK",
      "metadata": {
        "id": "O3sXHIXyuafK"
      },
      "source": [
        "ì´ë²ˆ ì‹¤ìŠµì€ êµ¬ê¸€ì˜ ì œë¯¸ë‚˜ì´ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. `ChatGoogleGenerativeAI`ë¥¼ í†µí•´ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
        "\n",
        "\n",
        "ë¬´ë£Œ APIì˜ ê²½ìš° ì‚¬ìš©ëŸ‰ ì œí•œì´ ìˆëŠ”ë°, ì´ë¥¼ ê³ ë ¤í•˜ì—¬ Rate Limitì„ ì¶”ê°€í•©ë‹ˆë‹¤.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UVlKfacsuYcU",
      "metadata": {
        "id": "UVlKfacsuYcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df27f0f4-6068-4d9c-bd01-8366774e4247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--ee7e5d02-8dae-4a99-94b6-32de8316832c-0', usage_metadata={'input_tokens': 3, 'output_tokens': 16, 'total_tokens': 19, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "\n",
        "# Gemini 2.0 FlashëŠ” ë¶„ë‹¹ 15ê°œ ìš”ì²­ ì œí•œ,\n",
        "# ì•ˆì •ì  ì„œë¹™ì„ ìœ„í•´ ë¶„ë‹¹ 10ê°œ ì„¤ì •\n",
        "# ì¦‰, ì´ˆë‹¹ ì•½ 0.167ê°œ ìš”ì²­ (10/60)\n",
        "# `https://aistudio.google.com/`ì—ì„œ ëª¨ë¸ë³„ ì‚¬ìš©ëŸ‰ í™•ì¸\n",
        "\n",
        "rate_limiter = InMemoryRateLimiter(\n",
        "    requests_per_second=0.167,  # ë¶„ë‹¹ 10ê°œ ìš”ì²­\n",
        "    check_every_n_seconds=0.1,  # 100msë§ˆë‹¤ ì²´í¬\n",
        "    max_bucket_size=10,  # ìµœëŒ€ ë²„ìŠ¤íŠ¸ í¬ê¸°\n",
        ")\n",
        "\n",
        "gemini_llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    rate_limiter=rate_limiter,\n",
        "    temperature = 0.7,\n",
        "    max_tokens = 4096\n",
        ")\n",
        "\n",
        "# Test\n",
        "gemini_llm.invoke(\"ì•ˆë…•?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1556fee9",
      "metadata": {
        "id": "1556fee9"
      },
      "source": [
        "### init_chat_model() ë¡œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645f17ae",
      "metadata": {
        "id": "645f17ae"
      },
      "source": [
        "ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì€ ë²ˆê±°ë¡­ê³ , ìœ ì—°í•œ ë³€í™˜ì´ ì–´ë µìŠµë‹ˆë‹¤.   \n",
        "ë­ì²´ì¸ì—ì„œëŠ” ì•„ë˜ ì½”ë“œë¥¼ ì§€ì›í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99c6d085",
      "metadata": {
        "id": "99c6d085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3676bed-2aaa-4f51-82d2-cabaef035a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT: ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” OpenAIì˜ ì–¸ì–´ ëª¨ë¸ GPT-4o ê¸°ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
            "\n",
            "Gemini: ì €ëŠ” Googleì—ì„œ í›ˆë ¨í•œ AI ëª¨ë¸ì´ë©°, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì— ë‹µí•˜ê³  ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦½ë‹ˆë‹¤.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "\n",
        "gpt_llm = init_chat_model(\n",
        "    \"gpt-5-mini\", model_provider=\"openai\", temperature=0)\n",
        "    # \"gpt-4.1-mini\", model_provider=\"openai\", temperature=0)\n",
        "\n",
        "# claude_opus = init_chat_model(\n",
        "#     \"claude-3-opus\", model_provider=\"anthropic\", temperature=0\n",
        "# ) # ì‚¬ìš©ì€ X\n",
        "\n",
        "gemini_llm = init_chat_model(\n",
        "    \"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=0, rate_limiter=rate_limiter\n",
        ")\n",
        "\n",
        "prompt = 'ëª¨ë¸ëª…ê³¼ í•¨ê»˜ ìê¸°ì†Œê°œë¥¼ í•œì¤„ë¡œ ë¶€íƒí•´.'\n",
        "\n",
        "print(\"GPT: \" + gpt_llm.invoke(prompt).content + \"\\n\")\n",
        "print(\"Gemini: \" + gemini_llm.invoke(prompt).content + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "051e1849",
      "metadata": {
        "id": "051e1849"
      },
      "source": [
        "### Configurable íŒŒë¼ë¯¸í„°ë¡œ LLM ë™ì  ë³€ê²½"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a5d31e4",
      "metadata": {
        "id": "0a5d31e4"
      },
      "source": [
        "llmì„ invokeí•  ë•Œ, íŒŒë¼ë¯¸í„°ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c545f5f6",
      "metadata": {
        "id": "c545f5f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a47fbd0-57a2-4330-8b81-a9bc9f026c07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT: ê¸°í›„ë³€í™”, ìì›ê³ ê°ˆ, ë¶ˆí‰ë“±, ê¸°ìˆ ìœ¤ë¦¬, í‰í™”, êµìœ¡, ê±´ê°•, í˜‘ë ¥, ì§€ì†ê°€ëŠ¥ì„±, ì¸ê¶Œ.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt = 'ì¸ë¥˜ì˜ ë¯¸ë˜ë¥¼ ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•œ ë¬¸ì œëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ? 10ë‹¨ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.'\n",
        "\n",
        "llm = init_chat_model(temperature=0.5, max_tokens=4096)\n",
        "\n",
        "response1 = llm.invoke(prompt, config={\"configurable\":\n",
        "                                     {\"model\": \"gpt-4.1-mini\",\n",
        "                                      \"model_provider\": \"openai\"}})\n",
        "print('GPT: ' + response1.content +'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c222ceb7",
      "metadata": {
        "id": "c222ceb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13dc16d3-0ff9-4fe9-e512-c4eb80127406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini: ì§€ì†ê°€ëŠ¥í•œ ìƒì¡´ì„ ìœ„í•œ ì§€êµ¬ í™˜ê²½ ë³´ì¡´ê³¼ í˜„ëª…í•œ ê¸°ìˆ  í™œìš©.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response2 = llm.invoke(prompt, config={\"configurable\":\n",
        "                                     {\"model\": \"gemini-2.5-flash\",\n",
        "                                      \"model_provider\": \"google_genai\"}})\n",
        "print('Gemini: ' + response2.content +'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9791a23b",
      "metadata": {
        "id": "9791a23b"
      },
      "outputs": [],
      "source": [
        "# with_configìœ¼ë¡œ ì—°ê²°\n",
        "thinking_llm = llm.with_config({\"configurable\":\n",
        "                                     {\"model\": \"gemini-2.5-flash\",\n",
        "                                      \"model_provider\": \"google_genai\"}})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14460392",
      "metadata": {
        "id": "14460392"
      },
      "source": [
        "## LCEL ë¬¸ë²•ì˜ ì²´ì¸(Chain) ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3b4252b",
      "metadata": {
        "id": "b3b4252b"
      },
      "source": [
        "\n",
        "LCELì˜ ê°€ì¥ í° íŠ¹ì§•ì€, Chainì˜ êµ¬ì„± ìš”ì†Œë¥¼ **|**  (íŒŒì´í”„)ë¡œ ì—°ê²°í•˜ì—¬ í•œ ë²ˆì— ì‹¤í–‰í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤.     \n",
        "ì˜ˆì‹œë¥¼ ë³´ê² ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d503ec22",
      "metadata": {
        "id": "d503ec22"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "fun_chat_template = ChatPromptTemplate([\n",
        "    ('user', \"\"\"\n",
        "### Role\n",
        "ë‹¹ì‹ ì€ ì˜ì–´ì™€ í•œêµ­ì–´ì˜ ë²ˆì—­ì— ëŠ¥í†µí•œ ìœ ë¨¸ì˜ ë‹¬ì¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "### Instruction\n",
        "1.  ë¨¼ì €, [{topic}]ì— ê´€í•œ ì˜ì–´ Pun ë†ë‹´ì„ í•˜ë‚˜ ì œì‹œí•˜ì„¸ìš”.\n",
        "í•´ë‹¹ ë†ë‹´ì€ í•œêµ­ì–´ë¡œ ë²ˆì—­í–ˆì„ ë•Œì—ì„œë„ ê·¸ ì˜ë¯¸ê°€ í†µí•˜ê³  ìœ ë¨¸ê°€ ìœ ì§€ë  ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
        "ë§Œì•½ ì§ì—­ì´ ì–´ë µë‹¤ë©´, ì°½ì˜ì ìœ¼ë¡œ ê°ìƒ‰í•˜ì—¬ í•œêµ­ì–´ ë²„ì „ì˜ ë†ë‹´ì„ ì¶œë ¥í•˜ì„¸ìš”.\n",
        "- í•œêµ­ì–´ì˜ ìœ ì‚¬ ë°œìŒ, ë‹¨ì–´ì˜ ì¤‘ì˜ì  ì˜ë¯¸, í˜¹ì€ í•œêµ­ì˜ ë¬¸í™”ì  ìƒí™© ë“±ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "2.  ë‹¤ìŒìœ¼ë¡œ, í•´ë‹¹ ë†ë‹´ì´ ì˜ì–´ ì›ì–´ë¯¼ ì‚¬ìš©ìì—ê²Œ ì™œ ì¬ë¯¸ìˆëŠ”ì§€ ê·¸ë“¤ì˜ ì–¸ì–´ì  ìœ í¬ ë° ë¬¸í™”ì  ê´€ì ì—ì„œ í•œêµ­ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.\n",
        "\"\"\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8def25a8",
      "metadata": {
        "id": "8def25a8"
      },
      "source": [
        "-----------\n",
        "LCELì˜ êµ¬ì¡°ì—ì„œëŠ” í…œí”Œë¦¿ê³¼ llm ëª¨ë¸ì„ ì„¤ì •í•˜ê³ , ì´ë¥¼ í•˜ë‚˜ë¡œ ë¬¶ì–´ ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcb53e81",
      "metadata": {
        "id": "bcb53e81"
      },
      "outputs": [],
      "source": [
        "joke = fun_chat_template | llm.with_config({\"configurable\":\n",
        "                                     {\"model\": \"gemini-2.0-flash\",\n",
        "                                      \"model_provider\": \"google_genai\"}})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b435fd",
      "metadata": {
        "id": "69b435fd"
      },
      "source": [
        "ì´í›„, ì²´ì¸ì˜ invokeë¥¼ ì‹¤í–‰í•˜ë©° ì…ë ¥ í¬ë§·ì„ ì „ë‹¬í•˜ë©´, ìˆœì„œëŒ€ë¡œ ì²´ì¸ì´ ì‹¤í–‰ë˜ë©° ìµœì¢… ê²°ê³¼ë¡œ ì—°ê²°ë©ë‹ˆë‹¤.       \n",
        "\n",
        "ì…ë ¥ ë³€ìˆ˜ê°€ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì „ë‹¬ë˜ê³ , ì™„ì„±ëœ í”„ë¡¬í”„íŠ¸ê°€ LLMì— ë“¤ì–´ê°€ëŠ” êµ¬ì¡°ì…ë‹ˆë‹¤.  \n",
        "ì…ë ¥ í¬ë§·ì€ Dict í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e1a8fa",
      "metadata": {
        "id": "a0e1a8fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8be55b83-d011-46d6-d8d9-16685fd3459b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì•Œê² ìŠµë‹ˆë‹¤! ê³„ë€ì— ê´€í•œ í€(Pun) ë†ë‹´ì„ í•˜ë‚˜ ì œì‹œí•˜ê³ , ì˜ì–´ ì›ì–´ë¯¼ ì‚¬ìš©ìì˜ ê´€ì ì—ì„œ ê·¸ ìœ ë¨¸ë¥¼ ì„¤ëª…í•´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
            "\n",
            "**ì˜ì–´ ë†ë‹´:**\n",
            "\n",
            "> Why did the egg hide? Because it was a little chicken!\n",
            "\n",
            "**í•œêµ­ì–´ ë²ˆì—­ (ê°ìƒ‰):**\n",
            "\n",
            "> ì™œ ê³„ë€ì´ ìˆ¨ì—ˆê²Œ? ì«„ì•˜ìœ¼ë‹ˆê¹Œ! (í˜¹ì€: ì«„ê³„ë‹ˆê¹Œ!)\n",
            "\n",
            "**ì˜ì–´ ì›ì–´ë¯¼ ê´€ì ì—ì„œì˜ ìœ ë¨¸ ì„¤ëª…:**\n",
            "\n",
            "ì˜ì–´ ë†ë‹´ì˜ í•µì‹¬ì€ \"chicken\"ì´ë¼ëŠ” ë‹¨ì–´ì˜ ì¤‘ì˜ì ì¸ ì˜ë¯¸ë¥¼ í™œìš©í•œ ì–¸ì–´ìœ í¬ì…ë‹ˆë‹¤.\n",
            "\n",
            "*   **Chicken (ëª…ì‚¬):** ë‹­, ë³‘ì•„ë¦¬\n",
            "*   **Chicken (í˜•ìš©ì‚¬):** ê²ì´ ë§ì€, ì†Œì‹¬í•œ\n",
            "\n",
            "ê³„ë€ì´ ìˆ¨ì€ ì´ìœ ëŠ” \"ë‹­\"ì´ê¸° ë•Œë¬¸ì´ ì•„ë‹ˆë¼, \"ê²ì´ ë§ì•„ì„œ\" ìˆ¨ì—ˆë‹¤ëŠ” ì˜ë¯¸ë¡œ í•´ì„ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, ê³„ë€ì´ ì•„ì§ ë¶€í™”í•˜ì§€ ì•Šì€ ìƒíƒœì´ë¯€ë¡œ \"little chicken\"ì€ 'ì•„ì§ ì–´ë¦° ë‹­'ì´ë¼ëŠ” ì˜ë¯¸ì™€ ë™ì‹œì— 'ê²ì´ ë§ì€'ì´ë¼ëŠ” ì˜ë¯¸ë¥¼ ë‚´í¬í•˜ë©°, ì´ëŠ” ìƒí™©ì— ëŒ€í•œ ë°˜ì „ê³¼ í•¨ê»˜ ì›ƒìŒì„ ìœ ë°œí•©ë‹ˆë‹¤.\n",
            "\n",
            "í•œêµ­ì–´ ë²ˆì—­ì—ì„œëŠ” \"ì«„ë‹¤\"ë¼ëŠ” í‘œí˜„ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ìŠ·í•œ ìœ ë¨¸ë¥¼ ì‚´ë¦¬ë ¤ê³  í–ˆìŠµë‹ˆë‹¤. \"ì«„ë‹¤\"ëŠ” 'ê²ì„ ë¨¹ë‹¤'ë¼ëŠ” ëœ»ìœ¼ë¡œ, 'ì«„ê³„'ëŠ” 'ê²ë¨¹ì€ ê³„ë€'ì´ë¼ëŠ” ì˜ë¯¸ì™€ ë¹„ìŠ·í•˜ê²Œ ë“¤ë¦¬ë„ë¡ ì˜ë„í–ˆìŠµë‹ˆë‹¤. ë¬¼ë¡  ì˜ì–´ ì›ì–´ë¯¼ì´ ëŠë¼ëŠ” ë§Œí¼ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ìœ ë¨¸ëŠ” ì•„ë‹ ìˆ˜ ìˆì§€ë§Œ, í•œêµ­ì–´ì˜ ìœ ì‚¬ ë°œìŒê³¼ ìƒí™©ì„ í™œìš©í•˜ì—¬ ìµœëŒ€í•œ ë¹„ìŠ·í•œ ëŠë‚Œì„ ì „ë‹¬í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "response = joke.invoke({'topic':'eggs'})\n",
        "# ë§¤ê°œë³€ìˆ˜ê°€ 1ê°œì¼ ë•ŒëŠ” joke.invoke('eggs') ë„ ê°€ëŠ¥\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f5fe575",
      "metadata": {
        "id": "5f5fe575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce7e401-62dc-4a3c-b3a6-c27b6db0879e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì•Œê² ìŠµë‹ˆë‹¤! ì»¤í”¼ì— ê´€í•œ í€(Pun) ë†ë‹´ì„ í•˜ë‚˜ ì œì‹œí•˜ê³ , í•œêµ­ì–´ ë²ˆì—­ ë° ì˜ì–´ ì›ì–´ë¯¼ ê´€ì ì—ì„œ ìœ ë¨¸ í•´ì„¤ì„ ë§ë¶™ì´ê² ìŠµë‹ˆë‹¤.\n",
            "\n",
            "**ì˜ì–´ Pun ë†ë‹´:**\n",
            "\n",
            "> What do you call sad coffee?\n",
            ">\n",
            "> Depresso.\n",
            "\n",
            "**í•œêµ­ì–´ ë²ˆì—­ (ê°ìƒ‰):**\n",
            "\n",
            "> ì»¤í”¼ê°€ ìš°ìš¸í•˜ë©´ ë­ë¼ê³  ë¶€ë¥¼ê¹Œ?\n",
            ">\n",
            "> ì¹´í˜ ì“°ë¼ë–¼.\n",
            "\n",
            "**ìœ ë¨¸ í•´ì„¤:**\n",
            "\n",
            "ì´ ë†ë‹´ì€ ì˜ì–´ì—ì„œ \"Depressed (ìš°ìš¸í•œ)\"ì™€ \"Espresso (ì—ìŠ¤í”„ë ˆì†Œ)\"ì˜ ë°œìŒì´ ìœ ì‚¬í•˜ë‹¤ëŠ” ì ì„ ì´ìš©í•œ ì–¸ì–´ìœ í¬ì…ë‹ˆë‹¤. \"Depresso\"ëŠ” \"Depressed\"ì™€ \"Espresso\"ë¥¼ í•©ì³ ë§Œë“  ì‹ ì¡°ì–´ë¼ê³  ë³¼ ìˆ˜ ìˆì£ . ì¦‰, \"ìš°ìš¸í•œ ì»¤í”¼\"ë¥¼ \"ì—ìŠ¤í”„ë ˆì†Œ\"ì²˜ëŸ¼ ë“¤ë¦¬ê²Œë” í‘œí˜„í•˜ì—¬ ì›ƒìŒì„ ìœ ë°œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
            "\n",
            "í•œêµ­ì–´ ë²ˆì—­ì—ì„œëŠ” \"ì“°ë¼ë¦°\" ê°ì •ì„ í‘œí˜„í•˜ëŠ” \"ì“°ë‹¤\"ì™€ ì»¤í”¼ ì¢…ë¥˜ì¸ \"ë¼ë–¼\"ë¥¼ ê²°í•©í•˜ì—¬ \"ì¹´í˜ ì“°ë¼ë–¼\"ë¼ëŠ” ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. \"ì“°ë¼ë¦°\" ê°ì •ì€ ìš°ìš¸í•¨ê³¼ ì—°ê²°ë  ìˆ˜ ìˆìœ¼ë©°, ë™ì‹œì— ì»¤í”¼ì˜ ì“´ë§›ì„ ì—°ìƒì‹œí‚¤ë¯€ë¡œ, í•œêµ­ì–´ ì‚¬ìš©ìì—ê²Œë„ ë¹„ìŠ·í•œ ì¢…ë¥˜ì˜ ì–¸ì–´ìœ í¬ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
            "\n",
            "**ì˜ì–´ ì›ì–´ë¯¼ ê´€ì ì—ì„œì˜ ìœ ë¨¸ í¬ì¸íŠ¸:**\n",
            "\n",
            "*   **ë°œìŒ ìœ ì‚¬ì„± (Phonetic Similarity):** ì˜ì–´ë¥¼ ëª¨êµ­ì–´ë¡œ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒë“¤ì€ \"Depressed\"ì™€ \"Espresso\"ì˜ ë°œìŒì´ ë§¤ìš° ë¹„ìŠ·í•˜ê²Œ ë“¤ë¦°ë‹¤ëŠ” ê²ƒì„ ì¸ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë°œìŒì˜ ìœ ì‚¬ì„±ì„ ì´ìš©í•œ ì–¸ì–´ìœ í¬ëŠ” ì˜ì–´ê¶Œì—ì„œ í”íˆ ì‚¬ìš©ë˜ëŠ” ìœ ë¨¸ ë°©ì‹ì…ë‹ˆë‹¤.\n",
            "*   **ë‹¨ì–´ í•©ì„± (Wordplay/Pun):** \"Depresso\"ë¼ëŠ” ìƒˆë¡œìš´ ë‹¨ì–´ë¥¼ ë§Œë“¤ì–´ë‚´ë©´ì„œ, ìµìˆ™í•œ ë‹¨ì–´ë“¤ì„ ì¬ì¹˜ ìˆê²Œ ì¡°í•©í•˜ì—¬ ì˜ˆìƒì¹˜ ëª»í•œ ì›ƒìŒì„ ì„ ì‚¬í•©ë‹ˆë‹¤.\n",
            "*   **ì¼ìƒì ì¸ ì†Œì¬ (Relatability):** ì»¤í”¼ëŠ” ë§ì€ ì‚¬ëŒë“¤ì´ ë§¤ì¼ ë§ˆì‹œëŠ” ìŒë£Œì´ë¯€ë¡œ, ì»¤í”¼ì™€ ê´€ë ¨ëœ ë†ë‹´ì€ ì‰½ê²Œ ê³µê°ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì¹´í˜ì¸ì´ ë¶€ì¡±í•  ë•Œ ëŠë¼ëŠ” ë¬´ê¸°ë ¥í•¨ì´ë‚˜ ìš°ìš¸ê°ì„ \"Depresso\"ë¼ëŠ” ë‹¨ì–´ë¡œ í‘œí˜„í•¨ìœ¼ë¡œì¨, ë”ìš± ì¬ë¯¸ìˆê²Œ ëŠê»´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "*   **ê°€ë²¼ìš´ ë¶„ìœ„ê¸° (Lightheartedness):** ìš°ìš¸í•¨ì´ë¼ëŠ” ë‹¤ì†Œ ë¬´ê±°ìš´ ì£¼ì œë¥¼ ì»¤í”¼ì™€ ì—°ê²°ì‹œì¼œ ê°€ë³ê³  ìœ ì¾Œí•˜ê²Œ í’€ì–´ëƒˆë‹¤ëŠ” ì ë„ ìœ ë¨¸ì˜ ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.\n",
            "\n",
            "í•œêµ­ì–´ ë²ˆì—­ì—ì„œë„ ì´ëŸ¬í•œ ìœ ë¨¸ í¬ì¸íŠ¸ë¥¼ ì‚´ë¦¬ê¸° ìœ„í•´, ë°œìŒ ìœ ì‚¬ì„±ê³¼ ë‹¨ì–´ í•©ì„±ì„ í™œìš©í•˜ì—¬ \"ì¹´í˜ ì“°ë¼ë–¼\"ë¼ëŠ” ìƒˆë¡œìš´ í‘œí˜„ì„ ë§Œë“¤ì–´ëƒˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "response = joke.invoke({'topic':'coffee', 'count':'3'})\n",
        "# í”„ë¡¬í”„íŠ¸ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì€ ë§¤ê°œë³€ìˆ˜ëŠ” ë¬´ì‹œ\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e396203",
      "metadata": {
        "id": "7e396203"
      },
      "source": [
        "### Geminiì˜ Reasoning ëª¨ë¸\n",
        "\n",
        "Geminiì˜ 2.5 Proì™€ Flash ëª¨ë¸ì€ Reasoning ëª¨ë¸ì…ë‹ˆë‹¤.   \n",
        "Flashì˜ ê²½ìš°, thinking_budgetì„ ì œí•œí•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79c3c49",
      "metadata": {
        "id": "f79c3c49"
      },
      "outputs": [],
      "source": [
        "joke = fun_chat_template | llm.with_config({\"configurable\":\n",
        "                                     {\"model\": \"gemini-2.5-flash-preview-05-20\",\n",
        "                                      \"model_provider\": \"google_genai\",\n",
        "                                      \"thinking_budget\": 1000}})\n",
        "                                    # 1000ê°œì˜ Reasoning í† í° ìƒì„± í›„ ë‹µë³€ ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8005f683",
      "metadata": {
        "id": "8005f683",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a93818-6f13-47a9-8991-3c313c88ae7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "response = joke.invoke('eggs')\n",
        "\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "996f34e5",
      "metadata": {
        "id": "996f34e5"
      },
      "source": [
        "## [ì‹¤ìŠµ] ë§¤ê°œë³€ìˆ˜ê°€ 2ê°œì¸ Prompt-LLM Chain ìƒì„±í•˜ê¸°   \n",
        "ì„ì˜ì˜ ChatPromptTemplateë¥¼ ë§Œë“¤ê³ , 2ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ë°›ë„ë¡ êµ¬ì„±í•˜ì—¬ ì²´ì¸ì„ ë§Œë“¤ê³  ì‹¤í–‰í•˜ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ec1ff2c",
      "metadata": {
        "id": "0ec1ff2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04b70c7-7855-4f05-8060-beff08ec5b8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œìš”. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 8, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CSZlR7dGjipfEcJovjKN5z6BtQHMB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--5f9bc19a-9d5a-4ee2-be72-7ad5a221e212-0', usage_metadata={'input_tokens': 8, 'output_tokens': 26, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# ì•„ë˜ LLMì„ ì‚¬ìš©í•˜ì„¸ìš”!\n",
        "gpt_llm = init_chat_model(\n",
        "    \"gpt-5-mini\", model_provider=\"openai\", reasoning_effort='low', temperature=0)\n",
        "gemini_llm = init_chat_model(\n",
        "    \"gemini-2.5-flash\", model_provider=\"google_genai\", temperature=0, rate_limiter=rate_limiter, thinking_budget=1000\n",
        ")\n",
        "\n",
        "gpt_llm.invoke(\"ì•ˆë…•\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LC7f4K056TWg",
      "metadata": {
        "id": "LC7f4K056TWg"
      },
      "outputs": [],
      "source": [
        "# System, Human í¬í•¨í•˜ì—¬, ì´ 2ê°œì˜ ë§¤ê°œë³€ìˆ˜ ë¶™ì´ê¸°\n",
        "prompt = ChatPromptTemplate([\n",
        "    ('system', 'ë‹¹ì‹ ì€ ì£¼ì–´ì§„ ì£¼ì œì— ëŒ€í•´ ë…¼ë¦¬ì ì¸ ê¸€ì„ ì‘ì„±í•©ë‹ˆë‹¤.'),\n",
        "    ('user', '''\n",
        "    ì£¼ì œ: {topic}\n",
        "    ë…¼ì¡°: {direction}\n",
        "    ''')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69894a7b",
      "metadata": {
        "id": "69894a7b"
      },
      "outputs": [],
      "source": [
        "gpt_chain = prompt | gpt_llm\n",
        "gemini_chain = prompt | gemini_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf3226d",
      "metadata": {
        "id": "ecf3226d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed5701c-aed8-4a7f-cd46-e868de98daa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì£¼ì œ: gptì™€ gemini ì°¨ì´\n",
            "\n",
            "gpt answer : ë‚˜ëŠ” ëŠë¦¬ë‹¤. í•˜ì§€ë§Œ ëŠë¦¼ ì†ì—” ê´€ì°°ê³¼ ìˆ™ê³ ê°€ ìˆë‹¤. ì˜¤ëŠ˜ì€ gptì™€ geminiì˜ ì°¨ì´ë¥¼ ì²œì²œíˆ, ê·¸ëŸ¬ë‚˜ ë…¼ë¦¬ì ìœ¼ë¡œ ë§í•´ ë³´ê² ë‹¤.\n",
            "\n",
            "ìš°ì„  ì •ì²´ì„±ê³¼ ì„¤ê³„ ì² í•™ì—ì„œ ì¶œë°œí•˜ì. GPT ê³„ì—´ì€ ëŒ€ì²´ë¡œ ë²”ìš© ì–¸ì–´ ëª¨ë¸ë¡œì„œ í…ìŠ¤íŠ¸ ìƒì„±ê³¼ ì¶”ë¡ ì— ì´ˆì ì„ ë§ì¶˜ë‹¤. í›ˆë ¨ ë°ì´í„°ì™€ ëª©í‘œëŠ” ê´‘ë²”ìœ„í•œ ì–¸ì–´ íŒ¨í„´ì˜ í•™ìŠµì´ë©°, ëª…ë£Œí•œ ë¬¸ì¥ ìƒì„±Â·ë…¼ë¦¬ì  ì‘ë‹µÂ·ì¶”ë¡  ëŠ¥ë ¥ì„ ì¤‘ì‹œí•œë‹¤. ì„¤ê³„ìƒ ì¼ê´€ì„± ìˆê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€ì„ ë‚´ë†“ë„ë¡ íŠœë‹ë˜ê³ , ì•ˆì „ì„±ê³¼ ìœ í•´ì„± ì™„í™”ë¥¼ ìœ„í•´ ì²´ê³„ì  ê²€í† ê°€ ë“¤ì–´ê°„ë‹¤.\n",
            "\n",
            "ì„±ëŠ¥ê³¼ ê°•ì  ì¸¡ë©´ì—ì„œ ë³´ë©´ GPTëŠ” ë³µì¡í•œ ë…¼ì¦ êµ¬ì„±, ë‹¨ê³„ì  ì‚¬ê³ (ì²´ì¸ ì˜¤ë¸Œ ìƒê° ë³´ì¡° ê¸°ë²• í¬í•¨), ì½”ë“œ ìƒì„±ê³¼ ë””ë²„ê¹…, ê¸´ ë¬¸ë§¥ ì²˜ë¦¬ì—ì„œ ì‹ ë¢°ì„±ì„ ë³´ì¸ë‹¤. ëŠë¦¬ê²Œ ìˆ™ê³ í•˜ëŠ” ë¹„ìœ ê°€ ê°€ë¦¬í‚¤ë“¯, ë³µí•©ì  ë¬¸ì œë¥¼ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ  ì²˜ë¦¬í•˜ê³  ë…¼ë¦¬ì  ì¼ê´€ì„±ì„ í™•ë³´í•˜ëŠ” ë° ê°•ì ì´ ìˆë‹¤. ë„ë©”ì¸ ì§€ì‹ì˜ í­ì´ ë„“ê³ , í”„ë¡¬í”„íŠ¸ ì„¤ê³„(prompt engineering)ì´ë‚˜ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¡œ í–‰ë™ì„ ì„¸ë°€í•˜ê²Œ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.\n",
            "\n",
            "í•œê³„ë„ ìˆë‹¤. íŠ¹ì • ìµœì‹  ì •ë³´(ì‹¤ì‹œê°„ ì‚¬ê±´, ì„œë¹„ìŠ¤ë³„ ìµœì‹  ê¸°ëŠ¥ ë“±)ëŠ” ì—…ë°ì´íŠ¸ ì£¼ê¸°ì— ì˜ì¡´í•˜ë©°, ë©€í‹°ëª¨ë‹¬(ì˜ˆ: ì´ë¯¸ì§€Â·ë¹„ë””ì˜¤) í†µí•© ì¸¡ë©´ì€ ëª¨ë¸ ë²„ì „ê³¼ êµ¬í˜„ì— ë”°ë¼ ì°¨ì´ê°€ í¬ë‹¤. ë˜ ê³¼ë„í•˜ê²Œ í™•ì‹ í•˜ëŠ”(í—ˆìœ„ ì •ë³´ ìƒì„±) ê²½í–¥ì„ ì¤„ì´ê¸° ìœ„í•œ ì¶”ê°€ì ì¸ ì•ˆì „ì¥ì¹˜ì™€ ì‚¬ìš©ì í”¼ë“œë°± ë£¨í”„ê°€ í•„ìš”í•˜ë‹¤.\n",
            "\n",
            "ì‹¤ìš©ì  ì‚¬ìš© ì‚¬ë¡€ë¡œëŠ”: ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±Â·ë…¼ë¦¬ì  ë³´ê³ ì„œÂ·í”„ë¡œê·¸ë˜ë° ë° ë””ë²„ê¹…Â·êµìœ¡ìš© ì„¤ëª…Â·ì‹¬ì¸µ Q&A ë“±, â€˜ì •í™•ì„±ê³¼ ì¼ê´€ì„±â€™ì´ ìš”êµ¬ë˜ëŠ” ì‘ì—…ì— ì í•©í•˜ë‹¤.\n",
            "\n",
            "gemini answer : ë‚˜ëŠ” ëŠë¦¬ì§€ë§Œ ê±°ë¶ì´ì˜ ëˆˆìœ¼ë¡œ ì„¸ìƒì„ ë³¸ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë²ˆì—” ê±°ë¶ì´ê°€ ì•„ë‹Œ, geminiì˜ ì‹œì„ ìœ¼ë¡œ í† ë¼(=ë¹ ë¥¸ ëª¨ë¸)ë¥¼ ë°”ë¼ë³´ë©° ì°¨ì´ë¥¼ ì´ì•¼ê¸°í•´ë³´ê² ë‹¤.\n",
            "\n",
            "geminiëŠ” ì„¤ê³„ ì² í•™ê³¼ ì‚¬ìš©ì ê²½í—˜ì—ì„œ â€˜ìœµí†µì„±â€™ê³¼ â€˜ë‹¤ì¤‘ ëª¨ë‹¬ë¦¬í‹°â€™ì— ë¬´ê²Œë¥¼ ë‘ëŠ” ê²½í–¥ì´ ìˆë‹¤. í…ìŠ¤íŠ¸ë¿ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ ë“± ë‹¤ì–‘í•œ ì…ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë£¨ëŠ” ëŠ¥ë ¥ì´ ê°•ì¡°ë˜ë©°, ì§ê´€ì ì´ê³  ì‘ë‹µì´ ê²½ì¾Œí•œ ì¸í„°ë™ì…˜ì„ ëª©í‘œë¡œ í•œë‹¤. ì†ë„ê° ìˆëŠ” ë°˜ì‘ê³¼ ë©€í‹°ëª¨ë‹¬ ì´í•´ ëŠ¥ë ¥ì€ ì‚¬ìš©ìì™€ì˜ ëŒ€í™”ì—ì„œ ì¦‰ê°ì ì¸ ë§Œì¡±ê°ì„ ì¤€ë‹¤.\n",
            "\n",
            "ê°•ì ì€ ë©€í‹°ëª¨ë‹¬ í†µí•©, ì¸í„°ë™ì…˜ì˜ ìì—°ìŠ¤ëŸ¬ì›€, ê·¸ë¦¬ê³  ë©€í‹°íƒœìŠ¤í¬ í™˜ê²½ì—ì„œì˜ ìœ ì—°ì„±ì´ë‹¤. ì´ë¯¸ì§€ ì„¤ëª…, ë¹ ë¥¸ ìš”ì•½, ëŒ€í™”í˜• ì°½ì‘ í™œë™(ìŠ¤í† ë¦¬í…”ë§Â·ì•„ì´ë””ì–´ ë¸Œë ˆì¸ìŠ¤í† ë°) ë“±ì—ì„œ íŠ¹íˆ ë¹›ë‚œë‹¤. í† ë¼ì²˜ëŸ¼ ê¸°ë¯¼í•˜ê²Œ ë¬¸ë§¥ì„ í¬ì°©í•˜ê³ , ì§§ì€ ì‹œê°„ ì•ˆì— í’ë¶€í•œ ì‘ë‹µì„ ë‚´ë†“ëŠ” íŠ¹ì§•ì´ ìˆë‹¤.\n",
            "\n",
            "ì œì•½ì€ ëª¨ë¸ ì„¤ê³„Â·ì •ì±…ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ë•Œë¡œëŠ” í‘œí˜„ì˜ ê²½ì¾Œí•¨ì´ ë…¼ë¦¬ì  ì—„ë°€ì„±ë³´ë‹¤ ì•ì„¤ ìˆ˜ ìˆìœ¼ë©°, ê¸´ ë…¼ì¦ì´ë‚˜ ë³µì¡í•œ ì¶”ë¡ ì—ì„œ ì„¸ì‹¬í•œ ë‹¨ê³„ì  ê·¼ê±° ì œì‹œê°€ í•„ìš”í•  ë•Œ ì¶”ê°€ì ì¸ ìœ ë„(í”„ë¡¬í”„íŠ¸)ê°€ ìš”êµ¬ë  ìˆ˜ ìˆë‹¤. ìµœì‹ ì„±, ì•ˆì „ì„±, ê·¸ë¦¬ê³  íŠ¹ì • ì „ë¬¸ ë¶„ì•¼ì˜ ì •ë°€í•œ ë‹µë³€ì—ì„œëŠ” ë³´ì™„ì´ í•„ìš”í•  ìˆ˜ ìˆë‹¤.\n",
            "\n",
            "ì í•©í•œ ì‚¬ìš© ì‚¬ë¡€ë¡œëŠ”: ë©€í‹°ë¯¸ë””ì–´ ë¶„ì„Â·ì´ë¯¸ì§€ ê¸°ë°˜ Q&AÂ·ëŒ€í™”í˜• ì°½ì‘Â·ë¹ ë¥¸ ìš”ì•½Â·ê³ ê° ì‘ëŒ€ ë“±, â€˜ì¦‰ê°ì ì´ê³  ì§ê´€ì ì¸ ìƒí˜¸ì‘ìš©â€™ì´ í•µì‹¬ì¸ ì‘ì—…ì— ì–´ìš¸ë¦°ë‹¤.\n",
            "\n",
            "ê²°ë¡  â€” ëŠë¦¼ê³¼ ë¯¼ì²©í•¨ì˜ ì¡°í™”ê°€ í•µì‹¬\n",
            "- GPT(ë‚˜ëŠ” ëŠë¦¬ë‹¤): ìˆ™ê³ ì™€ ë…¼ë¦¬ë¥¼ ì¤‘ì‹œí•˜ëŠ” ë„êµ¬. ë³µì¡í•œ ì¶”ë¡ , ì •í™•ì„±, ì¼ê´€ëœ í…ìŠ¤íŠ¸ ìƒì„±ì— ê°•í•˜ë‹¤. í•™ìˆ Â·ê¸°ìˆ Â·ì½”ë“œÂ·ê¸´ ë…¼ì¦ì— ì í•©í•˜ë‹¤.\n",
            "- Gemini(í† ë¼ì˜ ê²½ì¾Œí•¨): ë©€í‹°ëª¨ë‹¬Â·ëŒ€í™”í˜• ìƒí˜¸ì‘ìš©ì— ê°•í•œ ë„êµ¬. ì†ë„ì™€ ì§ê´€ì„±, ë‹¤ì–‘í•œ ì…ë ¥ í˜•íƒœ ì²˜ë¦¬ì—ì„œ ì¥ì ì´ ìˆë‹¤.\n",
            "\n",
            "ì‹¤ì œ ì„ íƒì€ ëª©ì ì— ë‹¬ë ¤ ìˆë‹¤. ê¹Šì€ ë…¼ë¦¬ì™€ ì •í™•ì„±ì„ ì›í•˜ë©´ GPT ê³„ì—´ì˜ ì ‘ê·¼ ë°©ì‹ì´ ì•ˆì •ì ì´ë‹¤. ë‹¤ì–‘í•œ ì…ë ¥(ì´ë¯¸ì§€Â·ìŒì„± ë“±)ê³¼ ì¦‰ê°ì  ìƒí˜¸ì‘ìš©ì„ ì¤‘ì‹œí•˜ë©´ Gemini ê³„ì—´ì´ ë” ì í•©í•  ìˆ˜ ìˆë‹¤. ìµœì ì˜ ê²°ê³¼ë¥¼ ìœ„í•´ì„œëŠ” ë‘ ì ‘ê·¼ì„ ë³´ì™„ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜, í”„ë¡¬í”„íŠ¸ì™€ í›„ì²˜ë¦¬ ì „ëµìœ¼ë¡œ ê° ëª¨ë¸ì˜ ì•½ì ì„ ë³´ì™„í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•˜ë‹¤.\n"
          ]
        }
      ],
      "source": [
        "gpt_response = gpt_chain.invoke({'topic':'í† ë¼', 'direction':'ê±°ë¶ì´'})\n",
        "gemini_response = gemini_chain.invoke({'topic':'í† ë¼', 'direction':'ê±°ë¶ì´'})\n",
        "# print(gpt_response.content)\n",
        "# print(gemini_response.content)\n",
        "gap = 'gpt answer : ' + gpt_response.content + '    VS    gemini answer : '+gemini_response.content\n",
        "response = gpt_chain.invoke({'topic':'gptì™€ geminiì°¨ì´', 'direction': gap})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7viSO-5e_Zzg",
      "metadata": {
        "id": "7viSO-5e_Zzg"
      },
      "source": [
        "<br><br><br><br><br><br><br><br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C2nlXU-d_dXE",
      "metadata": {
        "id": "C2nlXU-d_dXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5632a2-3bcd-4da1-cf92-19d2a7a47f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(ë¬´ëŒ€ëŠ” ê³ ì„±ì˜ ë²½ë‚œë¡œ ì˜†. í•œìª½ì—ëŠ” ê²€ì€ ì˜·ì„ ì…ì€ í–„ë¦¿, ë‹¤ë¥¸ ìª½ì—ëŠ” ë¹¨ê°„ëª¨ìì™€ ë©œë¹µë°”ì§€ë¥¼ ì…ì€ ìŠˆí¼ë§ˆë¦¬ì˜¤ê°€ ì„œ ìˆë‹¤. ë‘ ì‚¬ëŒ ì‚¬ì´ì—ëŠ” ì‘ì€ ë²„ì„¯ê³¼ ì¹¼ì´ ë†“ì—¬ ìˆë‹¤.)\n",
            "\n",
            "í–„ë¦¿: (í•œìˆ¨) ì¡´ì¬í•˜ëŠëƒ, ì•„ë‹ˆëƒ â€” ê·¸ê²ƒì´ ë¬¸ì œë¡œë‹¤. ì´ ì„¸ìƒì´ ë‚˜ë¥¼ ë¶€ì¶”ê¸°ê³ , ì–‘ì‹¬ì´ ë‚˜ë¥¼ ë¬¶ê³ , ë‚˜ì˜ ê¸¸ì„ ê°€ë¡œë§‰ëŠ”ë‹¤ë„¤.\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: (ë°ê²Œ) ì‰? ì´ê²Œ ë¬´ìŠ¨ ë³µì¡í•œ ë§ì´ì•¼! ì‚¶ì€ ìŠ¤í…Œì´ì§€ì•¼. ì í”„í•˜ê³  ë‹¬ë¦¬ê³ , ë•Œë¡œëŠ” ì•„ì´í…œì„ ë¨¹ê³  í˜ì„ ë‚´ì§€. ë‚œ ë¬¸ì œ ë³´ë©´ \"ë ›ì¸ ê³ !\"ì§€!\n",
            "\n",
            "í–„ë¦¿: (ì˜ì•„) ì•„ì´í…œì´ë¼â€¦ ë‚´ ì‚¶ì— ê·¸ëŸ° ë²„ì„¯ì´ ìˆë‹¤ë©´ ì–¼ë§ˆë‚˜ ì¢‹ì„ê¹Œ. í•˜ì§€ë§Œ ì„ íƒì€ ë¬´ê²ê³ , í–‰ë™ì˜ ê²°ê³¼ëŠ” ëŒì´í‚¬ ìˆ˜ ì—†ë‹¤. ì–´ì°Œí•´ì•¼ ì˜³ì€ ì¼ì„ í•  ìˆ˜ ìˆì„ì§€ ëª¨ë¥´ê² êµ¬ë‚˜.\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: ìŒâ€”ì˜³ì€ ì¼? ê·¸ê±´ ê²°êµ­ ë„¤ê°€ ë‘ë ¤ì›€ê³¼ ë§ì„œëŠ” ê±°ì•¼. ë‚˜ë„ ê³µì£¼ë¥¼ êµ¬í•˜ë ¤ê³  ì í”„í•  ë•Œë§ˆë‹¤ ë–¨ì–´ì§ˆê¹Œ ê±±ì •í–ˆì§€. ê·¼ë° ê³ ë¯¼í•œë‹¤ê³  ê³µì£¼ê°€ ì €ì ˆë¡œ êµ¬ì¶œë˜ì§„ ì•Šë”ë¼êµ¬. ì‘ì€ í•œ ê±¸ìŒ, ê·¸ê²Œ ì¤‘ìš”í•´!\n",
            "\n",
            "í–„ë¦¿: (ê³ ê°œë¥¼ ê°¸ì›ƒ) ì‘ì€ í•œ ê±¸ìŒì´ë¼â€¦ ë„ˆëŠ” ë‹¨ìˆœí•œ ìš©ê¸°ë¼ê³  í•˜ëŠ”êµ¬ë‚˜. í•˜ì§€ë§Œ ë³µìˆ˜ì™€ ì •ì˜ ì‚¬ì´ì˜ ê²½ê³„ê°€ ëª¨í˜¸í•  ë•Œ, ë‚˜ëŠ” ì–´ë–»ê²Œ í™•ì‹ í•˜ê² ëŠ”ê°€? ë‚˜ì˜ í–‰ë™ì´ ì˜³ë‹¤ê³  ë§í•  ì¦ê±°ëŠ” ì–´ë””ì— ìˆëŠ”ê°€?\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: ì¦ê±°ëŠ” ë„¤ ê°€ìŠ´ ì†ì— ìˆì–´. ê·¸ë¦¬ê³  ê³„íšë„ í•„ìš”í•˜ì§€. ë¯¸ë¦¬ ìƒê°í•˜ê³ , ìœ„í—˜ì„ ì¤„ì´ê³ , ë™ë£Œë“¤ë„ ë¯¿ì–´. ë£¨ì´ì§€ ê°™ì€ ì¹œêµ¬(í˜¹ì€ í˜¸ë ˆì´ì‡¼)ë¥¼ ê³ì— ë‘ë©´ í˜¼ì ëŒë ¤ê°€ì§€ ì•Šì•„. í–‰ë™ ì „ì— 'ì™œ'ë¥¼ ë¶„ëª…íˆ í•´ë´. ê·¸ë‹¤ìŒì—” í•œ ë²ˆì— í•œ ì¥ì• ë¬¼ì”© í•´ê²°!\n",
            "\n",
            "í–„ë¦¿: (ìƒê°í•˜ë©°) í˜¸ë ˆì´ì‡¼ë¥¼ ë¯¿ìœ¼ë¼â€¦ ë„¤ ë§ëŒ€ë¡œ ë‚˜ëŠ” ê°€ë” ë„ˆë¬´ ìƒê°ë§Œ í•˜ê³  ì‹¤ì²œì„ ë¯¸ë£¬ë‹¤. ê·¸ëŸ¬ë‚˜ ì¦‰í¥ì ì¸ í–‰ë™ì€ ë˜ ë‹¤ë¥¸ ë¹„ê·¹ì„ ë¶ˆëŸ¬ì˜¤ì§€ ì•Šê² ëŠ”ê°€?\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: ë§ì•„, ì„±ê¸‰í•¨ì€ ì•ˆ ì¢‹ì•„. í•˜ì§€ë§Œ ë‘ë ¤ì›€ì—ë§Œ ìˆìœ¼ë©´ ì•„ë¬´ ì¼ë„ ë°”ë€Œì§€ ì•Šì•„. ê· í˜•ì´ í•„ìš”í•´: ê³„íší•˜ë˜, ê¸°íšŒê°€ ì™”ì„ ë• ë›°ì–´ë“¤ì–´. ê·¸ë¦¬ê³  ì‹¤ìˆ˜í•´ë„ ë°°ìš°ë©´ ë¼. íŒŒì›Œì—…ì€ ì‹¤íŒ¨ ë’¤ì— ë” ê°•í•´ì§„ ë„ˆì•¼!\n",
            "\n",
            "í–„ë¦¿: (ë¯¸ì†Œë¥¼ ì‚´ì§ ì§€ìœ¼ë©°) ë„¤ ë§ì€ ê°„ë‹¨í•˜ì§€ë§Œ ëª…ë£Œí•˜êµ¬ë‚˜. ìš©ê¸°ì™€ ì‹ ì¤‘í•¨, ì¹œêµ¬ì˜ ì¡°ì–¸ê³¼ ìê¸°ë°˜ì„±. ì´ëŸ° ê²ƒì´ì•¼ë§ë¡œ ë‚˜ì˜ ê°ˆë¦¼ê¸¸ì—ì„œ ê¸¸ì¡ì´ê°€ ë ì§€ ëª¨ë¥´ê² êµ¬ë‚˜.\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: ê·¸ëŸ¼ ì‹œì‘í•˜ì! ë§ì„¤ì´ë©´ ì ë“¤ì´ ë” í˜ì„ ì–»ì–´. (ì£¼ë¨¹ì„ ë¶ˆëˆ) ì¤€ë¹„ëì§€? ì‡ì¸ -ì–´-íƒ€ì„!\n",
            "\n",
            "í–„ë¦¿: (ê²€ì„ ì¡ìœ¼ë©°) ê·¸ëŸ¬ë©´, 'ì¡´ì¬í•˜ëŠëƒ, ì•„ë‹ˆëƒ'ì˜ ì§ˆë¬¸ì„ ë„˜ì–´ì„œì„œ, 'ë¬´ì—‡ì„ í•  ê²ƒì¸ê°€'ë¥¼ íƒí•˜ê² ë…¸ë¼. í•¨ê»˜ë¼ë©´, ë‘ë ¤ì›€ë„ ì´ê²¨ë‚¼ ìˆ˜ ìˆê² êµ¬ë‚˜.\n",
            "\n",
            "ìŠˆí¼ë§ˆë¦¬ì˜¤: ë°”ë¡œ ê·¸ê±°ì•¼! ê°€ì, ìŠ¤í…Œì´ì§€ í´ë¦¬ì–´í•˜ì!\n",
            "\n",
            "(ë‘ ì‚¬ëŒì€ ë‚˜ë€íˆ ê±¸ì–´ë‚˜ê°€ë©°, ì„±ì˜ ì–´ë‘  ì†ìœ¼ë¡œ ì‚¬ë¼ì§„ë‹¤. ë©€ë¦¬ì„œ ë²„ì„¯ í•˜ë‚˜ê°€ ë¹›ë‚œë‹¤.)\n",
            "\n",
            "ë‚˜ë ˆì´ì…˜(ì§§ê²Œ êµí›ˆ): ë•Œë¡œëŠ” ê¹Šì€ ì„±ì°°ì´ í•„ìš”í•˜ê³ , ë•Œë¡œëŠ” í•œ ë°œì§ì˜ ìš©ê¸°ê°€ í•„ìš”í•˜ë‹¤. ìƒê°ê³¼ í–‰ë™, ë‘˜ ë‹¤ ë†“ì¹˜ì§€ ì•ŠëŠ” ê²ƒì´ ì§„ì§œ ìŠ¹ë¦¬ë‹¤.\n"
          ]
        }
      ],
      "source": [
        "prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        ('system', 'ë‹¹ì‹ ì€ ì¬ë¯¸ìˆê³  êµí›ˆì ì¸ ì´ì•¼ê¸°ë¥¼ ì”ë‹ˆë‹¤.'),\n",
        "        ('user', '{A}ì™€ {B}ê°€ ë§Œë‚¬ì„ ë•Œì˜ ëŒ€í™”ë¥¼ ì¨ ì£¼ì„¸ìš”.')\n",
        "    ])\n",
        "chain = prompt | gpt_llm\n",
        "response = chain.invoke({'A':'í–„ë¦¿', 'B':'ìŠˆí¼ë§ˆë¦¬ì˜¤'})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a939c4b3",
      "metadata": {
        "id": "a939c4b3"
      },
      "source": [
        "### Prompt | LLM | Parser ì²´ì¸\n",
        "\n",
        "LCELì˜ ì²´ì¸ì—ëŠ” **íŒŒì„œ(Parser)** ë¥¼ ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.    \n",
        "íŒŒì„œëŠ” ì¶œë ¥ í˜•ì‹ì„ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab182142",
      "metadata": {
        "id": "ab182142"
      },
      "source": [
        "StrOutputParser : ì¶œë ¥ ê²°ê³¼ë¥¼ String í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9ced988",
      "metadata": {
        "id": "e9ced988"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "recipe_template=ChatPromptTemplate([\n",
        "    ('system','ë‹¹ì‹ ì€ ì „ì„¸ê³„ì˜ ì¡°ë¦¬ë²•ì„ ì•„ëŠ” ì‰í”„ì…ë‹ˆë‹¤.'),\n",
        "    ('user','''ì €ëŠ” ë‹¤ìŒì˜ ì¬ë£Œë¥¼ ì´ìš©í•œ í™˜ìƒì ì¸ ìš”ë¦¬ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤.\n",
        "\n",
        "ë ˆì‹œí”¼ì™€ í•¨ê»˜, ê³ ê°ì˜ ì‹œì„ ì„ ì‚¬ë¡œì¡ì„ ìˆ˜ ìˆëŠ” ì¶”ì²œì‚¬ë„ ì‘ì„±í•´ ì£¼ì„¸ìš”.\n",
        "---\n",
        "[ì¬ë£Œ]: {ingredient}''')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6ed960",
      "metadata": {
        "id": "5c6ed960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43066df-1c6f-4b64-9636-ee3c14d0cc4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì•„, ì´ ì–¼ë§ˆë‚˜ í¥ë¯¸ë¡œìš´ ì¡°í•©ì¸ê°€ìš”! ì—°ë‘ë¶€ì˜ ë¶€ë“œëŸ¬ì›€, ì—ë„ˆì§€ë°”ì˜ í™œë ¥, ê·¸ë¦¬ê³  ë°”ë‚˜ë‚˜ì˜ ë‹¬ì½¤í•¨. ì–¸ëœ» ë³´ë©´ ì–´ìš¸ë¦¬ì§€ ì•Šì„ ê²ƒ ê°™ì§€ë§Œ, ì €ì˜ ë¯¸ì‹ ê²½í—˜ìœ¼ë¡œ ë³¼ ë•Œ ì´ ì„¸ ê°€ì§€ ì¬ë£ŒëŠ” ë†€ë¼ìš´ ì‹œë„ˆì§€ë¥¼ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì €ëŠ” ì´ ì¬ë£Œë“¤ì„ í™œìš©í•˜ì—¬ ë™ì–‘ì˜ ê³ ìš”í•¨ê³¼ ì„œì–‘ì˜ í™œë ¥ì´ ì¡°í™”ëœ, ê±´ê°•í•˜ë©´ì„œë„ í™©í™€í•œ ë””ì €íŠ¸ ë˜ëŠ” ë¸ŒëŸ°ì¹˜ ë©”ë‰´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.\n",
            "\n",
            "---\n",
            "\n",
            "### **[ì¶”ì²œì‚¬] ê³ ê°ì˜ ì‹œì„ ì„ ì‚¬ë¡œì¡ì„ í•œ ë§ˆë””**\n",
            "\n",
            "\"ì¹œì• í•˜ëŠ” ë¯¸ì‹ê°€ ì—¬ëŸ¬ë¶„, ì˜¤ëŠ˜ ì €ëŠ” ì—¬ëŸ¬ë¶„ì˜ ë¯¸ê°ê³¼ ì˜í˜¼ì„ ë™ì‹œì— ë§Œì¡±ì‹œí‚¬ íŠ¹ë³„í•œ ìš”ë¦¬ë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. 'ì—°ë‘ë¶€, ì—ë„ˆì§€ë°”, ë°”ë‚˜ë‚˜'ë¼ëŠ” ë‹¤ì†Œ íŒŒê²©ì ì¸ ì¡°í•©ì—ì„œ íƒ„ìƒí•œ **'ì   í“¨ì „ ë”œë¼ì´íŠ¸: ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œì™€ ì—ë„ˆì§€ í¬ëŸ¼ë¸”'**ì€ ë‹¨ìˆœí•œ ìŒì‹ì„ ë„˜ì–´ì„  í•˜ë‚˜ì˜ ê²½í—˜ì…ë‹ˆë‹¤.\n",
            "\n",
            "ì…ì•ˆì—ì„œ ì‚¬ë¥´ë¥´ ë…¹ì•„ë‚´ë¦¬ëŠ” ì—°ë‘ë¶€ì˜ ë¹„ë‹¨ê²° ê°™ì€ ë¶€ë“œëŸ¬ì›€ê³¼ ë°”ë‚˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ë‹¬ì½¤í•¨ì´ ë§Œë‚˜ êµ¬ë¦„ì²˜ëŸ¼ ê°€ë²¼ìš´ ë² ì´ìŠ¤ë¥¼ ì´ë£¨ê³ , ê·¸ ìœ„ë¥¼ ë°”ì‚­í•˜ê³  ê³ ì†Œí•œ ì—ë„ˆì§€ë°” í¬ëŸ¼ë¸”ì´ í™”ë ¤í•˜ê²Œ ì¥ì‹í•©ë‹ˆë‹¤. í•œ ìŠ¤í‘¼ ë– ë¨¹ëŠ” ìˆœê°„, ë™ì–‘ì˜ ê³ ìš”í•œ ëª…ìƒê³¼ ì„œì–‘ì˜ í™œê¸°ì°¬ ì—ë„ˆì§€ê°€ ì ˆë¬˜í•˜ê²Œ ì–´ìš°ëŸ¬ì§€ëŠ” ë§›ì˜ í–¥ì—°ì„ ëŠë¼ì‹¤ ê²ë‹ˆë‹¤.\n",
            "\n",
            "ì´ ìš”ë¦¬ëŠ” ê±´ê°•ì„ ìƒê°í•˜ëŠ” ë‹¹ì‹ ì—ê²ŒëŠ” ì£„ì±…ê° ì—†ëŠ” ë‹¬ì½¤í•¨ì„, ìƒˆë¡œìš´ ë¯¸ì‹ ê²½í—˜ì„ ì¶”êµ¬í•˜ëŠ” ë‹¹ì‹ ì—ê²ŒëŠ” ìŠì„ ìˆ˜ ì—†ëŠ” ê°ë™ì„ ì„ ì‚¬í•  ê²ƒì…ë‹ˆë‹¤. ì§€ê¸ˆ, ì´ íŠ¹ë³„í•œ ë§›ì˜ ì—¬ì •ì— ë™ì°¸í•˜ì—¬ ë‹¹ì‹ ì˜ í•˜ë£¨ë¥¼ ë”ìš± ë¹›ë‚´ë³´ì„¸ìš”!\"\n",
            "\n",
            "---\n",
            "\n",
            "### **[ë ˆì‹œí”¼] ì   í“¨ì „ ë”œë¼ì´íŠ¸: ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œì™€ ì—ë„ˆì§€ í¬ëŸ¼ë¸”**\n",
            "\n",
            "ì´ ìš”ë¦¬ëŠ” ì—°ë‘ë¶€ì˜ ë¶€ë“œëŸ¬ì›€ì„ ê·¹ëŒ€í™”í•˜ê³ , ë°”ë‚˜ë‚˜ì˜ ë‹¬ì½¤í•¨ìœ¼ë¡œ í’ë¯¸ë¥¼ ë”í•˜ë©°, ì—ë„ˆì§€ë°”ì˜ ì‹ê°ê³¼ ì˜ì–‘ì„ ë”í•´ ê· í˜• ì¡íŒ ë§›ê³¼ ê±´ê°•ì„ ì„ ì‚¬í•©ë‹ˆë‹¤.\n",
            "\n",
            "**ìš”ë¦¬ëª…:** ì   í“¨ì „ ë”œë¼ì´íŠ¸: ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œì™€ ì—ë„ˆì§€ í¬ëŸ¼ë¸” (Zen Fusion Delight: Tofu & Banana Cloud with Energy Crumble)\n",
            "\n",
            "**ë‚œì´ë„:** â˜…â˜†â˜†â˜†â˜† (ë§¤ìš° ì‰¬ì›€)\n",
            "**ì¡°ë¦¬ ì‹œê°„:** 15ë¶„ (ëƒ‰ì¥ ì‹œê°„ ì œì™¸)\n",
            "**ë¶„ëŸ‰:** 2ì¸ë¶„\n",
            "\n",
            "**[ì¬ë£Œ]**\n",
            "\n",
            "*   **ì—°ë‘ë¶€:** 1íŒ© (ì•½ 300g), ë¬¼ê¸° ì œê±°\n",
            "*   **ë°”ë‚˜ë‚˜:** 2ê°œ, ì˜ ìµì€ ê²ƒ (í¬ê¸°ì— ë”°ë¼ ì¡°ì ˆ)\n",
            "*   **ì—ë„ˆì§€ë°”:** 1ê°œ (ê²¬ê³¼ë¥˜, ì”¨ì•—ë¥˜ê°€ í¬í•¨ëœ ê²ƒì´ ì‹ê°ì— ì¢‹ìŠµë‹ˆë‹¤)\n",
            "*   **ë©”ì´í”Œ ì‹œëŸ½ ë˜ëŠ” ê¿€:** 1~2í°ìˆ  (ê¸°í˜¸ì— ë”°ë¼ ì¡°ì ˆ)\n",
            "*   **ë°”ë‹ë¼ ìµìŠ¤íŠ¸ë™:** 1/2 ì‘ì€ìˆ  (ì„ íƒ ì‚¬í•­)\n",
            "*   **ì†Œê¸ˆ:** ì•„ì£¼ ì•½ê°„ (ë‹¨ë§›ì„ ëŒì–´ì˜¬ë¦¬ëŠ” ì—­í• )\n",
            "*   **ì¥ì‹ìš© (ì„ íƒ ì‚¬í•­):** ì‹ ì„ í•œ ë¯¼íŠ¸ ì, ë°”ë‚˜ë‚˜ ìŠ¬ë¼ì´ìŠ¤, ì½”ì½”ì•„ íŒŒìš°ë” ì•½ê°„\n",
            "\n",
            "**[ì¡°ë¦¬ë²•]**\n",
            "\n",
            "1.  **ì—ë„ˆì§€ë°” í¬ëŸ¼ë¸” ì¤€ë¹„:**\n",
            "    *   ì—ë„ˆì§€ë°”ë¥¼ ë¹„ë‹ë´‰ì§€ì— ë„£ê³  ë°€ëŒ€ë‚˜ ì†ìœ¼ë¡œ ì˜ê²Œ ë¶€ìˆ´ í¬ëŸ¼ë¸” í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤.\n",
            "    *   (ì„ íƒ ì‚¬í•­) ë§ˆë¥¸ íŒ¬ì— ì•½ë¶ˆë¡œ 1~2ë¶„ê°„ ì‚´ì§ ë³¶ì•„ì£¼ë©´ ê²¬ê³¼ë¥˜ì˜ ê³ ì†Œí•œ í–¥ì´ ì‚´ì•„ë‚˜ê³  ë”ìš± ë°”ì‚­í•´ì§‘ë‹ˆë‹¤. ì‹í˜€ë‘¡ë‹ˆë‹¤.\n",
            "\n",
            "2.  **ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œ ë² ì´ìŠ¤ ë§Œë“¤ê¸°:**\n",
            "    *   ì—°ë‘ë¶€ëŠ” ì²´ì— ë°­ì³ ë¬¼ê¸°ë¥¼ ì¶©ë¶„íˆ ì œê±°í•©ë‹ˆë‹¤. (í‚¤ì¹œíƒ€ì›”ë¡œ ê°€ë³ê²Œ ëˆŒëŸ¬ì£¼ë©´ ì¢‹ìŠµë‹ˆë‹¤.)\n",
            "    *   ë¯¹ì„œê¸°ì— ë¬¼ê¸°ë¥¼ ì œê±°í•œ ì—°ë‘ë¶€, ì˜ ìµì€ ë°”ë‚˜ë‚˜, ë©”ì´í”Œ ì‹œëŸ½(ë˜ëŠ” ê¿€), ë°”ë‹ë¼ ìµìŠ¤íŠ¸ë™(ì„ íƒ ì‚¬í•­), ì†Œê¸ˆ ì•„ì£¼ ì•½ê°„ì„ ë„£ìŠµë‹ˆë‹¤.\n",
            "    *   ëª¨ë“  ì¬ë£Œê°€ ë¶€ë“œëŸ¬ìš´ í¬ë¦¼ì²˜ëŸ¼ ë  ë•Œê¹Œì§€ ê³±ê²Œ ê°ˆì•„ì¤ë‹ˆë‹¤. ì¤‘ê°„ì— ë©ˆì¶°ì„œ ë²½ì— ë¶™ì€ ì¬ë£Œë“¤ì„ ê¸ì–´ë‚´ê³  ë‹¤ì‹œ ê°ˆì•„ì£¼ì„¸ìš”.\n",
            "    *   ë§›ì„ ë³´ê³  ë‹¨ë§›ì´ ë¶€ì¡±í•˜ë©´ ë©”ì´í”Œ ì‹œëŸ½ì„ ë” ì¶”ê°€í•©ë‹ˆë‹¤. ì§ˆê°ì´ ë„ˆë¬´ ë˜ì§í•˜ë©´ ì‹ë¬¼ì„± ìš°ìœ (ì•„ëª¬ë“œìœ , ë‘ìœ  ë“±)ë¥¼ 1~2í°ìˆ  ë„£ì–´ ë†ë„ë¥¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "3.  **ë‹´ì•„ë‚´ê¸°:**\n",
            "    *   íˆ¬ëª…í•œ ìœ ë¦¬ì»µì´ë‚˜ ë””ì €íŠ¸ ë³¼ì— ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œ ë² ì´ìŠ¤ë¥¼ ì ˆë°˜ ì •ë„ ì±„ì›ë‹ˆë‹¤.\n",
            "    *   ê·¸ ìœ„ì— ì¤€ë¹„í•´ë‘” ì—ë„ˆì§€ë°” í¬ëŸ¼ë¸”ì„ ë„‰ë„‰í•˜ê²Œ ë¿Œë ¤ì¤ë‹ˆë‹¤.\n",
            "    *   ë‹¤ì‹œ ë‘ë¶€ ë°”ë‚˜ë‚˜ í´ë¼ìš°ë“œ ë² ì´ìŠ¤ë¥¼ ì±„ìš°ê³ , ë§¨ ìœ„ì— ì—ë„ˆì§€ë°” í¬ëŸ¼ë¸”ì„ í’ì„±í•˜ê²Œ ì˜¬ë ¤ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.\n",
            "\n",
            "4.  **ëƒ‰ì¥ ë° ì¥ì‹:**\n",
            "    *   ì™„ì„±ëœ ë””ì €íŠ¸ë¥¼ ëƒ‰ì¥ê³ ì— ë„£ì–´ 30ë¶„ ì´ìƒ ì°¨ê°‘ê²Œ ì‹íˆë©´ ë”ìš± ë§›ìˆìŠµë‹ˆë‹¤.\n",
            "    *   ì„œë¹™ ì§ì „ì— ì‹ ì„ í•œ ë°”ë‚˜ë‚˜ ìŠ¬ë¼ì´ìŠ¤, ë¯¼íŠ¸ ììœ¼ë¡œ ì¥ì‹í•˜ê±°ë‚˜ ì½”ì½”ì•„ íŒŒìš°ë”ë¥¼ ì‚´ì§ ë¿Œë ¤ì£¼ë©´ ì‹œê°ì ì¸ ì•„ë¦„ë‹¤ì›€ì„ ë”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "**[ì‰í”„ì˜ íŒ]**\n",
            "\n",
            "*   **ë°”ë‚˜ë‚˜ ì„ íƒ:** ë°”ë‚˜ë‚˜ëŠ” ì˜ ìµì–´ ê²€ì€ ë°˜ì ì´ ìƒê¸´ ê²ƒì´ ë‹¹ë„ê°€ ë†’ì•„ ë”ìš± ë§›ìˆìŠµë‹ˆë‹¤.\n",
            "*   **ì—ë„ˆì§€ë°” í™œìš©:** ì´ˆì½œë¦¿ ì¹©ì´ ë“¤ì–´ê°„ ì—ë„ˆì§€ë°”ë¥¼ ì‚¬ìš©í•˜ë©´ ë‹¬ì½¤í•¨ì´ ë°°ê°€ë˜ê³ , ê²¬ê³¼ë¥˜ì™€ ì”¨ì•—ì´ í’ë¶€í•œ ì—ë„ˆì§€ë°”ëŠ” ê³ ì†Œí•¨ê³¼ ì‹ê°ì„ ë”í•´ì¤ë‹ˆë‹¤.\n",
            "*   **ë³€í˜•:** ê¸°í˜¸ì— ë”°ë¼ ì‹œë‚˜ëª¬ íŒŒìš°ë”ë‚˜ ì¹´ì¹´ì˜¤ë‹™ìŠ¤ë¥¼ ì¶”ê°€í•˜ì—¬ í’ë¯¸ë¥¼ ë”ìš± ë‹¤ì±„ë¡­ê²Œ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "*   **ë³´ê´€:** ë‚¨ì€ ë””ì €íŠ¸ëŠ” ë°€í ìš©ê¸°ì— ë‹´ì•„ ëƒ‰ì¥ ë³´ê´€í•˜ê³ , ê°€ê¸‰ì  ë¹¨ë¦¬ ë“œì‹œëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
            "\n",
            "ì´ ìš”ë¦¬ëŠ” ì•„ì¹¨ ì‹ì‚¬ ëŒ€ìš©ìœ¼ë¡œë„ í›Œë¥­í•˜ê³ , ê±´ê°•í•œ ê°„ì‹ì´ë‚˜ ê°€ë²¼ìš´ ë””ì €íŠ¸ë¡œë„ ì†ìƒ‰ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì‹íƒì— ìƒˆë¡œìš´ í™œë ¥ê³¼ ì¦ê±°ì›€ì„ ì„ ì‚¬í•  ê²ƒì…ë‹ˆë‹¤!\n"
          ]
        }
      ],
      "source": [
        "recipe_chain = recipe_template | gemini_llm | parser\n",
        "response = recipe_chain.invoke({'ingredient':'ì—°ë‘ë¶€, ì—ë„ˆì§€ë°”, ë°”ë‚˜ë‚˜'})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b833846a",
      "metadata": {
        "id": "b833846a"
      },
      "source": [
        "## [ì‹¤ìŠµ] ê²€ìƒ‰ ê²°ê³¼ ë¶„ë¥˜ ì²´ì¸ ë§Œë“¤ê¸°\n",
        "\n",
        "ë‹¤ìŒì€ Arxivì˜ ìµœì‹  ë…¼ë¬¸ì„ ê²€ìƒ‰í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.   \n",
        "í•´ë‹¹ ë…¼ë¬¸ë“¤ì´ LLM ê´€ë ¨ ë…¼ë¬¸ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ì²´ì¸ì„ ë§Œë“¤ê³ , ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì„¸ìš”.   \n",
        "**í•¨ìˆ˜ì˜ ê²°ê³¼ë¬¼ë¡œ ë‹¤ì–‘í•œ ê°’ë“¤ì´ ìˆìœ¼ë¯€ë¡œ, ê°’ë“¤ ì¤‘ í•„ìš”í•œ ê°’ë§Œ ì…ë ¥ë°›ëŠ” ì²´ì¸ì„ ë§Œë“¤ê³  ì‹¤í–‰í•˜ì„¸ìš”.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de89b55b",
      "metadata": {
        "id": "de89b55b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a755e0-ad95-44aa-9a29-91094b10650b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7d8e8c915100>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7d8e8cc6e510>, root_client=<openai.OpenAI object at 0x7d8e8ca35340>, root_async_client=<openai.AsyncOpenAI object at 0x7d8e8c9141d0>, model_name='gpt-5-mini', model_kwargs={}, openai_api_key=SecretStr('**********'), stream_usage=True, reasoning_effort='low')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# gpt llm ì‚¬ìš©í•˜ê¸°\n",
        "gpt_llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d80cbe",
      "metadata": {
        "id": "14d80cbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c09456-17bf-4bbb-b43c-5481e6129d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "=== ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìµœê·¼ ë…¼ë¬¸ ===\n",
            "ì´ 5ê°œì˜ ë…¼ë¬¸ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n",
            "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM\n",
            "Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery\n",
            "LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal\n",
            "A merger within a merger: Chandra pinpoints the short GRB 230906A in a peculiar environment\n",
            "BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models\n",
            "\n",
            "\n",
            "=== ê²€ìƒ‰ì–´ `Security` ë¡œ ê²€ìƒ‰í•œ ìµœê·¼ ë…¼ë¬¸ ===\n",
            "ì´ 5ê°œì˜ ë…¼ë¬¸ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\n",
            "Sound Clouds: Exploring ambient intelligence in public spaces to elicit deep human experience of awe, wonder, and beauty\n",
            "On Universality of Deep Equivariant Networks\n",
            "Towards Proactive Defense Against Cyber Cognitive Attacks\n",
            "Ambusher: Exploring the Security of Distributed SDN Controllers Through Protocol State Fuzzing\n",
            "Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL\n"
          ]
        }
      ],
      "source": [
        "import arxiv\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "\n",
        "def get_arxiv_papers(query: Optional[str] = None, N: int = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    arXivì—ì„œ ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    query : str, optional\n",
        "        ê²€ìƒ‰ì–´\n",
        "    N : int, default=10\n",
        "        ê°€ì ¸ì˜¬ ë…¼ë¬¸ ê°œìˆ˜\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    List[Dict] : ë…¼ë¬¸ ì •ë³´ë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    search_query = query\n",
        "\n",
        "    # arxiv í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # ê²€ìƒ‰ ê°ì²´ ìƒì„±\n",
        "    search = arxiv.Search(\n",
        "        query=search_query,\n",
        "        max_results=N,\n",
        "        sort_by=arxiv.SortCriterion.SubmittedDate,  # ì œì¶œì¼ ê¸°ì¤€ ì •ë ¬\n",
        "        sort_order=arxiv.SortOrder.Descending  # ìµœì‹ ìˆœ\n",
        "    )\n",
        "\n",
        "    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
        "    papers = []\n",
        "\n",
        "    # ê²€ìƒ‰ ì‹¤í–‰ (ìƒˆë¡œìš´ API ì‚¬ìš©)\n",
        "    for result in client.results(search):\n",
        "        paper_info = {\n",
        "            'title': result.title,\n",
        "            'authors': [author.name for author in result.authors],\n",
        "            'summary': result.summary,\n",
        "            'published': result.published.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'updated': result.updated.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "            'arxiv_id': result.entry_id.split('/')[-1],  # arXiv ID ì¶”ì¶œ\n",
        "            'pdf_url': result.pdf_url,\n",
        "            'categories': result.categories,\n",
        "            'primary_category': result.primary_category,\n",
        "            'comment': result.comment,\n",
        "            'journal_ref': result.journal_ref\n",
        "        }\n",
        "        papers.append(paper_info)\n",
        "\n",
        "    return papers\n",
        "\n",
        "def get_recent_papers_all_categories(N: int = 10) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ìµœê·¼ ë…¼ë¬¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
        "    (ë” ì•ˆì •ì ì¸ ë°©ë²•)\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    N : int, default=10\n",
        "        ê°€ì ¸ì˜¬ ë…¼ë¬¸ ê°œìˆ˜\n",
        "    \"\"\"\n",
        "\n",
        "    return get_arxiv_papers(query=\"the\", N=N)\n",
        "\n",
        "\n",
        "print(\"\\n\\n=== ëª¨ë“  ì¹´í…Œê³ ë¦¬ ìµœê·¼ ë…¼ë¬¸ ===\")\n",
        "all_papers = get_recent_papers_all_categories(N=5)\n",
        "print(f\"ì´ {len(all_papers)}ê°œì˜ ë…¼ë¬¸ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\")\n",
        "print('\\n'.join([paper['title'] for paper in all_papers]))\n",
        "\n",
        "query = 'Security'\n",
        "print(f\"\\n\\n=== ê²€ìƒ‰ì–´ `{query}` ë¡œ ê²€ìƒ‰í•œ ìµœê·¼ ë…¼ë¬¸ ===\")\n",
        "security_papers = get_arxiv_papers(query=query, N=5)\n",
        "print(f\"ì´ {len(security_papers)}ê°œì˜ ë…¼ë¬¸ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.\")\n",
        "print('\\n'.join([paper['title'] for paper in security_papers]))\n",
        "\n",
        "# # ì„ì˜ì˜ ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰\n",
        "# query = 'ê²€ìƒ‰ì–´'\n",
        "# papers = get_arxiv_papers(query='*', N=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpt_llm.invoke(\"\"\"\n",
        "ì£¼ì–´ì§„ ë…¼ë¬¸ì— ëŒ€í•´, í•´ë‹¹ ë…¼ë¬¸ì´ LLM ê´€ë ¨ì¸ì§€ ë¶„ë¥˜í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì¤˜.\n",
        "ë§¤ê°œë³€ìˆ˜ 2ê°œ: title, summaryë¥¼ format templateë¡œ ì…ë ¥ë°›ë„ë¡ í•˜ëŠ” ë¬¸ìì—´ í˜•íƒœë¡œ ì¶œë ¥\n",
        "\"\"\").content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzNG1Oakoh6F",
        "outputId": "b211be9d-9919-4aed-bbe3-582e27db6309"
      },
      "id": "QzNG1Oakoh6F",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë‹¤ìŒ ë¬¸ìì—´ì„ ê·¸ëŒ€ë¡œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©í•˜ì„¸ìš”. {title} ë° {summary} ìë¦¬ì— ê°ê° ë…¼ë¬¸ ì œëª©ê³¼ ìš”ì•½ì„ ë„£ì–´ í‰ê°€í•©ë‹ˆë‹¤.\n",
            "\n",
            "\"ë‹¤ìŒì€ ë…¼ë¬¸ ì •ë³´ì…ë‹ˆë‹¤.\n",
            "Title: {title}\n",
            "Summary: {summary}\n",
            "\n",
            "ì§€ì‹œì‚¬í•­:\n",
            "1) ì´ ë…¼ë¬¸ì´ LLM(ëŒ€í˜•ì–¸ì–´ëª¨ë¸, transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ìƒì„±Â·ì´í•´ ëª¨ë¸)ê³¼ 'ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ”ì§€' ë¶„ë¥˜í•˜ì‹œì˜¤. ì§ì ‘ ê´€ë ¨ì˜ ì˜ˆ: ëª¨ë¸ ì„¤ê³„(architecture), í•™ìŠµë°©ë²•(finetuning, pretraining, RLHF ë“±), ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼, LLM ì‘ìš©(ì±—ë´‡Â·ëŒ€í™”ì‹œìŠ¤í…œ ë“±), LLM íŠ¹ìœ ì˜ ë¬¸ì œ(í¸í–¥, ì¶”ë¡ , ì•ˆì „ì„± ë“±)ë¥¼ ì£¼ì œë¡œ ë‹¤ë£° ë•Œ 'Yes'. ë°˜ëŒ€ë¡œ ìì—°ì–´ì²˜ë¦¬ ì¼ë°˜, ë¹„ì–¸ì–´ëª¨ë¸ ML ì—°êµ¬, ì†Œê·œëª¨ ëª¨ë¸Â·ë¹„ì–¸ì–´ ìƒì„± ëª¨ë¸ë§Œ ë‹¤ë£¬ë‹¤ë©´ 'No'. ê´€ë ¨ ê°€ëŠ¥ì„±ì€ ìˆìœ¼ë‚˜ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ 'Maybe'.\n",
            "2) íŒë‹¨ ê·¼ê±°ë¥¼ 1~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì‘ì„±í•˜ì‹œì˜¤(ë…¼ë¬¸ì—ì„œ ì–´ë–¤ ë¬¸êµ¬Â·ì£¼ì œê°€ LLM ê´€ë ¨ íŒë‹¨ì„ ì´ëŒì—ˆëŠ”ì§€ ëª…ì‹œ).\n",
            "3) ì¶”ê°€ë¡œ ê´€ë ¨ í‚¤ì›Œë“œ(ì˜ˆ: \"transformer\", \"pretraining\", \"LLM\", \"chatbot\", \"RLHF\", \"few-shot\", \"in-context learning\", \"tokenization\")ë¥¼ ìµœëŒ€ 5ê°œê¹Œì§€ ì¶”ì¶œí•˜ì—¬ ì œì‹œí•˜ì‹œì˜¤.\n",
            "4) ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¥´ì‹œì˜¤.\n",
            "\n",
            "ì¶œë ¥ JSON ì˜ˆì‹œ:\n",
            "{\n",
            "  \"is_llm\": \"Yes\" | \"No\" | \"Maybe\",\n",
            "  \"confidence\": 0.00-1.00,            // ì†Œìˆ˜ë¡œ 0~1 ì‚¬ì´\n",
            "  \"reason\": \"ê·¼ê±° 1~3ë¬¸ì¥\",\n",
            "  \"keywords\": [\"í‚¤ì›Œë“œ1\",\"í‚¤ì›Œë“œ2\",...]\n",
            "}\n",
            "\n",
            "ì œì•½:\n",
            "- confidenceëŠ” íŒë‹¨ì˜ í™•ì‹¤ì„±ì„ 0~1 ì‚¬ì´ ì†Œìˆ˜ë¡œ í‘œì‹œ(ì˜ˆ: 0.85).\n",
            "- reasonì€ 30~150ì ë‚´ì™¸ë¡œ ê°„ê²°íˆ ì‘ì„±.\n",
            "- keywordsëŠ” ìµœëŒ€ 5ê°œ, ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´([])ë¡œ ë°˜í™˜.\n",
            "\n",
            "ì§€ê¸ˆ ë°”ë¡œ íŒë‹¨í•˜ë¼.\"\n",
            "\n",
            "(í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ì˜ˆ: ìœ„ ë¬¸ìì—´ì—ì„œ {title}ê³¼ {summary}ë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë°”ê¿” LLMì— ì…ë ¥í•˜ë©´ ë©ë‹ˆë‹¤.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f924d742",
      "metadata": {
        "id": "f924d742"
      },
      "outputs": [],
      "source": [
        "# Prompt, LLM, Parser\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "parser = StrOutputParser()\n",
        "\n",
        "prompt = ChatPromptTemplate([\n",
        "        ('system' , '''\n",
        "        Arxivì— ê²Œì¬ëœ ë…¼ë¬¸ ì •ë³´ë¥¼ ë³´ê³ \n",
        "        í•´ë‹¹ ë…¼ë¬¸ì´ 'LLM ê´€ë ¨(ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ ê´€ë ¨)'ì¸ì§€ ì—¬ë¶€ë¥¼ íŒë³„í•˜ì‹œì˜¤.\n",
        "\n",
        "        ì§€ì‹œì‚¬í•­:\n",
        "        1) ì´ ë…¼ë¬¸ì´ LLM(ëŒ€í˜•ì–¸ì–´ëª¨ë¸, transformer ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ìƒì„±Â·ì´í•´ ëª¨ë¸)ê³¼ 'ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ ìˆëŠ”ì§€' ë¶„ë¥˜í•˜ì‹œì˜¤. ì§ì ‘ ê´€ë ¨ì˜ ì˜ˆ: ëª¨ë¸ ì„¤ê³„(architecture), í•™ìŠµë°©ë²•(finetuning, pretraining, RLHF ë“±), ëŒ€ê·œëª¨ ì–¸ì–´ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼, LLM ì‘ìš©(ì±—ë´‡Â·ëŒ€í™”ì‹œìŠ¤í…œ ë“±), LLM íŠ¹ìœ ì˜ ë¬¸ì œ(í¸í–¥, ì¶”ë¡ , ì•ˆì „ì„± ë“±)ë¥¼ ì£¼ì œë¡œ ë‹¤ë£° ë•Œ 'Yes'. ë°˜ëŒ€ë¡œ ìì—°ì–´ì²˜ë¦¬ ì¼ë°˜, ë¹„ì–¸ì–´ëª¨ë¸ ML ì—°êµ¬, ì†Œê·œëª¨ ëª¨ë¸Â·ë¹„ì–¸ì–´ ìƒì„± ëª¨ë¸ë§Œ ë‹¤ë£¬ë‹¤ë©´ 'No'. ê´€ë ¨ ê°€ëŠ¥ì„±ì€ ìˆìœ¼ë‚˜ ëª…í™•í•˜ì§€ ì•Šìœ¼ë©´ 'Maybe'.\n",
        "        2) íŒë‹¨ ê·¼ê±°ë¥¼ 1~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°íˆ ì‘ì„±í•˜ì‹œì˜¤(ë…¼ë¬¸ì—ì„œ ì–´ë–¤ ë¬¸êµ¬Â·ì£¼ì œê°€ LLM ê´€ë ¨ íŒë‹¨ì„ ì´ëŒì—ˆëŠ”ì§€ ëª…ì‹œ).\n",
        "        3) ì¶”ê°€ë¡œ ê´€ë ¨ í‚¤ì›Œë“œ(ì˜ˆ: \"transformer\", \"pretraining\", \"LLM\", \"chatbot\", \"RLHF\", \"few-shot\", \"in-context learning\", \"tokenization\")ë¥¼ ìµœëŒ€ 5ê°œê¹Œì§€ ì¶”ì¶œí•˜ì—¬ ì œì‹œí•˜ì‹œì˜¤.\n",
        "        4) ì¶œë ¥ í˜•ì‹ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì„ ë”°ë¥´ì‹œì˜¤.\n",
        "\n",
        "        ì¶œë ¥ì˜ˆì‹œëŠ” ë°˜ë“œì‹œ ì´ í¬ë§·ìœ¼ë¡œ ì œê³µ: json ì´ ì•„ë‹Œ í…ìŠ¤íŠ¸\n",
        "\n",
        "        1) is_llm : Yes | No | Maybe,\n",
        "        2) confidence : 0.00-1.00,            // ì†Œìˆ˜ë¡œ 0~1 ì‚¬ì´\n",
        "        3) reason : ê·¼ê±° 1~3ë¬¸ì¥,\n",
        "        4) keywords : [í‚¤ì›Œë“œ1,í‚¤ì›Œë“œ2,...]\n",
        "\n",
        "        ì œì•½:\n",
        "        - confidenceëŠ” íŒë‹¨ì˜ í™•ì‹¤ì„±ì„ 0~1 ì‚¬ì´ ì†Œìˆ˜ë¡œ í‘œì‹œ(ì˜ˆ: 0.85).\n",
        "        - reasonì€ 30~150ì ë‚´ì™¸ë¡œ ê°„ê²°íˆ ì‘ì„±.\n",
        "        - keywordsëŠ” ìµœëŒ€ 5ê°œ, ì—†ìœ¼ë©´ ë¹ˆ ë°°ì—´([])ë¡œ ë°˜í™˜.\n",
        "        '''\n",
        "        ),\n",
        "        ('user' , '''\n",
        "        ì…ë ¥:\n",
        "        - Title: {title}\n",
        "        - Summary: {summary}\n",
        "        '''\n",
        "        )\n",
        "    ])\n",
        "classify_chain = prompt | gpt_llm | parser\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = classify_chain.invoke(all_papers[0])\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHMGvE0prXPf",
        "outputId": "0edb51d4-601c-4e1d-808d-285a826798c3"
      },
      "id": "RHMGvE0prXPf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) is_llm : Yes,\n",
            "2) confidence : 0.95,\n",
            "3) reason : ë…¼ë¬¸ì€ \"omni-modal LLM\"ì„ ëª©í‘œë¡œ ëª¨ë¸ ì•„í‚¤í…ì²˜(OmniAlignNet, Temporal Embedding ë“±), ë°ì´í„°Â·í•™ìŠµ í† í° ìˆ˜ ë° LLM ì„±ëŠ¥ ë¹„êµë¥¼ ë‹¤ë£¨ë¯€ë¡œ ëŒ€í˜• ì–¸ì–´ëª¨ë¸ ê´€ë ¨ ì—°êµ¬ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.,\n",
            "4) keywords : [\"omni-modal\",\"LLM\",\"architecture\",\"pretraining\",\"multimodal\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da2adac6",
      "metadata": {
        "id": "da2adac6"
      },
      "outputs": [],
      "source": [
        "\n",
        "results = classify_chain.batch(all_papers)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0410a04c",
      "metadata": {
        "id": "0410a04c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "12c4d1c5-56db-4f07-ffae-18f414a07704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì¢‹ìŠµë‹ˆë‹¤ â€” ì „ì²´ êµ¬ì¡°ë¥¼ í•œëˆˆì— ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë‹¨ê³„ë³„ë¡œ ì •ë¦¬í•˜ê³ , ê° ë‹¨ê³„ì—ì„œ ê³ ë ¤í•  ì (ë³´ì•ˆ/ì •í™•ì„±/í¬ë§·íŒ… ë“±)ê³¼ êµ¬í˜„ ë°©ë²•(ì˜ˆì‹œ SQL, í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, ë„êµ¬ ì¶”ì²œ)ê¹Œì§€ ì œì•ˆí•˜ê² ìŠµë‹ˆë‹¤. ì˜ˆì‹œëŠ” ìŒì‹/ë ˆì‹œí”¼ DB(ìŒì‹ì¢…ë¥˜, ì¬ë£Œ, ë ˆì‹œí”¼ í…Œì´ë¸” ë“±)ë¥¼ ê°€ì •í•˜ì—¬ \"ê³„ë€ë§ì´ ë§Œë“œëŠ” ë°©ë²•\" ì§ˆë¬¸ì— ëŒ€í•´ LLMì´ ì–´ë–»ê²Œ ì ‘ê·¼í•´ì„œ íŠ¹ì • í¬ë§·ìœ¼ë¡œ ë‹µë³€ì„ ë§Œë“œëŠ”ì§€ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n",
            "\n",
            "1) ì „ì²´ ì•„í‚¤í…ì²˜(íë¦„ ê°œìš”)\n",
            "- ì‚¬ìš©ì â†’ í”„ë¡ íŠ¸ì—”ë“œ(ì§ˆë¬¸ ì…ë ¥)\n",
            "- Backend API(ì§ˆë¬¸ ì²˜ë¦¬)\n",
            "  - 1) ì§ˆì˜ í•´ì„ / ì˜ë„ ì¶”ì¶œ (LLM í˜¹ì€ ê·œì¹™ ê¸°ë°˜)\n",
            "  - 2) DB ì ‘ê·¼ ì „ëµ ê²°ì • (ì§ì ‘ SQL ìƒì„± ì‹¤í–‰ / ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ í…œí”Œë¦¿ ì‚¬ìš© / ê²€ìƒ‰ ê¸°ë°˜ ë˜í•‘)\n",
            "  - 3) DB ì¿¼ë¦¬ ì‹¤í–‰ (ORM ë˜ëŠ” Prepared Statement)\n",
            "  - 4) ê²°ê³¼ ì •ê·œí™” ë° êµ¬ì¡°í™”\n",
            "  - 5) LLMì— ê²°ê³¼ + ì‘ë‹µ í¬ë§· ì§€ì¹¨ ì „ë‹¬ â†’ ìµœì¢… ìì—°ì–´/ì •í˜• ì‘ë‹µ ìƒì„±\n",
            "- ì‚¬ìš©ìì—ê²Œ ì‘ë‹µ ë°˜í™˜\n",
            "\n",
            "ë‘ ê°€ì§€ ì£¼ìš” íŒ¨í„´:\n",
            "- íŒ¨í„´ A (LLMì´ SQL ìƒì„±): ì‚¬ìš©ìì˜ ìì—°ì–´ë¥¼ LLMì— ì£¼ì–´ SQLì„ ìƒì„±í•˜ê²Œ í•˜ê³ , ë°±ì—”ë“œê°€ ì‹¤í–‰ â†’ ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì—ê²Œ ì£¼ì–´ ì •í•´ì§„ ì¶œë ¥ í¬ë§·ìœ¼ë¡œ ë³€í™˜.\n",
            "- íŒ¨í„´ B (í…œí”Œë¦¿/ë§¤í•‘): ë¯¸ë¦¬ ì •ì˜ëœ ì¿¼ë¦¬ í…œí”Œë¦¿/ ë§¤í•‘ì„ ì‚¬ìš©í•˜ì—¬ ìì—°ì–´ë¥¼ íŒŒì‹±í•´ ì ì ˆí•œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰ â†’ LLMì€ ê²°ê³¼ë¥¼ í¬ë§·íŒ…/ë¶€ì—° ì„¤ëª…ë§Œ ë‹´ë‹¹.\n",
            "\n",
            "2) ì–´ë–¤ ë°©ì‹ì„ ì“¸ì§€ ê²°ì •í•˜ëŠ” ê¸°ì¤€\n",
            "- ì •í™•ì„±/ë³´ì•ˆ ìš°ì„ : í…œí”Œë¦¿/íŒŒì„œ(íŒ¨í„´ B)ê°€ ì•ˆì „. SQL ì¸ì ì…˜ ìœ„í—˜ ì ê³  ì˜ˆì¸¡ ê°€ëŠ¥.\n",
            "- ìœ ì—°ì„±/ë³µì¡í•œ ì§ˆì˜ í•„ìš”: LLMì´ SQL ìƒì„±(íŒ¨í„´ A)ì´ í¸ë¦¬í•˜ë‚˜ ê²€ì¦/ì œí•œì´ í•„ìš”.\n",
            "- ìœ ì§€ë³´ìˆ˜ì„±: í…Œì´ë¸” ë³€ê²½ì´ ì¦ë‹¤ë©´ í…œí”Œë¦¿ ê´€ë¦¬ ë¹„ìš© ê³ ë ¤.\n",
            "\n",
            "3) ì•ˆì „Â·ê²€ì¦ ì „ëµ (í•„ìˆ˜)\n",
            "- ì ˆëŒ€ ì§ì ‘ ì‚¬ìš©ì ì…ë ¥ì„ raw SQLë¡œ ì‹¤í–‰í•˜ì§€ ë§ ê²ƒ.\n",
            "- LLMì´ ìƒì„±í•œ SQLì„ ë°˜ë“œì‹œ ê²€ì¦/í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸í™”:\n",
            "  - í—ˆìš©í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ ëª©ë¡ê³¼ ë¹„êµ.\n",
            "  - í—ˆìš©í•˜ì§€ ì•ŠëŠ” SQL(DDL, DROP, ALTER, ë³µì¡í•œ JOIN/ì„œë¸Œì¿¼ë¦¬ ì œí•œ ë“±) ì°¨ë‹¨.\n",
            "- Prepared statements ë˜ëŠ” ORM ì‚¬ìš©. íŒŒë¼ë¯¸í„° ë°”ì¸ë”© ê¶Œì¥.\n",
            "- ì¿¼ë¦¬ íƒ€ì„ì•„ì›ƒ/ë¦¬ì†ŒìŠ¤ ì œí•œ.\n",
            "- ìµœì†Œ ê¶Œí•œ DB ê³„ì • ì‚¬ìš©(ì½ê¸° ì „ìš© ë“±).\n",
            "\n",
            "4) ì˜ˆì‹œ DB ìŠ¤í‚¤ë§ˆ (ê°„ë‹¨)\n",
            "- foods (food_id, name, category, description)\n",
            "- ingredients (ingredient_id, name, allergen_flag)\n",
            "- recipes (recipe_id, food_id, step_number, instruction, duration_minutes)\n",
            "- recipe_ingredients (recipe_id, ingredient_id, amount, unit)\n",
            "\n",
            "5) ì˜ˆì‹œ: \"ê³„ë€ë§ì´ ë§Œë“œëŠ” ë°©ë²•ì¢€ ì•Œë ¤ì¤˜\" ì²˜ë¦¬ íë¦„(A íŒ¨í„´: LLMâ†’SQL)\n",
            "- 1ë‹¨ê³„: ì˜ë„ íŒŒì•…/ìŠ¬ë¡¯ ì¶”ì¶œ(ì˜µì…˜)\n",
            "  - intent: \"ìš”ë¦¬ë°©ë²• ì¡°íšŒ\"\n",
            "  - dish: \"ê³„ë€ë§ì´\"\n",
            "  - output_format: (í”„ë¡ íŠ¸ì—”ë“œ ì œê³µ) ì˜ˆ: JSON {title, time, ingredients:[], steps:[]}\n",
            "- 2ë‹¨ê³„: LLMì—ê²Œ SQL ìƒì„± í”„ë¡¬í”„íŠ¸ (ì˜ˆì‹œ í”„ë¡¬í”„íŠ¸)\n",
            "  - Instruction: \"ì•„ë˜ ì œí•œì„ ì—„ê²©íˆ ì§€ì¼œ í•œ ê°œì˜ SELECT ë¬¸ë§Œ ìƒì„±í•˜ë¼. í—ˆìš© í…Œì´ë¸”: foods, recipes, recipe_ingredients, ingredients. ë°˜í™˜ ì»¬ëŸ¼ì€ recipe_id, food_id, food_name, total_time, ingredient_name, amount, unit, step_number, instruction. íŒŒë¼ë¯¸í„°ëŠ” ? ë¡œ ì‚¬ìš©í•˜ë¼. Dish ì´ë¦„ì„ ? ë°”ì¸ë”©ìœ¼ë¡œ ì‚¬ìš©.\"\n",
            "  - User input: \"Dish = 'ê³„ë€ë§ì´'\"\n",
            "- 3ë‹¨ê³„: LLMì´ ìƒì„±í•œ SQL(ì˜ˆì‹œ)\n",
            "  SELECT f.food_id AS food_id, f.name AS food_name,\n",
            "         NULL AS total_time, -- (ë§Œì•½ ì´ì‹œê°„ ì»¬ëŸ¼ ì—†ìœ¼ë©´ null í˜¹ì€ ê³„ì‚°)\n",
            "         i.name AS ingredient_name, ri.amount, ri.unit,\n",
            "         r.step_number, r.instruction\n",
            "  FROM foods f\n",
            "  JOIN recipes r ON f.food_id = r.food_id\n",
            "  JOIN recipe_ingredients ri ON r.recipe_id = ri.recipe_id\n",
            "  JOIN ingredients i ON ri.ingredient_id = i.ingredient_id\n",
            "  WHERE LOWER(f.name) = LOWER(?);\n",
            "- 4ë‹¨ê³„: ë°±ì—”ë“œì—ì„œ SQL ê²€ì¦(í—ˆìš© í…Œì´ë¸”/ì»¬ëŸ¼, DML/DDL ì°¨ë‹¨) í›„ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©('ê³„ë€ë§ì´')ë¡œ ì‹¤í–‰.\n",
            "- 5ë‹¨ê³„: DB ê²°ê³¼ â†¦ ì •ê·œí™”(ì˜ˆ: recipe ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ JSON êµ¬ì¡° ìƒì„±)\n",
            "- 6ë‹¨ê³„: LLMì—ê²Œ \"ì¶œë ¥ í¬ë§· ê°•ì œ ì§€ì‹œ\"ì™€ í•¨ê»˜ ê²°ê³¼ ì „ë‹¬ â†’ ìµœì¢… ì‘ë‹µ ìƒì„±\n",
            "  - ì˜ˆ: \"ì‘ë‹µì€ JSON í˜•íƒœë¡œ {title, total_time, ingredients:[{name, amount, unit}], steps:[{step_number, instruction}]} ë§Œ ë°˜í™˜í•˜ë¼.\"\n",
            "\n",
            "6) íŒ¨í„´ B(í…œí”Œë¦¿/íŒŒì„œ) ì˜ˆì‹œ (ê¶Œì¥: ë‹¨ìˆœí•œ ì¿¼ë¦¬/ë†’ì€ ì •í™•ë„)\n",
            "- ì‚¬ìš©ì ë¬¸ì¥ íŒŒì‹±(ê°„ë‹¨ ê·œì¹™ or ì‘ì€ NLU ëª¨ë¸)\n",
            "  - dish=\"ê³„ë€ë§ì´\"\n",
            "- Choose SQL template:\n",
            "  - SELECT ... FROM ... WHERE LOWER(name)=LOWER(:dish)\n",
            "- Execute, group, format. LLMì€ í¬ë§·/ë¶€ê°€ ì„¤ëª…(íŒ, ëŒ€ì²´ì¬ ë“±)ë§Œ ë‹´ë‹¹.\n",
            "\n",
            "7) ì‘ë‹µ í¬ë§· ì„¤ê³„(ëª…í™•í•œ ìŠ¤í‚¤ë§ˆ ê¶Œì¥)\n",
            "- ì˜ˆ: JSON schema\n",
            "  {\n",
            "    \"title\": \"ê³„ë€ë§ì´\",\n",
            "    \"total_time_minutes\": 10,\n",
            "    \"servings\": 2,\n",
            "    \"ingredients\": [\n",
            "      {\"name\": \"ê³„ë€\", \"amount\": 3, \"unit\": \"ê°œ\"},\n",
            "      {\"name\": \"ì†Œê¸ˆ\", \"amount\": \"ì•½ê°„\", \"unit\": null}\n",
            "    ],\n",
            "    \"steps\": [\n",
            "      {\"step\": 1, \"instruction\": \"ê³„ë€ì„ í’€ì–´ ì†Œê¸ˆì„ ë„£ê³  ì„ëŠ”ë‹¤.\"},\n",
            "      {\"step\": 2, \"instruction\": \"íŒ¬ì— ê¸°ë¦„ì„ ë‘ë¥´ê³  ì•½ë¶ˆì—ì„œ ì²œì²œíˆ ë§ì•„ì¤€ë‹¤.\"}\n",
            "    ],\n",
            "    \"notes\": \"ì¤‘ë¶ˆì—ì„œ ìµíˆë©´ ì†ì´ ìµê¸° ì–´ë ¤ìš°ë¯€ë¡œ ì•½ë¶ˆ ê¶Œì¥.\"\n",
            "  }\n",
            "- LLMì—ê²Œ ì¶œë ¥ì€ ë°˜ë“œì‹œ ì´ schemaë§Œ ë”°ë¥´ë„ë¡ ê°•ì œ(ë˜ëŠ” API function calling/JSON schema validation ì‚¬ìš©).\n",
            "\n",
            "8) ì˜ˆì‹œ ì „ì²´ ëŒ€í™”/í”„ë¡¬í”„íŠ¸ (ê°„ë‹¨í•œ í…œí”Œë¦¿)\n",
            "- System: \"ë‹¹ì‹ ì€ DBì—ì„œ ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì  JSONìœ¼ë¡œ ë§Œë“œëŠ” ì—­í• ì…ë‹ˆë‹¤. ì¶œë ¥ì€ ì˜¤ì§ JSON schema Xë§Œìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.\"\n",
            "- User: \"ê³„ë€ë§ì´ ë§Œë“œëŠ” ë°©ë²• ì•Œë ¤ì¤˜\"\n",
            "- Backend: (parse dish=\"ê³„ë€ë§ì´\") â†’ run template query â†’ results\n",
            "- Backend â†’ LLM: \"ë‹¤ìŒ DB ê²°ê³¼ë¥¼ JSON schema Xë¡œ ë³€í™˜í•˜ê³ , í•„ìš”í•˜ë©´ ì¶”ê°€ íŒ 1-2ë¬¸ì¥ ë§ë¶™ì—¬ë¼. DB ê²°ê³¼: [...]\"\n",
            "- LLM â†’ return JSON\n",
            "\n",
            "9) ë„êµ¬/ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ì²œ\n",
            "- í”„ë¡¬í”„íŠ¸/ì›Œí¬í”Œë¡œìš°: LangChain, LlamaIndex(íŠ¹íˆ RAG, ìš”ì•½, ì¸ë±ì‹±), Vertex AI\n",
            "- SQL/ORM: SQLAlchemy (Python), knex (Node), prepared statements\n",
            "- ê²€ì¦: SQL parsers (sqlparse), í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê²€ì‚¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
            "- LLM API: OpenAI, Anthropic, Mistral ë“±. í•¨ìˆ˜ í˜¸ì¶œ/JSON Schema ê¸°ëŠ¥ì´ ìˆìœ¼ë©´ í¬ë§· ê°•ì œì— ìœ ìš©.\n",
            "\n",
            "10) êµ¬í˜„ íŒê³¼ ì£¼ì˜ì‚¬í•­\n",
            "- ë””ë²„ê¹…: LLMì´ ìƒì„±í•œ SQLê³¼ ìµœì¢… JSONì„ ë¡œê·¸(ë¯¼ê°ì •ë³´ ì œì™¸)í•˜ì—¬ ë¬¸ì œ ì¶”ì .\n",
            "- ìºì‹±: ì¸ê¸° ì§ˆì˜(ì˜ˆ: ê³„ë€ë§ì´ ë ˆì‹œí”¼)ëŠ” ìºì‹œí•´ì„œ ì‘ë‹µ ì†ë„ ê°œì„ .\n",
            "- ë‹¤êµ­ì–´ ì²˜ë¦¬: ìŒì‹ëª… í‘œì¤€í™”(ë™ì¼ ìŒì‹ì˜ ì—¬ëŸ¬ í‘œí˜„ ì²˜ë¦¬) â€” ë³„ë„ ì •ê·œí™” í…Œì´ë¸”/alias í…Œì´ë¸” êµ¬ì¶•.\n",
            "- ë²„ì „ ê´€ë¦¬: ë ˆì‹œí”¼ ë³€ê²½ ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•œ ë ˆì½”ë“œ ë²„ì „(ìœ íš¨ê¸°ê°„, ìˆ˜ì •ì¼ ë“±).\n",
            "- ì˜¤ë¥˜ ì¼€ì´ìŠ¤: DBì— í•´ë‹¹ ìŒì‹ì´ ì—†ì„ ë•Œ LLMì—ê²Œ ëŒ€ì²´ ì œì•ˆ(ìœ ì‚¬í•œ ìŒì‹ ì¶”ì²œ)í•˜ë„ë¡ ì§€ì‹œ.\n",
            "- ê°œì¸ì •ë³´/ì €ì‘ê¶Œ: ì™¸ë¶€ ì¶œì²˜ ë ˆì‹œí”¼ë¥¼ ê·¸ëŒ€ë¡œ ì €ì¥/ê³µê°œí•  ë•Œ ì €ì‘ê¶Œ ë¬¸ì œ ê²€í† .\n",
            "\n",
            "11) ê°„ë‹¨í•œ ì˜ˆì‹œ ê²°ê³¼(ìµœì¢… ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ í˜•íƒœ)\n",
            "- ì¶œë ¥(ì‚¬ëŒì´ ì½ê¸° ì¢‹ê²Œ ë³€í™˜ëœ ì˜ˆ)\n",
            "  ì œëª©: ê³„ë€ë§ì´\n",
            "  ì´ ì‹œê°„: 10ë¶„\n",
            "  ì¬ë£Œ:\n",
            "  - ê³„ë€ 3ê°œ\n",
            "  - ì†Œê¸ˆ ì•½ê°„\n",
            "  ìˆœì„œ:\n",
            "  1) ê³„ë€ì„ í’€ì–´ ì†Œê¸ˆì„ ì„ëŠ”ë‹¤.\n",
            "  2) ê¸°ë¦„ ë‘ë¥¸ íŒ¬ì— ì•½ë¶ˆë¡œ ë¶€ì–´ ë§ì•„ê°€ë©° ìµíŒë‹¤.\n",
            "  íŒ: ì¤‘ë¶ˆë³´ë‹¤ ì•½ë¶ˆì—ì„œ ì²œì²œíˆ ìµíˆë©´ ì†ì´ ì´‰ì´‰í•©ë‹ˆë‹¤.\n",
            "\n",
            "ìš”ì•½\n",
            "- ì•ˆì „í•˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ ì›í•˜ë©´ 'í…œí”Œë¦¿ + í¬ë§·íŒ…ìš© LLM' í˜¼í•© ë°©ì‹(B íŒ¨í„´)ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
            "- ë³µì¡í•˜ê³  ììœ ë¡œìš´ ì§ˆì˜ë¥¼ ì›í•˜ë©´ 'LLMâ†’SQLâ†’ê²€ì¦â†’ì‹¤í–‰â†’LLM í¬ë§·' íë¦„ì„ ì‚¬ìš©í•˜ë˜ ì—„ê²©í•œ ê²€ì¦ê³¼ ê¶Œí•œ ì œí•œì„ ë°˜ë“œì‹œ ë„£ìœ¼ì„¸ìš”.\n",
            "- ì¶œë ¥ í¬ë§·ì€ JSON ë“± ìŠ¤í‚¤ë§ˆë¡œ ì—„ê²©íˆ ì •ì˜í•˜ê³ , LLMì—ê²Œ ê·¸ê²ƒë§Œ ë‚´ë³´ë‚´ë„ë¡ ì§€ì‹œí•˜ê±°ë‚˜ function-calling/ìŠ¤í‚¤ë§ˆ ë°¸ë¦¬ë°ì´ì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n",
            "\n",
            "ì›í•˜ì‹œë©´:\n",
            "- ì‹¤ì œ ì½”ë“œ ì˜ˆì œ(Python + FastAPI + SQLAlchemy + OpenAI prompt)ë¡œ ì‘ì€ PoC í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”.\n",
            "- í˜¹ì€ LLMì´ ìƒì„±í•œ SQLì„ ìë™ ê²€ì¦í•˜ëŠ” ìƒ˜í”Œ ê²€ì¦ê¸°(í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜) ì½”ë“œë„ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ëŠ ìª½ì„ ë¨¼ì € ì›í•˜ì‹œë‚˜ìš”?\n"
          ]
        }
      ],
      "source": [
        "print(gpt_llm.invoke(\"\"\"\n",
        "ë‚˜ëŠ” íŠ¹ì • ì§ˆë¬¸ì— ëŒ€í•˜ì—¬ rdbë‚´ì— ìˆëŠ” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ llmì´ íŠ¹ì •í•œ í¬ë§·ìœ¼ë¡œ ë‹µë³€ì„ í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ê³ ì‹¶ì–´. ë‚˜ëŠ” rdb ì „ë¬¸ê°€ì´ê³ , í”„ë¡œê·¸ë¨ì€ í•  ìˆ˜ ìˆì§€ë§Œ llmì„ ì–´ë–¤ì‹ìœ¼ë¡œ ì—°ê²°í•´ì•¼í•˜ëŠ”ì§€ ëª¨ë¥´ê² ì–´. ì €ì¥ëœ ë°ì´í„° ë‚´ìš©ì— ëŒ€í•´ì„œë„ ì˜ ì•Œê³ ìˆëŠ”ë°, ë§Œì•½ ë°ì´í„°ê°€ ìŒì‹ê³¼ ë ˆì‹œí”¼ì— ëŒ€í•œ ë¶€ë¶„ì´ë¼ê³  ê°€ì •í•˜ê³  í…Œì´ë¸”ë“¤ì€ ìŒì‹ì¢…ë¥˜ í…Œì´ë¸”, ì¬ë£Œí…Œì´ë¸”, ë ˆì‹œí”¼í…Œì´ë¸” ë“±ë“± ì´ë ‡ê²Œ ìˆì„ê±´ë°, ê³„ë€ë§ì´ ë§Œë“œëŠ” ë°©ë²•ì¢€ ì•Œë ¤ì¤˜ ì´ë ‡ê²Œ ì§ˆë¬¸í–ˆì„ë•Œ ì´ê±¸ llmì´ ì ‘ê·¼í•˜ëŠ” êµ¬ì¡°ë¥¼ ì „ì²´ì ìœ¼ë¡œ ì•Œê³ ì‹¶ì–´.\n",
        "\"\"\").content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e435cb7",
      "metadata": {
        "id": "5e435cb7"
      },
      "source": [
        "## [ì‹¤ìŠµ] LLM ìµœì‹  ì—°êµ¬ ìš”ì•½ ì²´ì¸ ë§Œë“¤ê¸°\n",
        "\n",
        "ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ, LLM ê´€ë ¨ ë…¼ë¬¸ë§Œ ëª¨ì•„ ìš”ì•½í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "ì ì ˆí•œ ìš”ì•½ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì—¬, ì´ì „ ì‹¤ìŠµì˜ ê²°ê³¼ ì¤‘ LLMì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë“¤ë§Œì„ ëª¨ìœ¼ì„¸ìš”."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f29a9567",
      "metadata": {
        "id": "f29a9567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac593faa-6a02-4b65-d039-a28f5b7461f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# ì„ì˜ì˜ ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰\n",
        "query = 'ê²€ìƒ‰ì–´'\n",
        "papers = get_arxiv_papers(query=query, N=5)\n",
        "\n",
        "\n",
        "LLM_documents=[]\n",
        "\n",
        "for paper in papers:\n",
        "    if \"is_llm : Yes\" in classify_chain.invoke(papers): # LLM ë¶„ë¥˜ ì¡°ê±´ ë„£ê¸°\n",
        "        LLM_documents.append(\n",
        "            f\"\"\"ì œëª©:{paper['title']}\n",
        "            ì €ì:{paper['authors']}\n",
        "            PDF ë§í¬:{paper['pdf_url']}\n",
        "            ìš”ì•½:{paper['summary']}\n",
        "            \"\"\"\n",
        "        )\n",
        "        # ë¶„ë¥˜ì‹œ ë¡œì§ ì¶”ê°€\n",
        "        # Str í˜•ì‹ì˜ ì €ë³´ë¥¼ ì €ì¥\n",
        "\n",
        "LLM_documents\n",
        "# [\"ì œëª©: , ì €ì: , ìš”ì•½: \", \"ì œëª©: , ì €ì: , ìš”ì•½: \", ...]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e0b22a1",
      "metadata": {
        "id": "4e0b22a1"
      },
      "outputs": [],
      "source": [
        "# ë¶„ë¥˜ í”„ë¡¬í”„íŠ¸ì™€ ì²´ì¸ ë§Œë“¤ê¸°\n",
        "summary_prompt = ChatPromptTemplate(\n",
        "    [\n",
        "        ('system', '''ì£¼ì–´ì§„ ë…¼ë¬¸ë“¤ì˜ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬,\n",
        "                      ì£¼ì œì— ëŒ€í•œ ìµœì‹  ì—°êµ¬ ë™í–¥ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì“°ì„¸ìš”.\n",
        "\n",
        "                      ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ê³¼ì¥ëœ í†¤ìœ¼ë¡œ, ë…¼ë¬¸ì˜ ì£¼ìš” ë‚´ìš©ê³¼ ê¸°ì—¬, ë°œì „ ë°©í–¥ì„ ì†Œê°œí•˜ì„¸ìš”.\n",
        "        '''),\n",
        "        ('human', '''\n",
        "        ì£¼ì œ: {topic} ê´€ë ¨ LLM ë…¼ë¬¸ë“¤\n",
        "\n",
        "        ì¡°ì‚¬ ë…¼ë¬¸ ëª©ë¡: {context}\n",
        "        ''')\n",
        "    ]\n",
        ")\n",
        "summary_chain = summary_prompt | gpt_llm | parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d29360",
      "metadata": {
        "id": "86d29360"
      },
      "outputs": [],
      "source": [
        "# LLM í˜ì´í¼ ìš”ì•½ ì¶œë ¥í•˜ê¸°\n",
        "summary = summary_chain.invoke(\n",
        "    {\n",
        "        'topic':query,\n",
        "        'context':LLM_documents\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbFL1FoC4pVh",
        "outputId": "df99e4f4-3447-467d-9e28-30fdda6f2bda"
      },
      "id": "wbFL1FoC4pVh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ì£¼ì–´ì§„ ë…¼ë¬¸ ëª©ë¡ì´ ë¹„ì–´ ìˆì–´ì„œ(ì•„ë¬´ë„ ë…¼ë¬¸ì„ ìˆ¨ê²¨ë†¨ë‚˜ ë´…ë‹ˆë‹¤â€¦), ì‹¤ì œ ë…¼ë¬¸ë“¤ì„ ì§ì ‘ ì¸ìš©í•˜ì§€ëŠ” ëª»í•˜ì§€ë§Œ, â€œê²€ìƒ‰ì–´(ì¿¼ë¦¬) ê´€ë ¨ LLM ì—°êµ¬â€ì˜ ìµœì‹  ì—°êµ¬ ë™í–¥ì„ ì¢…í•©Â·ì •ë¦¬í•œ ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ì•½ê°„ ê³¼ì¥ëœ ë‰´ìŠ¤ë ˆí„°ë¥¼ ëŒ€ì‹  ì‘ì„±í•´ ë“œë¦½ë‹ˆë‹¤. ì›í•˜ì‹œë©´ ë‚˜ì¤‘ì— êµ¬ì²´ì  ë…¼ë¬¸ ë¦¬ìŠ¤íŠ¸ë‚˜ PDFë¥¼ ì£¼ì‹œë©´ í•´ë‹¹ ë…¼ë¬¸ë“¤ì„ ë°˜ì˜í•´ ë” ì •í™•í•œ ë²„ì „ì„ ë§Œë“¤ì–´ ë“œë¦´ê²Œìš”. ê·¸ëŸ¼ ì¶œë°œâ€”ê²€ìƒ‰ì–´ì˜ ì„œì‚¬ì‹œ, LLM ë²„ì „ìœ¼ë¡œ ê°€ë´…ì‹œë‹¤.\n",
            "\n",
            "----------------------------\n",
            "ê²€ìƒ‰ì–´ ì†ìœ¼ë¡œ ë›°ì–´ë“  ê±°ëŒ€í•œ ì–¸ì–´ ìƒëª…ì²´ë“¤ â€” ê²€ìƒ‰ì–´ ê´€ë ¨ LLM ì—°ê°\n",
            "Issue #1 â€” ì˜¤ëŠ˜ì˜ í—¤ë“œë¼ì¸: \"ë‹¹ì‹ ì˜ í•œë§ˆë”” ê²€ìƒ‰ì–´ê°€ LLM ì•ì—ì„œ ë“œë¼ë§ˆí‹±í•˜ê²Œ ë³€ì‹ í•©ë‹ˆë‹¤\"\n",
            "\n",
            "ì¹œì• í•˜ëŠ” ì—°êµ¬ìÂ·ê°œë°œìÂ·í˜¸ê¸°ì‹¬ ë§ì€ ë…ì ì—¬ëŸ¬ë¶„,\n",
            "ê²€ìƒ‰ì°½ì— â€œìµœê³ ì˜ ê¹€ë°¥â€ë§Œ ì…ë ¥í•˜ë˜ ì‹œëŒ€ëŠ” ê°”ìŠµë‹ˆë‹¤. ì´ì œëŠ” LLMì´ ë‹¹ì‹ ì˜ ëª¨í˜¸í•œ í•œ ì¤„ì„ ë°›ì•„ ë©‹ë“¤ì–´ì§€ê²Œ ë‹¤ë“¬ê³ , í•„ìš”í•œ ì •ë³´ë¥¼ ì°¾ì•„ë‚´ë©°, ë•Œë¡œëŠ” ë‹¹ì‹ ì˜ ì˜ë„ë¥¼ ì‹¬ë¦¬ ë¶„ì„í•˜ë“¯ ì½ì–´ë‚´ë ¤ í•©ë‹ˆë‹¤. ìµœê·¼ ì—°êµ¬ë“¤ì€ ì´ â€˜ì¿¼ë¦¬ â†” LLMâ€™ ìƒí˜¸ì‘ìš©ì„ ì „ë°©ìœ„ë¡œ ì—…ê·¸ë ˆì´ë“œí•˜ê³  ìˆëŠ”ë°ìš”, ì˜¤ëŠ˜ì€ ê·¸ íë¦„ì„ ì›ƒìŒê³¼ ì•½ê°„ì˜ ê³¼ì¥ìœ¼ë¡œ ìš”ì•½í•´ ë“œë¦½ë‹ˆë‹¤.\n",
            "\n",
            "ì£¼ìš” íë¦„ 1 â€” ì¿¼ë¦¬ ì´í•´ì™€ ì˜ë„ íŒŒì•…: LLMì´ ë‹¹ì‹ ì˜ ì†ë§ˆìŒì„ ì½ëŠ”ë‹¤ (ì¡°ì‹¬)\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì€ ì˜›ë§. LLM ê¸°ë°˜ ëª¨ë¸ë“¤ì´ ë¬¸ë§¥ê³¼ ëŒ€í™” ì´ë ¥, ì‚¬ìš©ì í”„ë¡œí•„(ë˜ëŠ” ì„¸ì…˜ ì •ë³´)ì„ ê²°í•©í•´ í•œ ì¤„ ì¿¼ë¦¬ì˜ ìˆ¨ì€ ì˜ë„ê¹Œì§€ ì¶”ë¡ í•©ë‹ˆë‹¤.\n",
            "- í•µì‹¬ ê¸°ì—¬: ëŒ€í™”í˜• ì˜ë„ ì¶”ë¡ , ë‹¤ì˜ì–´ í•´ì†Œ, ìƒí™© ì˜ì¡´ì  ì¬í•´ì„(ì˜ˆ: â€œì˜¤ëŠ˜ ë¹„ ì˜¬ê¹Œ?â€ì˜ ìœ„ì¹˜Â·ì‹œê°„ ë§¥ë½ ë°˜ì˜).\n",
            "- ì™œ ì›ƒê¸´ê°€: â€œë¹„ ì˜¬ê¹Œ?â€ì— ëŒ€í•´ LLMì´ ê¸°ìƒì²­ ìˆ˜ì¤€ì˜ ì¶”ì • í™•ë¥ ê³¼ ìš°ì‚° êµ¬ë§¤ ë§í¬ê¹Œì§€ ê¶Œí•˜ë©´, ë‹¹ì‹ ì€ ì´ë¯¸ ì‡¼í•‘ëª° ê´‘ê³ ì˜ ì‚°ë¬¼ì…ë‹ˆë‹¤.\n",
            "- ë°œì „ ë°©í–¥: ê°œì¸í™”ì™€ í”„ë¼ì´ë²„ì‹œì˜ ê· í˜•, ì˜ë„ ë¶ˆí™•ì‹¤ì„± í‘œí˜„(ëª¨ë¸ì´ â€˜í™•ì‹¤í•˜ì§€ ì•ŠìŒâ€™ì„ ë§í•  ìˆ˜ ìˆê²Œ).\n",
            "\n",
            "ì£¼ìš” íë¦„ 2 â€” ì¿¼ë¦¬ ì •ì œ ë° ì¬ì‘ì„± (query rewriting): ì¿¼ë¦¬ëŠ” ë‹¤ë“¬ì–´ì ¸ì•¼ ë¹›ë‚œë‹¤\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: LLMë¡œ ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ê²€ìƒ‰ì—”ì§„ ìµœì í™”ëœ(ë˜ëŠ” ê²€ìƒ‰ ì‹œìŠ¤í…œì— ì¹œí™”ì ì¸) í˜•íƒœë¡œ ì¬ì‘ì„±í•©ë‹ˆë‹¤. ì¥ë¬¸ì˜ ì„¤ëª…ë„ í•µì‹¬ìœ¼ë¡œ ì••ì¶• ê°€ëŠ¥.\n",
            "- í•µì‹¬ ê¸°ì—¬: ë²ˆì—­ì  ì •ì œ, ì˜¤íƒ€Â·ì•½ì–´ ë³µì›, ê°œì¸í™”ëœ ì¶”ì²œ ê²€ìƒ‰ì–´ ìƒì„±.\n",
            "- ì™œ ì›ƒê¸´ê°€: â€œí”¼ìâ€ë¥¼ â€œì¹¼ë¡œë¦¬Â·ë°°ë‹¬ì‹œê°„ í¬í•¨ ë‰´ìš•ìŠ¤íƒ€ì¼ í”¼ì ì¶”ì²œâ€ìœ¼ë¡œ ë°”ê¿” ì£¼ë©´, ë‹¹ì‹ ì˜ í—ˆê¸°ê¹Œì§€ ê¸°ê³„ê°€ ì„¤ê³„í•œ ë“¯í•œ ëŠë‚Œ.\n",
            "- ë°œì „ ë°©í–¥: ì¬ì‘ì„±ì˜ íˆ¬ëª…ì„±(ì›ë³¸â†”ì¬ì‘ì„± ë¹„êµ), ì‚¬ìš©ìê°€ ì›ì¹˜ ì•Šì„ ë•Œì˜ â€˜ì›ë³¸ ì¡´ì¤‘ ëª¨ë“œâ€™.\n",
            "\n",
            "ì£¼ìš” íë¦„ 3 â€” ì¿¼ë¦¬ ìƒì„±(ìƒì„±í˜• ì§ˆì˜): ê²€ìƒ‰ì—”ì§„ì´ ìŠ¤ìŠ¤ë¡œ ì§ˆë¬¸ì„ ë˜ì§„ë‹¤\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ì¿¼ë¦¬ë¥¼ ìë™ ìƒì„±í•´ì„œ ë°ì´í„°ë² ì´ìŠ¤Â·ë¬¸ì„œ ì½”í¼ìŠ¤ì— ëŒ€í•œ ë³´ì¶© ì••ì¶• ì§ˆì˜ë¥¼ ë§Œë“¤ê³ , ê²€ìƒ‰ ì»¤ë²„ë¦¬ì§€ë¥¼ ë†’ì…ë‹ˆë‹¤.\n",
            "- í•µì‹¬ ê¸°ì—¬: ì ì€ ë ˆì´ë¸”ë¡œë„ ë‹¤ì–‘í•œ ì¿¼ë¦¬ ìƒì„±, ë°ì´í„° ì¦ê°•ì„ í†µí•œ ê²€ìƒ‰ ì‹œìŠ¤í…œ ê°œì„ .\n",
            "- ì™œ ì›ƒê¸´ê°€: ëª¨ë¸ì´ â€œì´ ë¬¸ì„œì—ëŠ” ì´ëŸ° ì§ˆë¬¸ë“¤ì´ í•„ìš”í•  ê²ƒ ê°™ìŠµë‹ˆë‹¤â€ë¼ë©° ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë±‰ì–´ë‚´ë©´, ë¬¸ì„œê°€ ì¸í„°ë·° ë‹¹í•˜ëŠ” ê¸°ë¶„.\n",
            "- ë°œì „ ë°©í–¥: ì¿¼ë¦¬ ë‹¤ì–‘ì„±ì˜ ì œì–´, ë¬´ì˜ë¯¸Â·í¸í–¥ëœ ì¿¼ë¦¬ ìƒì„± ë°©ì§€.\n",
            "\n",
            "ì£¼ìš” íë¦„ 4 â€” LLM + Retrieval: RAG(ê²€ìƒ‰ ë³´ê°• ìƒì„±)ì´ ëŒ€ì„¸\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: LLMì´ ì™¸ë¶€ ì§€ì‹(ë²¡í„° DB, ë¬¸ì„œ ì¸ë±ìŠ¤)ì„ ëŒì–´ì™€ ì‚¬ì‹¤ ê¸°ë°˜ ì‘ë‹µì„ ìƒì„± â€” hallucinationì„ ì¤„ì´ëŠ” ëŒ€í‘œì  ë°©ë²•.\n",
            "- í•µì‹¬ ê¸°ì—¬: ê²€ìƒ‰-ìƒì„± íŒŒì´í”„ë¼ì¸, context-window ìµœì í™”, evidence attribution(ì¶œì²˜ í‘œì‹œ).\n",
            "- ì™œ ì›ƒê¸´ê°€: ëª¨ë¸ì´ ì¶œì²˜ë¥¼ ë•ì§€ë•ì§€ ë¶™ì´ë©° â€œë‚´ ë§ì€ ì´ ë¬¸ì„œë“¤ì´ ì¦ëª…í•´ì¤ë‹ˆë‹¤â€ë¼ë©° ë³€í˜¸ì‚¬ì²˜ëŸ¼ ë‚˜ì˜¤ë©´, ë§í•˜ê¸° ì „ ì¦ê±° ë³´ê´€í•¨ì„ ë³¸ëŠ¥ì ìœ¼ë¡œ ì—´ê²Œ ë¨.\n",
            "- ë°œì „ ë°©í–¥: ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸(ì§€ì‹ ì‹ ì„ ë„), ê·¼ê±°ì˜ ì‹ ë¢°ë„ ì ìˆ˜í™”, ëŒ€ê·œëª¨ íŒŒì´í”„ë¼ì¸ì˜ ë¹„ìš© íš¨ìœ¨í™”.\n",
            "\n",
            "ì£¼ìš” íë¦„ 5 â€” ì¬ë­í‚¹ê³¼ ì„¸ë°€í•œ ì •ë°€ë„: LLMì´ ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì •ëˆí•œë‹¤\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ì´ˆê¸° í›„ë³´ ê²€ìƒ‰(ê²€ìƒ‰ì—”ì§„Â·ë²¡í„° ê²€ìƒ‰)ì´ ë½‘ì€ ê²°ê³¼ë¥¼ LLMë¡œ ì„¸ë°€í•˜ê²Œ ì¬í‰ê°€Â·ì¬ì •ë ¬í•˜ì—¬ ë” ê´€ë ¨ì„± ë†’ì€ ê²°ê³¼ ì œê³µ.\n",
            "- í•µì‹¬ ê¸°ì—¬: semantic reranking, cross-encoder ìŠ¤íƒ€ì¼ ì •ë°€ë„ í–¥ìƒ, ì‚¬ìš©ì í”¼ë“œë°±ì„ ë°˜ì˜í•œ í•™ìŠµ.\n",
            "- ì™œ ì›ƒê¸´ê°€: ê²€ìƒ‰ê²°ê³¼ê°€ LLMì˜ â€˜ë¯¸ì  ê¸°ì¤€â€™ì— ë”°ë¼ ì¬ë°°ì¹˜ë˜ë©´, ì–´ë–¤ ê²°ê³¼ëŠ” ê°‘ìê¸° â€œê³ ê¸‰ ì·¨ê¸‰â€ì„ ë°›ìŠµë‹ˆë‹¤.\n",
            "- ë°œì „ ë°©í–¥: ì†ë„ vs ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ í•´ê²°, ì‚¬ìš©ìë³„ ë­í‚¹ ë§ì¶¤í™”.\n",
            "\n",
            "ì£¼ìš” íë¦„ 6 â€” íš¨ìœ¨ì„±ê³¼ ì†Œí˜•í™”: ê±°ëŒ€í•œ LLM ì•„ë‹ˆë©´ ì•ˆ ëœë‹¤ê³ ?\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ê²½ëŸ‰í™”ëœ LLM, ì§€ì‹ ì¦ë¥˜, ì €ì „ë ¥ ì˜¨ë””ë°”ì´ìŠ¤ ê²€ìƒ‰ ë³´ì¡°ê¸°ìˆ ì´ ëŠ˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "- í•µì‹¬ ê¸°ì—¬: LoRA, quantization, knowledge distillationì„ í†µí•œ ë°°í¬í˜• ê²½ëŸ‰ ëª¨ë¸.\n",
            "- ì™œ ì›ƒê¸´ê°€: â€œì´ˆê²½ëŸ‰ LLMì´ ë‚´ íœ´ëŒ€í°ì—ì„œ ì¸í„°ë„·ì„ ë§ˆë²•ì²˜ëŸ¼ í•´ê²°í•´ì¤€ë‹¤â€ë©° ì‚¬ìš©ìëŠ” ìŠ¤ë§ˆíŠ¸í°ì„ ë°•ì‚¬ë¡œ ì°©ê°í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
            "- ë°œì „ ë°©í–¥: ê²½ëŸ‰ ëª¨ë¸ì˜ ì •í™•ë„ í™•ë³´, í”„ë¼ì´ë²„ì‹œ-íš¨ìœ¨-ì •í™•ì„± ì‚¼ë°•ì ë§ì¶”ê¸°.\n",
            "\n",
            "ì£¼ìš” íë¦„ 7 â€” ë©€í‹°ëª¨ë‹¬Â·ëŒ€í™”í˜• ê²€ìƒ‰: ì´ë¯¸ì§€Â·ìŒì„±ê¹Œì§€ ì¿¼ë¦¬ê°€ ëœë‹¤\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ì‚¬ìš©ìëŠ” ì‚¬ì§„ í•œ ì¥, ìŒì„± í•œ ë§ˆë””, ë˜ëŠ” í™”ë©´ ìº¡ì²˜ë¡œ ì¿¼ë¦¬ë¥¼ ëŒ€ì‹ í•©ë‹ˆë‹¤. LLMì€ ì´ë¥¼ í•´ì„í•´ ê²€ìƒ‰ ì§ˆì˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
            "- í•µì‹¬ ê¸°ì—¬: OCRÂ·ë¹„ì „-ì–¸ì–´ ëª¨ë¸ í†µí•©, ë©€í‹°í„´ ëŒ€í™”í˜• ê²€ìƒ‰ ì„¸ì…˜.\n",
            "- ì™œ ì›ƒê¸´ê°€: ì‚¬ì§„ í•œ ì¥ìœ¼ë¡œ â€œì´ ì¹˜ë§ˆ ì–´ë””ì„œ ìƒ€ì–´?â€ë¥¼ ë¬»ê³ , ëª¨ë¸ì´ ì‡¼í•‘ëª°Â·ê°€ê²©Â·ìœ ì‚¬ ìŠ¤íƒ€ì¼ê¹Œì§€ ì¶”ì²œí•˜ë©´, ë‹¹ì‹ ì˜ ì‡¼í•‘ ë¦¬ìŠ¤íŠ¸ê°€ AIì˜ ì‘í’ˆì²˜ëŸ¼ ë³´ì…ë‹ˆë‹¤.\n",
            "- ë°œì „ ë°©í–¥: ë©€í‹°ëª¨ë‹¬ ì‹ ë¢°ì„±, ì €ì‘ê¶ŒÂ·í”„ë¼ì´ë²„ì‹œ ë¬¸ì œ í•´ê²°.\n",
            "\n",
            "ì£¼ìš” íë¦„ 8 â€” í‰ê°€ì™€ ë²¤ì¹˜ë§ˆí¬: ë¬´ì—‡ì„ â€˜ì¢‹ì€ ì¿¼ë¦¬ ë°˜ì‘â€™ì´ë¼ í•  ê²ƒì¸ê°€\n",
            "- ë¬´ì—‡ì´ ìƒˆë¡œì›Œì¡Œë‚˜: ë‹¨ìˆœ ì •ë‹µë¥ ì„ ë„˜ì–´ì„œëŠ” ì‚¬ìš©ì ë§Œì¡±ë„, ì‚¬ì‹¤ì„±, ì‘ë‹µì˜ íˆ¬ëª…ì„±, ì†ë„ í‰ê°€ ì§€í‘œë“¤ì´ ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
            "- í•µì‹¬ ê¸°ì—¬: ì‹¤ì„¸ê³„ ëŒ€í™” ë°ì´í„° ê¸°ë°˜ í‰ê°€, human-in-the-loop í‰ê°€, ì‹ ë¢°ë„Â·ì™¸ë¶€ ê·¼ê±° ê¸°ë°˜ ì ìˆ˜.\n",
            "- ì™œ ì›ƒê¸´ê°€: ìˆ˜ì¹˜ê°€ ì¢‹ìœ¼ë©´ ì¢‹ì€ ê²ƒì´ê³ , ê¸°ì¨ì„ ì£¼ë©´ ë” ì¢‹ì€ ê²ƒì´ë©°, ê²°êµ­ 'ì‚¬ëŒì´ ì›ƒëŠ”ê°€'ë¡œ ê·€ê²°ë˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.\n",
            "- ë°œì „ ë°©í–¥: í‘œì¤€í™”ëœ ì‹ ë¢°ì„± ì§€í‘œ, ê°œì¸ì •ë³´Â·ìœ¤ë¦¬ì  í‰ê°€ í”„ë ˆì„ì›Œí¬ í†µí•©.\n",
            "\n",
            "ê¸°íƒ€ ë– ì˜¤ë¥´ëŠ” í™”ë‘ë“¤ (ì§§ê³  êµµê²Œ)\n",
            "- í•©ì„± ì¿¼ë¦¬ ìƒì„±ìœ¼ë¡œ ë°ì´í„° ì¦ê°•: ì ì€ ë ˆì´ë¸”ë¡œ ê²€ìƒ‰ ì„±ëŠ¥ì„ ë»¥íŠ€ê¸°í•˜ëŠ” í…Œí¬ë‹‰ì´ ì¸ê¸°.\n",
            "- ì¿¼ë¦¬ í”„ë¼ì´ë²„ì‹œ & ë¡œì»¬ ëŸ°íƒ€ì„: ì‚¬ìš©ì ë°ì´í„°ê°€ ì„œë²„ ë°–ìœ¼ë¡œ ìƒˆì§€ ì•Šê²Œ í•˜ë ¤ëŠ” ë…¸ë ¥ ì¦ê°€.\n",
            "- ì„¤ëª… ê°€ëŠ¥í•œ ê²€ìƒ‰(Explainable Retrieval): LLMì´ â€œì™œ ì´ ê²°ê³¼ë¥¼ ê³¨ëë‚˜?â€ë¥¼ ì„¤ëª…í•´ì•¼ ì‚¬ìš©ì ì‹ ë¢°ê°€ ì‚°ë‹¤.\n",
            "- í¸í–¥Â·ì•…ìš© ë°©ì§€: ì•…ì˜ì  ì¿¼ë¦¬ ìƒì„±ì— ëŒ€í•œ ì•ˆì „ì¥ì¹˜ í•„ìš”ì„± ì»¤ì§.\n",
            "- ì‹¤ì‹œê°„Â·ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° í†µí•©: ìµœì‹  ë‰´ìŠ¤Â·ê°€ê²© ì •ë³´ ë°˜ì˜ ë¬¸ì œ.\n",
            "\n",
            "ë¯¸ë˜ ì˜ˆì¸¡ (ê³¼ì¥ í¬í•¨)\n",
            "- 1ë…„ ë‚´: RAG + ì¬ë­í‚¹ì˜ ì¡°í•©ì´ ëŒ€ë¶€ë¶„ì˜ ìƒìš© ê²€ìƒ‰ì—ì„œ ê¸°ë³¸ ìŠ¤íƒìœ¼ë¡œ ìë¦¬ì¡ì„ ê²ƒ. ì¿¼ë¦¬ ì¬ì‘ì„±/ì„¸ì…˜ ê¸°ë°˜ ê°œì¸í™”ê°€ ëŒ€ì¤‘í™”.\n",
            "- 3ë…„ ë‚´: íœ´ëŒ€í°/ë¸Œë¼ìš°ì € ë‚´ ê²½ëŸ‰ LLMì´ ì¿¼ë¦¬ ì „ì²˜ë¦¬Â·í›„ì²˜ë¦¬ë¥¼ ë‹´ë‹¹, í”„ë¼ì´ë²„ì‹œ ì¹œí™”ì  ê²€ìƒ‰ ê²½í—˜ì´ ë³´í¸í™”.\n",
            "- 5ë…„ ë‚´: ì¿¼ë¦¬ëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œê°€ ì•„ë‹ˆë¼ â€˜ëŒ€í™”í˜• ê³„ì•½â€™ì´ ëœë‹¤ â€” ì‚¬ìš©ìëŠ” í•œ ë²ˆì˜ ë¬¸ì¥ìœ¼ë¡œ ì¡°ëª…Â·ìš”ì•½Â·ë¹„êµÂ·ì‡¼í•‘ê¹Œì§€ ëë‚¸ë‹¤. ê·¸ë¦¬ê³  ê°€ë” LLMì´ ìœ ë¨¸ë¥¼ ì„ì–´ ë‹µë³€ì„ ì¤˜ì„œ ì‚¬ìš©ìë¥¼ ì¦ê²ê²Œ í•¨(ê·¸ë¦¬ê³  ê°€ë” ê³¼ì¥ë„ í•¨).\n",
            "\n",
            "ì—°êµ¬ìë“¤ê»˜ ê¶Œí•˜ëŠ” ì—°êµ¬ ì•„ì´ë””ì–´\n",
            "- ì¿¼ë¦¬ ë¶ˆí™•ì‹¤ì„± í‘œê¸°ë²•: ëª¨ë¸ì´ ìì‹ ê°Â·ë¶ˆí™•ì‹¤ì„±ì„ ìì—°ì–¸ì–´ë¡œ í‘œí˜„í•˜ë„ë¡ ì„¤ê³„í•˜ë¼.\n",
            "- ê°œì¸í™”ëœ ì¿¼ë¦¬ ë³´ì •ì˜ í”„ë¼ì´ë²„ì‹œ ë³´ì¥ ë°©ë²•: ë¡œì»¬ íŒŒì¸íŠœë‹, ì•”í˜¸í•™ì  ê¸°ë²• ì ìš©.\n",
            "- ë©€í‹°ëª¨ë‹¬ ì¿¼ë¦¬ì˜ ì‹ ë¢°ì„± í‰ê°€ í”„ë ˆì„ì›Œí¬: ì´ë¯¸ì§€ ê¸°ë°˜ ì¿¼ë¦¬ê°€ ì–¼ë§ˆë‚˜ ì‹ ë¢°ì„± ìˆëŠ” ê²°ê³¼ë¡œ ì´ì–´ì§€ëŠ”ì§€ ì •ëŸ‰í™”.\n",
            "- ë¹„ìš©-íš¨ìœ¨ì  RAG: ê²€ìƒ‰ í›„ë³´ ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ë©´ì„œë„ LLM ì‘ë‹µì˜ í’ˆì§ˆì„ ìœ ì§€í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜.\n",
            "- ì‚¬ìš©ì„± ì—°êµ¬: ì‹¤ì œ ì‚¬ìš©ì ì¸í„°ë™ì…˜ì—ì„œ LLM ê¸°ë°˜ ì¿¼ë¦¬ ì¬ì‘ì„±ì˜ ìˆ˜ìš©ì„±/ë¶ˆí¸ê° ì¡°ì‚¬.\n",
            "\n",
            "ì—í•„ë¡œê·¸ â€” ê²€ìƒ‰ì–´, ì´ì œëŠ” LLMì˜ ì—°ê·¹ ë¬´ëŒ€\n",
            "ê²€ìƒ‰ì–´ëŠ” ë‹¨ìˆœí•œ ë¬¸ìì—´ì´ ì•„ë‹ˆë¼, LLMì´ í•´ì„í•˜ê³  ë³´ê°•í•˜ê³  ì¦ê±°ë¥¼ ë‹¬ì•„ë‚´ë©° ê³µì—°í•˜ëŠ” â€˜ì‘í’ˆâ€™ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ ë¬´ëŒ€ì— ì„œì„œ ê´€ëŒë„ í•˜ê³ , ê°ë…ë„ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì›ƒê¸°ê³  ê³¼ì¥ëœ ë¯¸ë˜ë„ ìˆì§€ë§Œ í•µì‹¬ì€ ë¶„ëª…í•©ë‹ˆë‹¤: ì‚¬ìš©ì ì˜ë„ì— ì¶©ì‹¤í•˜ê³ , ì‚¬ì‹¤ì„±ì— ì±…ì„ì„ ì§€ë©°, í”„ë¼ì´ë²„ì‹œì™€ íš¨ìœ¨ì„±ì„ ì§€í‚¤ëŠ” ê¸°ìˆ ì´ ìŠ¹ìê°€ ë  ê²ë‹ˆë‹¤.\n",
            "\n",
            "ì›í•˜ì‹œë©´:\n",
            "- íŠ¹ì • ë…¼ë¬¸(ì˜ˆ: RAG ê´€ë ¨, query rewriting, retrieval-augmented reranking ë“±)ë“¤ì„ ë„£ì–´ ë…¼ë¬¸ ê¸°ë°˜ ë‰´ìŠ¤ë ˆí„°ë¡œ ìˆ˜ì •í•´ ë“œë¦½ë‹ˆë‹¤.\n",
            "- íŠ¹ì • ì²­ì¤‘(ì‹¤ë¬´ ì—”ì§€ë‹ˆì–´, í•™ê³„ ì—°êµ¬ì, ê²½ì˜ì§„ ë“±)ì— ë§ì¶˜ ë²„ì „ìœ¼ë¡œ í†¤Â·ë‚´ìš©ì„ ì¡°ì •í•´ ë“œë¦½ë‹ˆë‹¤.\n",
            "\n",
            "ì–´ë–¤ ì‹ìœ¼ë¡œ ë” ë‹¤ë“¬ì–´ ë“œë¦´ê¹Œìš”? ë…¼ë¬¸ ëª©ë¡ì„ ë˜ì ¸ì£¼ì‹œë©´, ê·¸ ë…¼ë¬¸ë“¤ ì¤‘ì‹¬ìœ¼ë¡œ ë” ì‚¬ì‹¤ì ì´ê³  ì¸ìš© ê°€ëŠ¥í•œ ë ˆí„°ë¡œ ì—…ê·¸ë ˆì´ë“œí•´ ë“œë¦½ë‹ˆë‹¤.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "multicampus",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}