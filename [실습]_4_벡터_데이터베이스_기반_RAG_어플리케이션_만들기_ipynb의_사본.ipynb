{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHQzg8LlBPiX"
      },
      "source": [
        "# [실습] 벡터 데이터베이스 기반 RAG 어플리케이션 만들기\n",
        "\n",
        "RAG는 Retrieval-Augmented Generation (RAG) 의 약자로,   \n",
        "LLM의 작동 과정에 검색을 결합하여 답변 성능을 높이는 어플리케이션입니다.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD8cevFKBPia"
      },
      "source": [
        "이번 실습에서는 뉴스 검색 데이터를 이용한 RAG를 수행해 보겠습니다.    \n",
        "코랩 GPU 사용을 위한 설정이 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcZZ-ssVvai7"
      },
      "source": [
        "### <필수> 실습을 진행하기 전, GPU를 T4로 설정해 주세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN-eQ45rvai7"
      },
      "source": [
        "## 라이브러리 설치  \n",
        "\n",
        "랭체인 관련 라이브러리와 벡터 데이터베이스 라이브러리를 설치합니다.  \n",
        "<br>\n",
        "\n",
        "`sentence_transformers`: 트랜스포머 계열의 공개 임베딩 모델을 사용할 수 있습니다.    \n",
        "`langchain_chroma`: ChromaDB를 이용해 벡터 데이터베이스를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHgrhVbLnM6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "6da1e653-e332-4310-fb5a-3ee332dba03e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dotenv in /usr/local/lib/python3.12/dist-packages (0.9.9)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4)\n",
            "Requirement already satisfied: langchain_chroma in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from dotenv) (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.35.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (1.0.0)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.57.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (1.16.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence_transformers) (4.15.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines) (25.4.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.35)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: chromadb<2.0.0,>=1.0.20 in /usr/local/lib/python3.12/dist-packages (from langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.3.0)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.37.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.23.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.19.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (34.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.25.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (25.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.1.10)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_huggingface) (1.33)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (2.1.2)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (1.0.0)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.0->langchain) (3.6.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.0.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.10)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.0->langchain) (1.11.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.29.5)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.38.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.38.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.59b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.7.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.22.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (1.1.1)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb<2.0.0,>=1.0.20->langchain_chroma) (15.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.1.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<2.0.0,>=1.0.20->langchain_chroma) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (3.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<2.0.0,>=1.0.20->langchain_chroma) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install dotenv langchain_huggingface sentence_transformers jsonlines langchain langchain-openai langchain-community langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numpy 2.2.5~2.2.6 버전 문제로 numpy 다운그레이드 필요\n",
        "!pip install \"numpy<2\""
      ],
      "metadata": {
        "id": "zaxUQ-Mnb5Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8787e4d-957e-4134-87ae-c3265cf3f90c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.12/dist-packages (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**코랩에서 실행 시, Restart 메시지가 나타납니다. 런타임을 재시작하여 패키지를 정리합니다.**"
      ],
      "metadata": {
        "id": "LFuqp34YoCKy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM과 임베딩 모델 구성하기   \n",
        "\n",
        "이번 실습에서는 LLM 모델과 함께 임베딩 모델이 필요합니다.   \n",
        "임베딩 모델은 텍스트를 벡터로 변환하며,    \n",
        "이후 결과를 벡터 DB에 저장해 검색할 수 있습니다."
      ],
      "metadata": {
        "id": "mRXSq8k7oLsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('env', override=True)\n",
        "\n",
        "if os.environ.get('OPENAI_API_KEY'):\n",
        "    print('OpenAI API 키 확인')"
      ],
      "metadata": {
        "id": "ce99R1nno2lR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16dbf52b-45e1-4228-bdc4-9e377c7b85c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI API 키 확인\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature = 0.7, max_tokens = 4096)"
      ],
      "metadata": {
        "id": "v9OFyTiRo5ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI의 `text-embedding-3-large` 는 빠른 속도로 연산이 가능하나, 비용이 발생하며 온라인 모델입니다.   \n",
        "이에 따라, 폐쇄망/온프레미스 환경에서는 공개 임베딩 모델을 사용하여 구현해야 합니다."
      ],
      "metadata": {
        "id": "OG7zn5MLpZlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "openai_embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
        "# 2024.1 출시 (낮은 성능)"
      ],
      "metadata": {
        "id": "ejt0rirQpfqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "허깅페이스에 게시된 공개 모델을 불러옵니다.   \n",
        "오픈 임베딩 모델에서 중요한 파라미터는 다음과 같습니다.\n",
        "\n",
        "- 파라미터 수 : 큰 임베딩 모델의 크기는 LLM에 육박합니다. GPU를 고려하여 선택합니다.\n",
        "- Max Tokens: 임베딩 모델의 최대 토큰보다 큰 데이터를 입력하면, 앞부분만을 이용해 계산하게 되므로 적절한 검색이 되지 않을 수 있습니다.\n",
        "- 임베딩 차원: 큰 차원의 벡터를 생성하는 임베딩 모델은 검색 속도가 감소합니다."
      ],
      "metadata": {
        "id": "U6Pyih7EsXBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재 한국어 데이터를 임베딩하기 위해 자주 사용하는 모델은 아래와 같습니다.\n",
        "\n",
        "- BGE-M3 (2GB, 8194 토큰 제한)   \n",
        "BGE-M3 시리즈는 BAAI의 임베딩 모델로, 현재 가장 인기가 많은 모델입니다.\n",
        "\n",
        "- KURE-V1 (2GB, 8194 토큰 제한)    \n",
        "KURE 임베딩은 고려대학교 NLP 연구실에서 만든 모델로, BGE-M3를 한국어 텍스트로 파인 튜닝한 모델입니다.\n",
        "\n",
        "- Qwen-3 Embedding (LLM 기반, 0.6, 4, 8B)     \n",
        "Qwen 3 Embedding은 2025년 5월 출시된  Qwen 3 LLM을 기반으로 만들어진 임베딩 모델로, 현재 다국어 임베딩 벤치마크에서 2,3,4등을 달성한 모델입니다."
      ],
      "metadata": {
        "id": "Z_vDnCC1s9sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Qwen 3 임베딩 모델을 불러옵니다."
      ],
      "metadata": {
        "id": "GluOS03tvScR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ~/.cache/huggingface\n"
      ],
      "metadata": {
        "id": "JCqmWmfVbotS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "\n",
        "# HuggingFace 임베딩 주소 지정하기\n",
        "# intfloat/multilingual-e5-small , baai/bge-m3, 등의 주소를 입력하여 지정\n",
        "# GPU에 여유가 있다면 Qwen3 Embedding의 큰 사이즈 (4B, 8B)?\n",
        "\n",
        "model_name = 'Qwen/Qwen3-Embedding-0.6B'\n",
        "#실제 주소: https://huggingface.co/Qwen/Qwen3-Embedding-0.6B\n",
        "\n",
        "# CPU 설정으로 모델 불러오기\n",
        "emb_model = SentenceTransformer(model_name, device='cpu',model_kwargs={'torch_dtype':torch.bfloat16})\n",
        "\n",
        "# 로컬 폴더에 모델 저장하기\n",
        "emb_model.save('./embedding')\n",
        "\n",
        "# 모델 메모리에서 삭제\n",
        "del emb_model\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "ZnESxjIJr2pk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711,
          "referenced_widgets": [
            "e065ad4a6bd248d99d0a4878fe4f9a2b",
            "3cc0610b5a6549438dbef03ebdce7254",
            "69d00a869e954730840839260380f6fb",
            "1d32165f92ea40eaa92031c6e3f80a06",
            "9b652c5df1344009a967185187e67334",
            "ed05235aaafe4706bd26c96dfb107876",
            "3a1336dc671c4619abc5c553eaf5cd06",
            "cc6267c0291b44d88910badf61760ca7",
            "5852f9b4bc3048b9ac760924f105f7e9",
            "38c7487f7c3948b59eb13a934f6eb09a",
            "c2b6434ccc9a46cf8243e78022d4513e",
            "1f1f3967abd74809be2ec4010ac40855",
            "1594d031d5924109b4045530c5fbdb83",
            "afe93cf083e0411a880fe54e7d319b91",
            "a22a688b576a4d4db73aa3808705dca4",
            "0140b187ca1045dcaab1ace86585985c",
            "00225e7899714ab4abad64e53beb06fa",
            "2d25cae750cd43d88671942b55f4414f",
            "99eb50177769461caaabd6baf43cb471",
            "68ae55891e794fcbbcb3aaf75ca312e0",
            "3006ff9e3bc24beab77f7502abb9cdf5",
            "cbfb8f3ab37e42a6b85d564301009283",
            "287707c9fb984499b9a1a6dc06509fa1",
            "253bc15954a24856ad1b8972d12e2b07",
            "1d9d467a089846d8bb62c2f5b8ff3c8f",
            "fd1814707df24081baec1fccaf9037cb",
            "27666c8556854567b4b56feee24b274a",
            "511ecabf6b824194aff9af31e568a14c",
            "70d06964a9514413a2f57ae8788eebea",
            "49d5a6e6394f4f888a3aca50e1a69063",
            "31cf5a8232a6423290ca445aa31d08a6",
            "2730ccb73ef74ac1853be2ea991de912",
            "368155f8052c45cdafa729cd45f0cf37",
            "5717ae2f4f8047f78d8baac61d2e1403",
            "b5d98809ab474c908dcc17a2f4e3d4ff",
            "678c17cb4141413d9036c864dd3979ca",
            "d7ec8242e4364abd91fdc3232424fa74",
            "1278ca3c8b074c25b337eae010b0493d",
            "0d4290702c014b7ba4bec6aa18a40e2c",
            "d3ea1c0fc964409dab573b8af99cfe09",
            "616c786e0d444ef2974221d21dbffde8",
            "db9a38195280404e923825b56488a28f",
            "0a6aab1e62a149ddad8dade9ccc72dff",
            "c4c8371b11f14c3596c1b7068ccaf33d",
            "55eef424495543b2948d0c37ea480375",
            "544f6f657a3640a3982b4a6b13ac849b",
            "2987e783ab5648e2aced99de301528a3",
            "21647f7f0e6543c1b73b3a3cdae69503",
            "1214fa89f16c49d39b30fc042280bf92",
            "e4cf366718e14ab5852af8e9701028f3",
            "c83f8ba3cca14bb6b6fa2ee97d25da21",
            "1f07913972de4a6b914c73fba3641320",
            "ec69e7cd5a3c45919a3f5d3f71029221",
            "42cc533fd89245069db0b13d070c2dc9",
            "fe60bef8d8bd46e8abc8300e908eb4aa"
          ]
        },
        "outputId": "215ae278-3589-4905-c74c-9f6676e3f8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e065ad4a6bd248d99d0a4878fe4f9a2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/215 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f1f3967abd74809be2ec4010ac40855"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "287707c9fb984499b9a1a6dc06509fa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5717ae2f4f8047f78d8baac61d2e1403"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.19G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55eef424495543b2948d0c37ea480375"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load the model for 'Qwen/Qwen3-Embedding-0.6B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Qwen/Qwen3-Embedding-0.6B' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1036\u001b[0m                 }\n\u001b[0;32m-> 1037\u001b[0;31m                 \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1170\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1172\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[1;32m   1722\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Xet Storage is enabled for this repo. Downloading file from Xet Storage..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m             xet_get(\n\u001b[0m\u001b[1;32m   1724\u001b[0m                 \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mincomplete_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mxet_get\u001b[0;34m(incomplete_path, xet_file_data, headers, expected_size, displayed_filename, _tqdm_bar)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         download_files(\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0mxet_download_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Data processing error: CAS service error : Reqwest Error: HTTP status server error (500 Internal Server Error), domain: https://cas-server.xethub.hf.co/reconstructions/f26bc1cc8f0165387549ed9f0c32730b050c188d06acd72375c2bb7c2ab1381d",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2432943398.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# CPU 설정으로 모델 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0memb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'torch_dtype'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# 로컬 폴더에 모델 저장하기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    325\u001b[0m                 \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             ):\n\u001b[0;32m--> 327\u001b[0;31m                 modules, self.module_kwargs = self._load_sbert_model(\n\u001b[0m\u001b[1;32m    328\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   2303\u001b[0m                 \u001b[0;31m# Newer modules that support the new loading method are loaded with the new style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m                 \u001b[0;31m# i.e. with many keyword arguments that can optionally be used by the modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2305\u001b[0;31m                 module = module_class.load(\n\u001b[0m\u001b[1;32m   2306\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m                     \u001b[0;31m# Loading-specific keyword arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model_name_or_path, subfolder, token, cache_folder, revision, local_files_only, trust_remote_code, model_kwargs, tokenizer_kwargs, config_kwargs, backend, **kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         )\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# Get the signature of the auto_model's forward method to pass only the expected arguments from `features`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, backend, is_peft_model, **model_args)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_mt5_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 self.auto_model = AutoModel.from_pretrained(\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    605\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4898\u001b[0m             )\n\u001b[1;32m   4899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4900\u001b[0;31m         checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n\u001b[0m\u001b[1;32m   4901\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4902\u001b[0m             \u001b[0msubfolder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_get_resolved_checkpoint_files\u001b[0;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0;31m# For any other exception, we throw a generic error.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m                 raise OSError(\n\u001b[0m\u001b[1;32m   1161\u001b[0m                     \u001b[0;34mf\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m                     \u001b[0;34m\" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load the model for 'Qwen/Qwen3-Embedding-0.6B'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'Qwen/Qwen3-Embedding-0.6B' is the correct path to a directory containing a file named pytorch_model.bin, tf_model.h5, model.ckpt or flax_model.msgpack."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-hAwOWJNb-10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "파일 시스템에 저장한 오픈 모델은 HuggingFaceEmbeddings로 불러옵니다."
      ],
      "metadata": {
        "id": "zhvxvXUDxqrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# 허깅페이스 포맷의 임베딩 모델 불러오기\n",
        "open_embeddings = HuggingFaceEmbeddings(model_name= './embedding',\n",
        "                                   model_kwargs={'device':'cuda'}) # gpu 사용하기\n",
        "\n",
        "# GPU 로드된 것 확인"
      ],
      "metadata": {
        "id": "vHcWMM23xpr_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "942922fa-f6fe-4418-a666-5c1322abeaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name ./embedding. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HFValidationError",
          "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './embedding'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    480\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './embedding'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1977659285.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 허깅페이스 포맷의 임베딩 모델 불러오기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m open_embeddings = HuggingFaceEmbeddings(model_name= './embedding',\n\u001b[0m\u001b[1;32m      5\u001b[0m                                    model_kwargs={'device':'cuda'}) # gpu 사용하기\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_huggingface/embeddings/huggingface.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         self._client = model_cls(\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    337\u001b[0m                 )\n\u001b[1;32m    338\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 modules = self._load_auto_model(\n\u001b[0m\u001b[1;32m    340\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_auto_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs, has_modules)\u001b[0m\n\u001b[1;32m   2110\u001b[0m         \u001b[0mconfig_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshared_kwargs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mshared_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         transformer_model = Transformer(\n\u001b[0m\u001b[1;32m   2113\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path, backend)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mconfig_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_peft_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m_load_config\u001b[0;34m(self, model_name_or_path, cache_dir, backend, config_args)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         if (\n\u001b[0;32m--> 138\u001b[0;31m             find_adapter_config_file(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/peft_utils.py\u001b[0m in \u001b[0;36mfind_adapter_config_file\u001b[0;34m(model_id, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, _commit_hash)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0madapter_cached_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         adapter_cached_filename = cached_file(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mADAPTER_CONFIG_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;31m# Now we try to recover if we can find all files correctly in the cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         resolved_files = [\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0m_get_cache_file_to_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfull_filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision, repo_type)\u001b[0m\n\u001b[1;32m    141\u001b[0m ):\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# We try to see if we have a cached version (not up to date):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     resolved_file = try_to_load_from_cache(\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         ):\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"token\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marg_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mREPO_ID_REGEX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0;34m\"Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;34m\" forbidden, '-' and '.' cannot start or end the name, max length is 96:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './embedding'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCiZIvxIvai8"
      },
      "source": [
        "RAG를 하기 전, 비교를 위해 LLM에게 질문해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5aalGFW30h5"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "llm.invoke(\"도메인 특화 언어 모델이란 무엇입니까? 어떤 예시가 있나요?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비하기    \n",
        "네이버 API를 통해, 검색어에 대한 뉴스 기사 링크를 가져오겠습니다.    \n"
      ],
      "metadata": {
        "id": "AxSz7qW0yCRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def get_naver_news_links(query, num_links=100):\n",
        "    \"\"\"\n",
        "    query와 num_links를 입력받아 네이버 검색 수행, 네이버 뉴스 URL의 기사만 수집\n",
        "    \"\"\"\n",
        "\n",
        "    url = f\"https://openapi.naver.com/v1/search/news.json?query={query}&display={num_links}&sort=sim\"\n",
        "    # 최대 100개의 결과를 표시\n",
        "    headers = {\n",
        "        'X-Naver-Client-Id': 'Ko6yIqbV2TOHq9rPH8tu',\n",
        "        'X-Naver-Client-Secret': 'BvqX8mNtHu'\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "    result = response.json()\n",
        "    # 특정 링크 형식만 필터링\n",
        "    filtered_links = []\n",
        "    for item in result['items']:\n",
        "        link = item['link']\n",
        "        if \"n.news.naver.com/mnews/article/\" in link:\n",
        "            # 네이버 뉴스 스타일만 모으기\n",
        "            filtered_links.append(link)\n",
        "\n",
        "    # 결과 출력\n",
        "    print(query, ':', len(filtered_links), 'Example:', filtered_links[0])\n",
        "    # for link in filtered_links:\n",
        "    #     print(link)\n",
        "\n",
        "    return filtered_links\n",
        "\n",
        "filtered_links = []\n",
        "for topic in ['도메인 특화 언어모델', 'OpenAI', 'GPT', '구글', '가전제품', '넷플릭스']:\n",
        "    filtered_links += get_naver_news_links(topic, 100)\n",
        "print('Total Articles:', len(filtered_links))\n",
        "print('Total Articles(Without Duplicate):',len(list(set(filtered_links))))\n",
        "filtered_links = list(set(filtered_links))"
      ],
      "metadata": {
        "id": "N2oonQePyFzX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52623b2c-a695-48d7-8433-662836e4474a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "도메인 특화 언어모델 : 24 Example: https://n.news.naver.com/mnews/article/031/0000972728?sid=105\n",
            "OpenAI : 28 Example: https://n.news.naver.com/mnews/article/123/0002369759?sid=101\n",
            "GPT : 90 Example: https://n.news.naver.com/mnews/article/021/0002743835?sid=102\n",
            "구글 : 89 Example: https://n.news.naver.com/mnews/article/008/0005264957?sid=105\n",
            "가전제품 : 28 Example: https://n.news.naver.com/mnews/article/082/0001349630?sid=101\n",
            "넷플릭스 : 36 Example: https://n.news.naver.com/mnews/article/003/0013544425?sid=104\n",
            "Total Articles: 295\n",
            "Total Articles(Without Duplicate): 295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8tnZzwABPid"
      },
      "source": [
        "## LangChain Document Loaders\n",
        "\n",
        "LangChain의 `document_loaders`는 다양한 형식의 파일을 불러올 수 있습니다.   \n",
        "[https://python.langchain.com/docs/integrations/document_loaders/ ]    \n",
        "\n",
        "Web URL로부터 페이지를 로드하는 기본 파서인 `WebBaseLoader`를 사용합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K21DHXavwoff"
      },
      "outputs": [],
      "source": [
        "# # Jupyter 분산 처리를 위한 설정 (코랩에서는 불필요)\n",
        "# import nest_asyncio\n",
        "\n",
        "# nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEmvVcecuqsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eab5e51-9722-459c-e64b-28b0fc1b5722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "Fetching pages: 100%|##########| 295/295 [00:08<00:00, 36.15it/s]\n"
          ]
        }
      ],
      "source": [
        "import bs4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "async def get_news_documents(links):\n",
        "    loader = WebBaseLoader(\n",
        "        web_paths=links,\n",
        "        bs_kwargs={'parse_only':bs4.SoupStrainer(class_=(\"newsct\", \"newsct-body\"))},\n",
        "                                # newsct, newsct-body만 추출 : 네이버 뉴스 포맷 HTML 요소\n",
        "\n",
        "        requests_per_second = 10, # 1초에 10개 요청 보내기\n",
        "        show_progress = True # 진행 상황 출력\n",
        "    )\n",
        "    # docs = loader.load() # 기본 코드\n",
        "\n",
        "    docs = []\n",
        "\n",
        "    async for doc in loader.alazy_load(): # 순차적 로드 대신 비동기 처리\n",
        "        docs.append(doc)\n",
        "    return docs\n",
        "\n",
        "docs = await get_news_documents(filtered_links)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73nVmzJLBPie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6891a474-825f-4e72-d901-60f53711e6e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://n.news.naver.com/mnews/article/655/0000027792?sid=101'}, page_content='\\n\\n\\n\\n\\nCJB청주방송\\n\\nCJB청주방송\\n\\n\\n구독\\n\\nCJB청주방송 언론사 구독되었습니다. 메인 뉴스판에서  주요뉴스를  볼 수 있습니다.\\n보러가기\\n\\n\\nCJB청주방송 언론사 구독 해지되었습니다.\\n\\n\\n\\n\\nPICK\\n안내\\n\\n\\n언론사가 주요기사로선정한 기사입니다.\\n언론사별 바로가기\\n닫기\\n\\n\\n\\n\\n삼성전자·SK하이닉스 강세...반도체 장비주 ‘급등세’\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n장원석 기자\\n\\n\\n\\n\\n\\n\\n\\n\\n장원석 기자\\n\\n\\n\\n\\n장원석 기자\\n\\n구독\\n구독중\\n\\n\\n\\n\\n구독자\\n0\\n\\n\\n응원수\\n0\\n\\n\\n\\n더보기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n입력\\n2025.10.10. 오후 2:24\\n\\n\\n\\n기사원문\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n추천\\n\\n\\n\\n\\n쏠쏠정보\\n0\\n\\n\\n\\n\\n흥미진진\\n0\\n\\n\\n\\n\\n공감백배\\n0\\n\\n\\n\\n\\n분석탁월\\n0\\n\\n\\n\\n\\n후속강추\\n0\\n\\n\\n \\n\\n\\n\\n댓글\\n\\n\\n\\n\\n\\n본문 요약봇\\n\\n\\n\\n본문 요약봇도움말\\n자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기 위해서는 기사 본문 전체보기를 권장합니다.\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n텍스트 음성 변환 서비스 사용하기\\n\\n\\n\\n성별\\n남성\\n여성\\n\\n\\n말하기 속도\\n느림\\n보통\\n빠름\\n\\n이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\\n본문듣기 시작\\n\\n닫기\\n\\n\\n \\n\\n글자 크기 변경하기\\n\\n\\n\\n가1단계\\n작게\\n\\n\\n가2단계\\n보통\\n\\n\\n가3단계\\n크게\\n\\n\\n가4단계\\n아주크게\\n\\n\\n가5단계\\n최대크게\\n\\n\\n\\n\\n\\n\\nSNS 보내기\\n\\n\\n\\n인쇄하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n뉴시스 제공삼성전자와 SK하이닉스의 주가가 나란히 강세를 보이면서 반도체 업종 전반에 매수세가 몰리고 있습니다.특히 반도체 장비주들은 일제히 급등세를 보이며 강한 상승 흐름을 이어가고 있습니다.10일 오전 10시 기준 반도체 장비업체인 원익홀딩스는 전 거래일 대비 29.31%(4300원) 오른 1만8970원에 거래됐습니다.같은 시각 한미반도체(15.41%), 엠케이전자(14.38%), 해성디에스(12.72%), 제주반도체(12.23%), 케이엔제이(10.24%), 피에스케이홀딩스(10.05%), 코미코(9.85%), 티엘엔지니어링(9.23%), 마이크로투나노(8.63%) 등도 동반 강세를 나타냈습니다.반도체주의 주가 급등세는 인공지능(AI) 반도체 수요 증가에 따른 수혜 기대감이 반영된 것으로 분석됩니다.챗GPT 개발사 OpenAI는 최근 국내 반도체 기업들에 월 90만 장 규모의 고대역폭메모리(HBM) 공급을 요청했습니다.이는 삼성전자·SK하이닉스·마이크론 등 글로벌 3사의 월간 생산량(약 39만 장)의 두 배를 넘는 수치입니다.아울러 OpenAI는 지난 6일 AMD와도 6GW 규모의 그래픽처리장치(GPU) 공급 계약을 체결한 것으로 알려졌습니다.허재환 유진투자증권 연구원은 \"이 같은 수요 전망은 국내 반도체 업계의 실적이 최소 2027년까지 크게 개선될 가능성을 높인다\"며 \"지난해 반도체 업계의 영업이익은 57조9000억원이었고, 올해는 70조원, 내년에는 95조원에 이를 것으로 예상된다\"고 분석했습니다.이어 \"단순 계산만으로도 OpenAI와의 장기 공급 계약이 연간 15~20% 수준의 추가 이익을 가져올 수 있다\"며 \"내년 반도체 업계의 영업이익은 2018년 고점을 넘을 가능성이 높아졌고, 현재 국내 반도체주의 밸류에이션(PER 10배 수준)은 부담스럽지 않은 수준\"이라고 덧붙였습니다.\\n\\t\\t\\n\\n\\n\\n장원석 wonseok123@gmail.com\\n\\n\\n\\n\\nCopyright ⓒ CJB청주방송. All rights reserved. 무단 전재 및 재배포 금지.\\n\\n \\n이 기사는 언론사에서 경제 섹션으로 분류했습니다.\\n\\n기사 섹션 분류 안내\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다.\\n닫기\\n\\n\\n\\n\\n기자 프로필\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n장원석 기자\\n\\n\\n\\n\\n\\n\\n\\n장원석 기자\\n\\n\\n\\nCJB청주방송\\n\\n\\n\\n\\n구독\\n\\n\\n구독중\\n\\n\\n\\n\\n\\n\\n\\n\\n\"광역철도 조기 착공하라\"...7개 자치단체장 집결\\n\\n\\n청주시 지적재조사 사업 속도... \"인력·예산 대폭 확대\"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n구독\\nCJB청주방송 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요!\\n\\n\\n구독중\\nCJB청주방송 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요!\\n\\n\\n언론사홈\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n네이버에서 CJB뉴스를 구독해주세요!\\nQR 코드를 클릭하면 크게 볼 수 있어요.\\n\\n\\n\\nQR을 촬영해보세요.\\n네이버에서 CJB뉴스를 구독해주세요!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCJB청주방송 바로가기\\nQR 코드를 클릭하면 크게 볼 수 있어요.\\n\\n\\n\\nQR을 촬영해보세요.\\nCJB청주방송 바로가기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n닫기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n이 기사를 추천합니다\\n\\n\\n기사 추천은 24시간 내 50회까지 참여할 수 있습니다.\\n닫기\\n\\n\\n\\n\\n\\n\\n쏠쏠정보\\n0\\n\\n\\n\\n\\n흥미진진\\n0\\n\\n\\n\\n\\n공감백배\\n0\\n\\n\\n\\n\\n분석탁월\\n0\\n\\n\\n\\n\\n후속강추\\n0\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n기자 구독 후 기사보기\\n\\n\\n\\n구독 없이 계속 보기\\n\\n\\n\\n\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "docs[12]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VohN5U6jzkbJ"
      },
      "source": [
        "크롤링 결과에는 불필요한 문자가 많이 포함되어 있습니다.    \n",
        "전처리를 통해 이를 제거합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VLH9vOHzls-"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def preprocess(docs):\n",
        "    noise_texts = [\n",
        "        '''구독중 구독자 0 응원수 0 더보기''',\n",
        "        '''쏠쏠정보 0 흥미진진 0 공감백배 0 분석탁월 0 후속강추 0''',\n",
        "        '''댓글 본문 요약봇 본문 요약봇''',\n",
        "        '''도움말 자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기 위해서는 기사 본문 전체보기를 권장합니다. 닫기''',\n",
        "        '''텍스트 음성 변환 서비스 사용하기 성별 남성 여성 말하기 속도 느림 보통 빠름''',\n",
        "        '''이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다. 본문듣기 시작''',\n",
        "        '''닫기 글자 크기 변경하기 가1단계 작게 가2단계 보통 가3단계 크게 가4단계 아주크게 가5단계 최대크게 SNS 보내기 인쇄하기''',\n",
        "        'PICK 안내 언론사가 주요기사로선정한 기사입니다. 언론사별 바로가기 닫기',\n",
        "        '응원 닫기',\n",
        "        '구독 구독중 구독자 0 응원수 0 ',\n",
        "    ]\n",
        "\n",
        "    def clean_text(doc):\n",
        "        text = doc.page_content\n",
        "        # 탭과 개행문자를 공백으로 변환\n",
        "        text = text.replace('\\t', ' ').replace('\\n', ' ')\n",
        "\n",
        "        # 연속된 공백을 하나로 치환\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # 여러 구분자를 한번에 처리\n",
        "        split_markers = [\n",
        "            '구독 해지되었습니다.',\n",
        "            '구독 메인에서 바로 보는 언론사 편집 뉴스 지금 바로 구독해보세요!'\n",
        "        ]\n",
        "        for marker in split_markers:\n",
        "            parts = text.split(marker)\n",
        "            if len(parts) > 1:\n",
        "                if marker == '구독 해지되었습니다.':\n",
        "                    text = parts[1]  # 뒷부분 사용\n",
        "                else:\n",
        "                    text = parts[0]  # 앞부분 사용\n",
        "\n",
        "        # 노이즈 텍스트 제거\n",
        "        for noise in noise_texts:\n",
        "            text = text.replace(noise, '')\n",
        "\n",
        "        # 연속된 공백을 하나로 치환\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        doc.page_content = text\n",
        "        return doc\n",
        "\n",
        "    preprocessed_docs = []\n",
        "    for doc in docs:\n",
        "\n",
        "        # 텍스트 정제\n",
        "        doc= clean_text(doc)\n",
        "        preprocessed_docs.append(doc)\n",
        "\n",
        "    return preprocessed_docs\n",
        "\n",
        "preprocessed_docs = preprocess(docs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9t26Ejavai-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578a2576-b943-459b-f3c5-f9b11e730410"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://n.news.naver.com/mnews/article/003/0013534408?sid=104'}, page_content='구글 \"印에 5년간 21조5280억원 투자…최대 규모 AI 허브 건설\" 유세진 기자 유세진 기자 유세진 기자 구독 입력 2025.10.14. 오후 8:35 수정 2025.10.14. 오후 10:17 기사원문 추천 320만㎞ 이상 기존 육상·해저 케이블과 연결 새 국제 해저 게이트웨이 건설\"커다 경제·사회적 기회 창출과 동시에 AI 능력의 세대교체 이끌 것\" [마운틴뷰(미 캘리포니아주)=AP/뉴시스]나렌드라 모디 인도 총리(오른쪽)가 2015년 9월27일 미 캘리포니아주 마운틴뷰의 구글 본사에서 순다르 피차이 구글 최고경영자(CEO)로부터 설명을 듣고 있다. 구글이 인도에 향후 5년 간 150억 달러(21조5280억원)를 투자해 인도 최초의 인공지능(AI) 허브를 구축하겠다고 14일 밝혔다. 2025.10.14.[뉴델리(인도)=AP/뉴시스] 유세진 기자 = 구글이 인도에 향후 5년 간 150억 달러(21조5280억원)를 투자해 인도 최초의 인공지능(AI) 허브를 구축하겠다고 14일 밝혔다.인도 남부 도시 비사카파트남에 위치할 이 AI 허브는 구글 역사상 세계 최대 규모의 허브 중 하나가 될 것이다. 구글은 기가와트 규모의 데이터 센터 운영, 광범위한 에너지 인프라, 확장된 광섬유 네트워크를 특징으로 할 것이라고 밝혔다.이번 투자는 구글이 AI 지배를 위한 글로벌 경쟁에서 핵심 기술과 인재 기반으로서 인도에 대한 의존도가 커지고 있음을 강조한다. 인도로서는 디지털 전환 야망을 가속화할 수 있는 규모로 고부가가치 인프라와 외국인 투자를 유치하게 된다.구글은 자사의 AI 허브 투자에 320만㎞ 이상의 기존 육상 및 해저 케이블과 연결되는 새로운 국제 해저 게이트웨이 건설이 포함될 것이라고 말했다.\"이 이니셔티브는 인도와 미국 모두에게 상당한 경제적, 사회적 기회를 창출하는 동시에 AI 능력의 세대 교체를 이끌 것\"이라고 구글 측은 밝혔다.순다르 피차이 구글 최고경영자(CEO)는 나렌드라 모디 인도 총리에게 회사의 야심찬 계획에 대해 설명했는데, 그는 소셜미디어 플랫폼 X에 \"(허브를 통해)인도의 기업과 사용자들에게 업계 선도 기술을 가져와 AI 혁신을 가속화하고 전국적으로 성장을 견인할 것\"이라고 말했다.모디 총리는 다각적인 투자가 선진국 건설을 위한 인도의 비전과 일치한다고 말했다. 그는 \"기술 민주화에 강력한 힘이 될 것이다. 또한 모든 사람을 위한 AI를 보장하고, 시민들에게 최첨단 도구를 제공하며, 디지털 경제를 활성화하고, 글로벌 기술 리더로서 인도의 위치를 확보할 것\"이라고 덧붙였다.인도의 기업 재벌 아다니 그룹은 성명을 통해 구글과 허브 개발을 위해 제휴했다고 밝혔다． 유세진 기자(dbtpwls@newsis.com) Copyright ⓒ 뉴시스. All rights reserved. 무단 전재 및 재배포 금지. 이 기사는 언론사에서 세계 섹션으로 분류했습니다. 기사 섹션 분류 안내 기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다. 닫기 기자 프로필 유세진 기자 유세진 기자 뉴시스 구독 구독중 달리던 印 버스에 불…최소 20명 사망 15명 중화상 美, 中항공사들의 러 영공 통과 금지 추진…中항공사들, 강력 반발 구독 뉴시스 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 구독중 뉴시스 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 언론사홈 뉴시스 주요뉴스해당 언론사에서 선정하며 언론사(아웃링크)로 이동합니다. 한채아 \"남편 차세찌, 팬티 구멍 나도 그냥 입더니…\" 이동국 딸 재시·설아 폭풍성장…아이돌 비주얼 \\'더 글로리\\' 정성일, 결혼 9년만에 이혼 송혜교, 수지 생일 축하…독보적 미모 여진구 군대 간다…\"너무 슬퍼 마세요\" 네이버 메인에서 뉴시스 구독하세요 QR 코드를 클릭하면 크게 볼 수 있어요. QR을 촬영해보세요. 네이버 메인에서 뉴시스 구독하세요 닫기 스타들이 빛나는 순간엔 \\'N샷\\' QR 코드를 클릭하면 크게 볼 수 있어요. QR을 촬영해보세요. 스타들이 빛나는 순간엔 \\'N샷\\' 닫기 뉴시스 언론사가 직접 선정한 이슈 이슈 3대 특검 \\'금거북이 매관매직\\' 이배용 오늘 특검 출석…참고인 신분 이슈 가자 휴전 \"가자 휴전후 군사 충돌 악화로 사망자 46명 달해 \"- 현지 소식통 이슈 러-우크라 전쟁 트럼프, 젤렌스키에 \"푸틴 조건 수용하라\" 압박…백악관서 고성 오가 이슈 캄보디아 납치 한국·캄보디아 경찰, 내일 양자회담…\\'코리안데스크\\' 논의 주목 이슈 국정자원 화재 마비 시스템 복구율 52.6%…과기부 업무포털 등 5개 추가 복구(종합) 이전 다음 이 기사를 추천합니다 기사 추천은 24시간 내 50회까지 참여할 수 있습니다. 닫기 기자 구독 후 기사보기 구독 없이 계속 보기')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "preprocessed_docs[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGKFZ9VrxV9Z"
      },
      "source": [
        "불러온 텍스트 데이터는 파일로 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1pr_kM8wxg1"
      },
      "outputs": [],
      "source": [
        "# 불러온 document 저장하기\n",
        "\n",
        "import jsonlines\n",
        "def save_docs_to_jsonl(documents, file_path):\n",
        "    with jsonlines.open(file_path, mode=\"w\") as writer:\n",
        "        for doc in documents:\n",
        "            writer.write(doc.model_dump())\n",
        "\n",
        "# jsonl 파일 불러오기\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "def load_docs_from_jsonl(file_path):\n",
        "    documents = []\n",
        "    with jsonlines.open(file_path, mode=\"r\") as reader:\n",
        "        for doc in reader:\n",
        "            documents.append(Document(**doc))\n",
        "    return documents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장\n",
        "save_docs_to_jsonl(preprocessed_docs, \"docs.jsonl\")"
      ],
      "metadata": {
        "id": "_1WhbuYzzGB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT7hRU6wBPie"
      },
      "source": [
        "## Chunking: 청크 단위로 나누기   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEyCdybpBPie"
      },
      "source": [
        "전처리가 완료된 docs를 chunk 단위로 분리합니다.\n",
        "`chunk_size`와 `chunk_overlap`을 이용해 청크의 구성 방식을 조절할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMrSdeV4vai-"
      },
      "source": [
        "Chunk Size * K(검색할 청크의 수) 의 결과가 Context의 길이가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "4SopeO4tBPie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8371703e-5c0e-4111-fde9-a39e7cbff38f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "991\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "# from langchain import hub\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "# 0~1000, 800~1800, 1600~2600, ...\n",
        "# 실제로는 구분자(공백,엔터,탭 등) 를 기준으로 자르므로 정확히 일치하지는 않음\n",
        "chunks = text_splitter.split_documents(preprocessed_docs)\n",
        "print(len(chunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIb2-nkpvai-"
      },
      "source": [
        "## Vector DB 구성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwbv-FQ2BPif"
      },
      "source": [
        "구성된 청크를 ChromaDB 벡터 데이터베이스에 로드합니다.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAAhmf2GBPif"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "Chroma().delete_collection() # (메모리에 저장하는 경우) 기존 데이터 삭제\n",
        "\n",
        "# DB 구성하기\n",
        "db = Chroma(embedding_function=openai_embeddings,\n",
        "            persist_directory=\"./chroma_OpenAI\",\n",
        "            # 파일 시스템에 저장 (생략시 메모리에 저장)\n",
        "\n",
        "            collection_name='Web', # 식별 이름\n",
        "\n",
        "            collection_metadata={'hnsw:space':'l2'},\n",
        "            # l2 메트릭 설정(기본값, cosine, mmr 로 변경 가능)\n",
        "            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4nWgcq4vai_"
      },
      "source": [
        "DB에 document를 추가합니다.    \n",
        "OpenAI 임베딩은 30만 토큰 동시 처리 제한이 있어, 나눠서 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXObsTlovai_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c87c23-183e-4028-87c2-d4c0a42e7f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:24<00:00,  2.43s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "print(len(chunks))\n",
        "# 300,000 토큰 제한\n",
        "\n",
        "# 100개씩 추가\n",
        "for i in tqdm(range(0, len(chunks), 100)):\n",
        "    db.add_documents(chunks[i:min(i+100, len(chunks))])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIuEJaToBPif"
      },
      "source": [
        "db로부터 retriever를 구성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4AhVSXLBPif"
      },
      "outputs": [],
      "source": [
        "# Top 5 Search(기본값은 4)\n",
        "retriever = db.as_retriever(search_kwargs={'k':5})\n",
        "\n",
        "# Top 5 Chuck * Chuck Size 1000 = 5000 글자 Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLCZKMIRnvi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53db3eca-49a1-45a5-db18-7b77b90957dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='01e6e678-c792-40c1-8e64-5fe93d3e7715', metadata={'source': 'https://n.news.naver.com/mnews/article/015/0005163430?sid=105'}, page_content='SKT·크래프톤, 언어모델 공동 개발…\"수학 추론에 특화\" 박수빈 기자 박수빈 기자 박수빈 기자 구독 입력 2025.07.28. 오전 10:07 기사원문 추천 게임 AI 고도화 위한 한국형 LLM도메인 특화 AI 모델 개발 역량 입증 SK텔레콤 사옥과 크래프톤 로고. 사진=SK텔레콤, 한경DBSK텔레콤과 크래프톤이 공동으로 개발한 언어모델을 공개했다. 크래프톤은 이 모델에 적용한 학습 기법을 게임 특화형 AI 응용 기술을 고도화하는 데 활용한다. SK텔레콤은 28일 크래프톤과 공동으로 개발한 7B(70억개 파라미터) 규모의 추론 특화 언어 모델 3종을 공개했다.이번에 공개한 모델은 수학 문제 해결과 코드 개발에 특화된 소형 언어 모델이다. 크래프톤이 독자적으로 개발한 학습 기법을 적용한 것이 특징이다.이 기법을 바탕으로 해당 모델은 수학 추론 벤치마크 AIME 25에서 뚜렷한 성능 향상을 기록했다. 수학은 게임을 포함한 고난도 추론 분야와 기술적으로 밀접한 연관성을 갖는다. 공간지각과 논리 추론 역량이 요구돼서다. 크래프톤은 해당 모델을 기반으로 게임 중심의 AI 기술 확장 가능성도 기대하고 있다. 양사 간 협력은 도메인 특화 AI 모델 개발 역량을 입증한 사례로 평가된다. SK텔레콤과 크래프톤은 각각 인프라를 구축하고 학습 기법을 개선해 모델 품질과 성능을 고도화했다.크래프톤은 기존 모델의 취약점을 분석해 이를 개선하는 오답 복기 학습 기법을 자체 개발했다. 틀린 문제의 정답을 찾아 오답과 비교해 학습하며 추론 정확도와 효율성을 동시에 확보하는 전략적 학습 방식이다. SK텔레콤은 데이터 검증과 모델 학습의 인프라 구축을 담당해 모델의 품질과 안정성을 확보했다.크래프톤은 이번 언어 모델에 적용한 학습 기법을 게임 플레이 분석, 전략 판단 등 게임 특화형 AI 응용 기술 고도화에 활용할 계획이다. 나아가 다양한 규모의 LLM을 개발해, 한국형 AI 기술 생태계의 독립성과 주도권을 확보하는 데 기여할 방침이다.언어 모델은 글로벌 오픈소스 플랫폼인 허깅페이스를 통해'),\n",
              " Document(id='ab1b3784-01f3-4da1-b457-643988262193', metadata={'source': 'https://n.news.naver.com/mnews/article/030/0003350666?sid=105'}, page_content=\"AI 특화 모델 개발, '대기업 참여 제한'으로 강소기업 각축전 박종진 기자 박종진 기자 박종진 기자 구독 입력 2025.09.15. 오후 2:21 기사원문 추천 과학기술정보통신부와 정보통신산업진흥원(NIPA)이 15일 서울 양재동 엘타워에서 '인공지능(AI) 특화 파운데이션 모델 프로젝트' 사업설명회가 열리고 있다. 장기철 과기정통부 과장이 프로젝트에 대해 설명하고 있다. ⓒ박종진기자정부가 새롭게 추진하는 독자 인공지능(AI) 특화 파운데이션 모델 개발 프로젝트에 AI 강소기업이 대거 참여한다.독자 AI 파운데이션 모델 5개 정예팀 주관기업과 모델 개발에 직접 참여하는 기업, 대기업(컨소시엄 주관 불가)의 프로젝트 참여가 제한되며 버티컬 AI 플랫폼 기업이나 거대언어모델(LLM)이 있는 AI 강소기업 간 치열한 경쟁을 벌일 전망이다.특히 솔트룩스, 코난테크놀로지, 모티프테크놀로지스, 트릴리온랩스, 투모로로보틱스, 루닛 등 독자 AI 모델 프로젝트에 도전했던 AI 강소기업들이 대거 참여할 것으로 보인다. 마키나락스, 이스트소프트 등 독자 AI 모델 5개 정예팀 참여기업 중 모델 개발을 직접 담당하지 않는 기업도 참여를 검토하고 있다.과학기술정보통신부는 15일 서울 양재동 엘타워에서 350억원 규모 예산이 투입되는 'AI 특화 파운데이션 모델 프로젝트' 사업설명회를 개최했다. LG·업스테이지·네이버·SK·NC 등 독자 AI 모델 5개 정예팀이 개발하는 범용 AI 모델과 별도로 추진되는 특정 산업 분야에 특화된 AI 모델 개발 프로젝트다.우리나라가 강점이 있는 특정 분야 적용 또는 확장 가능한 모델·기술을 개발, 글로벌 시장을 선점할 독자 AI 특화 모델과 서비스 개발을 목표로 한다. 의료·제조·로봇·국방·법률 등 산업 특화 버티컬 AI 모델 개발을 통해 국가 AI 경쟁력을 강화하겠다는 것이다. 독자 AI 특화 파운데이션 모델 프로젝트 개요. 과기정통부 제공독자 AI 특화 모델 개발은 해외 모델 튜닝 없이 자체 기술로 개발하는 프롬 스크래치 또는 범용 AI 모델을\"),\n",
              " Document(id='44051132-bcac-428c-9b06-4693cb8a2eba', metadata={'source': 'https://n.news.naver.com/mnews/article/008/0005053876?sid=101'}, page_content=\"포티투마루, '2024 AI&빅데이터쇼'서 도메인 특화 LLM과 생성형 AI 솔루션 선봬 입력 2024.06.21. 오후 4:32 수정 2024.06.21. 오후 4:32 기사원문 추천 포티투마루(대표 김동환)는 19일부터 21일까지 3일간 코엑스에서 열리는 '2024 AI&빅데이터쇼'와 '스마트테크코리아 2024'에 참가해 도메인 특화 설치형 LLM(대규모 언어 모델)와 생성형 AI 솔루션 'DocuAgent42'를 선보였다고 밝혔다. 사진제공=포티투마루스마트테크코리아 2024는 단일 국내 최대 규모의 ICT 행사로 AI&빅데이터쇼, 스마트테크쇼, 리테일테크쇼, 로봇테크쇼, 시큐테크쇼 등 총 5개의 전문 전시회로 구성됐으며, 코엑스 1층 A, B홀, 3층 C홀에서 진행된다. 포티투마루는 AI&빅데이터쇼에 참가해 도메인 특화 설치형 LLM 및 생성형 AI 솔루션을 선보였다. 도메인 특화 설치형 LLM은 특정 산업 분야의 요구와 특성에 최적화한 경량화 언어 모델로, 질의 응답, 문서 요약, 초안 작성, 문서 분류 등 다양한 자연어 처리 기능을 수행하며 이를 통해 복잡한 업무를 자동화 할 수 있다. 사진제공=포티투마루포티투마루의 도메인 특화 설치형 LLM과 생성형 AI 솔루션은 국내외 전자, 통신, 금융, 자동차, 조선해양, 엔지니어링, 커머스, 리테일, 교육, 법률, 헬스케어, 국방 등 다양한 산업 분야에서 정확하고 효율적인 데이터 처리를 통해 업무 효율성을 높이고 비용을 절감해 비즈니스 고도화와 고객 서비스 향상에 중요한 도구가 된다.특히 네이버클라우드의 하이퍼클로바 X, LG U+의 익시젠, 구글의 제미나이 프로 및 포티투마루의 자체 초거대 AI LLM42까지 글로벌 및 국내 리딩 IT 기업과의 전략적 협력을 통해 산업별로 특화한 LLM을 설치형으로 제공하고 있다. 포티투마루는 LLM, RAG 및 MRC 기술을 활용한 생성형 AI 서비스인 DocuAgent42도 함께 선보였다. 기업 내 보유 중인 다양한 유형의 문서 파일과 웹 문서를 검색 혹은 대화형\"),\n",
              " Document(id='8988e12c-9ff6-44d7-bd74-55be71bb9ee9', metadata={'source': 'https://n.news.naver.com/mnews/article/138/0002204421?sid=105'}, page_content='코난테크, 軍 도메인 특화 AI 모델 개발 이나연 기자 이나연 기자 이나연 기자 구독 입력 2025.09.09. 오전 9:52 기사원문 추천 국방기관 생성형 에이전틱 AI 실증 사업 수주 [ⓒ 코난테크놀로지][디지털데일리 이나연 기자] 인공지능(AI) 소프트웨어 전문기업 코난테크놀로지가 군사 분야에서 전략적으로 중요한 거대언어모델(LLM) 도입 사업을 수주했다고 9일 밝혔다.코난테크놀로지가 착수한 국방 기관의 ‘생성형 기반 에이전틱 AI 실증’ 사업은 국방 도메인 특화 실증을 위해 추진됐다. 국군 환경에 최적화된 AI 플랫폼과 도메인 특화 LLM을 구축해 군사정보 기반 의사결정 지원 및 역량을 대폭 강화하는 것이 목표다. 군사 분야에 LLM 도입 자체가 이례적이라는 게 회사 측 설명이다.코난테크놀로지는 자체 개발 대규모 언어모델 ‘코난 LLM’을 활용해 방대한 군사용어 데이터를 바탕으로 맞춤형 학습과 미세조정을 진행한다. 최신 검색증강생성(RAG) 기술을 적용해 정보 생성과 요약, 번역기능을 제고하며, AI 에이전트 기반의 검색 및 에이전틱 기능으로 실무자들이 빠르고 정확한 의사결정을 내릴 수 있도록 지원하는 데 중점을 둔다.코난 LLM은 한국남부발전, 한림대의료원에서 실무 적용됐고, 최근 경기도청, 대법원, 한국서부발전, 한국동서발전의 생성형 AI 사업에도 도입이 확정됐다. 특히 보안 요구가 높은 공공·국방·의료 분야에서 LLM 레퍼런스를 확보하고 있다.코난테크놀로지의 국방 분야 진출은 2006년 국방부에 통합검색엔진 ‘코난 서치’를 납품하며 시작했다. 이후 육·해·공군 및 주요 사령부로 고객층을 확대했고, 영상 객체 식별 기반 AI 솔루션 ‘코난 와처’를 중심으로 국방 AI 수요에 본격적으로 사업을 착수했다.현재는 ▲인식 및 판단 ▲플랫폼 구축 ▲스마트 전력지원 분야에서 20여개 국방 기관과 사업을 수행하고 있다. 육군 교육사령부의 밀리터리 이미지넷 구축, 국방부의 국방 지능형 플랫폼, 공군 전력지원체계 사업단의 AI 기반 공중전투기동훈련체계(ACMI)'),\n",
              " Document(id='3b53b516-553d-4d4c-8ccf-2f6f347b24f4', metadata={'source': 'https://n.news.naver.com/mnews/article/029/0002981187?sid=105'}, page_content='코난테크놀로지, ‘군사 도메인 특화 LLM’ 사업 맡는다 임성원 기자 TALK 임성원 기자 임성원 기자 TALK 구독 입력 2025.09.09. 오후 5:06 수정 2025.09.09. 오후 7:28 기사원문 추천 인공지능(AI) 소프트웨어 전문기업 코난테크놀로지는 군사 분야에서 전략적으로 중요한 거대언어모델(LLM) 도입 사업을 최근 수주해 실무에 착수했다고 9일 밝혔다.이번 사업은 국방 기관의 생성형 기반 에이전틱 AI를 실증하는 것으로 국방 도메인 특화 실증을 위해 추진됐다. 국군 환경에 최적화된 AI 플랫폼과 도메인 특화 LLM을 구축해 군사정보 기반의 의사결정 지원 및 역량을 대폭 강화하는 것을 목표로 한다.코난테크놀로지는 군사 분야의 특수성 상 발주처와 사업 규모는 밝히지 않았다.회사 측은 \"군사 분야 LLM 도입 자체가 이례적\"이라며 \"축적된 국방 AI 전문 역량을 다시 한번 입증했다\"고 강조했다. 앞서 코난테크놀로지는 지난 2006년 국방부에 통합검색엔진 \\'코난 서치\\'를 납품한 이후 육·해·공군 및 주요 사령부로 사업을 확대했다.코난테크놀로지는 자체 개발 대규모 언어모델 \\'코난 LLM\\'을 활용해 방대한 군사용어 데이터를 바탕으로 맞춤형 학습과 미세조정을 진행한다. 최신 검색증강생성(RAG) 기술을 적용해 정보 생성과 요약, 번역 기능을 고도화한다. AI 에이전트 기반의 검색 및 에이전틱 기능을 통해 실무자들이 빠르고 정확한 의사결정을 내릴 수 있도록 지원한다.사업 완료 시 군사정보 수집과 처리 자동화를 실현해 정밀 분석·보고·다국어 대응 등 혁신적인 정보작전 역량을 확보할 것으로 기대한다. 김규훈 코난테크놀로지 국방AI 사업부 이사는 \"전장을 판단하는 에이전트를 적용함으로써 지휘결심 지원을 첨단화하는데 힘쓰겠다\"고 말했다.임성원 기자 sone@dt.co.kr 코난테크놀로지가 군사 분야 관련 거대언어모델(LLM) 도입 사업을 수주했다. 코난테크놀로지 제공 임성원 기자(sone@dt.co.kr) Copyright ⓒ 디지털타임스. All rights')]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "retriever.invoke(\"도메인 특화 언어 모델\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7i4qL0ZBPif"
      },
      "source": [
        "## Prompting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5QpFAyVMYpV"
      },
      "source": [
        "RAG를 위한 간단한 프롬프트를 작성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BiDkZRlBPig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff92dd2e-d449-44e4-d5d0-90d52d724a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
            "다음의 Context를 이용하여 Question에 답변하세요.\n",
            "정확한 답변을 제공하세요.\n",
            "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
            "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
            "---\n",
            "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
            "---\n",
            "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate([\n",
        "    (\"user\", '''당신은 QA(Question-Answering)을 수행하는 Assistant입니다.\n",
        "다음의 Context를 이용하여 Question에 답변하세요.\n",
        "정확한 답변을 제공하세요.\n",
        "만약 모든 Context를 다 확인해도 정보가 없다면,\n",
        "\"정보가 부족하여 답변할 수 없습니다.\"를 출력하세요.\n",
        "---\n",
        "Context: {context}\n",
        "---\n",
        "Question: {question}''')])\n",
        "\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C09vkykMwXo"
      },
      "source": [
        "## Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H98LGZRVBPig"
      },
      "source": [
        "RAG를 수행하기 위한 Chain을 만듭니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kqWGHwuBPig"
      },
      "source": [
        "RAG Chain은 프롬프트에 context와 question을 전달해야 합니다.    \n",
        "Question을 입력받아, Context를 함께 프롬프트에 전달합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEr1E0zbBPig"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# retriever의 결과물은 List[Document] 이므로 이를 ---로 구분하는 함수\n",
        "# metadata의 source를 보존하여 추가\n",
        "def format_docs(docs):\n",
        "    return \" \\n---\\n \".join(['URL: '+ doc.metadata['source'] + '\\nContent: '+ doc.page_content+ '\\n' for doc in docs])\n",
        "    # join : 구분자를 기준으로 스트링 리스트를 하나의 스트링으로 연결\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    # retriever : question을 받아서 context 검색: document 반환\n",
        "    # format_docs : document 형태를 받아서 텍스트로 변환\n",
        "    # RunnablePassthrough(): 체인의 입력을 그대로 저장\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV9-CYSzBPig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "ac75639a-708d-4f24-905b-33cb10e0e6cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'도메인 특화 언어 모델이란 특정 산업 분야나 주제 영역(도메인)에 최적화되어 개발된 언어 모델을 말합니다. 이러한 모델은 해당 도메인에서 요구되는 전문 지식, 용어, 문제 해결 방식 등에 맞춰 학습되어, 일반 범용 모델보다 높은 정확도와 효율성을 보입니다.\\n\\n예시로는 다음과 같은 도메인 특화 언어 모델들이 있습니다:\\n\\n1. **SK텔레콤과 크래프톤의 수학 추론 특화 언어 모델**  \\n   - 70억 개 파라미터 규모의 소형 언어 모델로, 수학 문제 해결과 코드 개발에 특화되어 있음.  \\n   - 크래프톤이 개발한 오답 복기 학습 기법을 적용해 추론 정확도와 효율성을 높였음.  \\n   - 게임 AI 고도화를 위해 게임 플레이 분석 및 전략 판단 등 게임 특화 AI 응용 기술에도 활용.\\n\\n2. **LG유플러스와 KODATA의 기업·금융 특화 AI 파운데이션 모델**  \\n   - 금융 및 기업 데이터를 바탕으로 한 맞춤형 AI 서비스 제공.  \\n   - 기업 신용 평가, 재무 분석 등 금융권 업무에 특화된 대화형 AI 및 리포트 자동 생성 기능 포함.  \\n   - DACP 기술을 적용해 산업별 특화 데이터로 모델 정확도와 도메인 이해도 향상.\\n\\n3. **코난테크놀로지의 군사 도메인 특화 LLM**  \\n   - 국방 환경에 최적화된 AI 플랫폼과 맞춤형 학습을 거친 군사 분야 특화 언어 모델.  \\n   - 군사정보 기반 의사결정 지원, 정보 생성 및 요약, 다국어 대응 등 기능 강화.  \\n   - 최신 검색증강생성(RAG) 기술 적용.\\n\\n4. **포티투마루의 도메인 특화 설치형 LLM**  \\n   - 전자, 통신, 금융, 자동차, 법률, 헬스케어, 국방 등 다양한 산업 분야에 맞춰 경량화 및 최적화된 언어 모델.  \\n   - 질의응답, 문서 요약, 초안 작성 등 자연어 처리 기능 제공.\\n\\n요약하면, 도메인 특화 언어 모델은 특정 산업이나 분야의 요구에 맞추어 설계되고 학습된 AI 모델로, 해당 분야의 업무 효율성과 정확도를 높이는 데 활용되고 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "rag_chain.invoke(\"도메인 특화 언어 모델이란 무엇입니까? 어떤 예시가 있나요?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0j9J2CpsBPig",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "81574e0a-7ca7-4cd7-a811-8c6a2130e262"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"인공지능의 최근 발전 방식은 다음과 같습니다.\\n\\n- AI가 사람의 목소리, 제스처, 시각을 직관적으로 이해하는 멀티모달 능력을 갖추고 있으며, 이를 기반으로 한 AI 인터페이스가 가능해지고 있습니다.\\n- XR(eXtended Reality, 확장현실) 기술과 결합하여 가상현실(VR), 증강현실(AR), 혼합현실(MR) 등 현실과 가상을 융합한 새로운 경험을 제공하는 기술군이 발전하고 있습니다.\\n- 구글의 제미나이(Gemini) 모델이 세일즈포스 차세대 AI 플랫폼인 '에이전트포스 360'에 탑재되어, 이메일 작성, 일정 예약, 고객관리 데이터 분석 등 다양한 업무를 처리하는 AI 에이전트로 활용되고 있습니다.\\n- AI 에이전트를 안전하고 통제 가능한 방식으로 기업 환경에 통합하는 데 집중하고 있으며, 이를 통해 업무 생산성 향상과 글로벌 경쟁력 확보를 기대하고 있습니다.\\n- 초지능(Super Intelligence) 단계의 AI가 AGI(Artificial General Intelligence) 등장 후 스스로 진입할 것으로 전망되며, 과학·예술·의학·공학·사회·감정 등 모든 영역에서 인간을 뛰어넘는 문제 해결 능력과 창의성, 추론 능력을 갖출 것으로 예상됩니다.\\n\\n관련 기사 링크:  \\nhttps://n.news.naver.com/mnews/article/421/0008544124?sid=105\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "rag_chain.invoke(\"인공지능의 최근 발전 방식은? 관련 링크도 보여주세요\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhgi0WUEzxvF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7304b69-386c-4ef3-fc34-5c929c7ab527"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'정보가 부족하여 답변할 수 없습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "rag_chain.invoke(\"알리바바의 언어 모델 이름은?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37hTqiCOzxvF"
      },
      "source": [
        "assign()을 이용하면, 체인의 결과를 받아 새로운 체인에 전달하고, 그 결과를 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lirfP5Q-HyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "019c21ec-feaf-41fd-c5c2-4b6bd7562466"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'URL: https://n.news.naver.com/mnews/article/421/0008544124?sid=105\\nContent: 경험을 제공하는 기술군 전체를 의미한다.■ 초지능초지능(Super Intelligence)은 인간의 지능을 모든 분야에서 뛰어넘는 인공지능 시스템을 말한다. AGI 등장 시 스스로 초지능 단계로 진입할 것으로 전망한다. 과학·예술·의학·공학·사회·감정 등 모든 영역에서 인간보다 월등한 문제 해결 능력과 창의성·추론 능력을 갖출 것으로 보인다. 김민석 기자 (ideaed@news1.kr) Copyright ⓒ 뉴스1. All rights reserved. 무단 전재 및 재배포, AI학습 이용 금지. 이 기사는 언론사에서 IT, 경제 섹션으로 분류했습니다. 기사 섹션 분류 안내 기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다. 닫기 기자 프로필 김민석 기자 김민석 기자 뉴스1 구독 구독중 \"179만원 아이폰 이게 말이 되나\"…아이폰17 변색 전세계 확산 오픈AI, 브로드컴 손잡고 \\'AI 칩\\' 직접설계…엔비디아 독점 균열 구독 뉴스1 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 구독중 뉴스1 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 언론사홈 뉴스1 주요뉴스해당 언론사에서 선정하며 언론사(아웃링크)로 이동합니다. 모델 꿈 안고 태국 간 미모의 20대 장기적출…동남아 전체가 \\'위험지대\\' \"근육질 남편, 5년간 부부관계 단 1회…위자료 가능?\" \"결혼 전 성병 치료 아내 \\'완치\\' 당당, 계속 살아야 하나\" \\'10일간 발기\\' 40대, 뒤늦게 병원갔지만 \"영구 손상\" \"누가 오나 보려고\"…장례식 열고 화장 직전 일어난 男 K팝·K트롯 팬들의 놀이터, 스타1픽 QR 코드를 클릭하면 크게 볼 수 있어요. QR을 촬영해보세요. K팝·K트롯 팬들의 놀이터, 스타1픽 닫기 세상에 이런 일이...[사건의 재구성] QR 코드를 클릭하면 크게 볼 수 있어요. QR을 촬영해보세요. 세상에 이런 일이...[사건의 재구성] 닫기 뉴스1 언론사가 직접 선정한 이슈 이슈 3대\\n \\n---\\n URL: https://n.news.naver.com/mnews/article/277/0005666280?sid=104\\nContent: \"챗GPT로 숙제하면 사고능력 저하\"…청소년 보호 칼 빼든 미국 이현우 기자 이현우 기자 이현우 기자 구독 입력 2025.10.19. 오전 6:00 수정 2025.10.19. 오전 6:01 기사원문 추천 AI가 가져온 어린이 \\'인지부채\\' 문제뇌신경 연결성 80% 이상 낮아져 미 당국, 어린이·청소년 위한 대책마련 지시 챗GPT와 같은 AI 챗봇을 과제 작성에 이용할 때 인지능력에 악영향을 받을 수 있다는 연구 결과가 나왔다. AP연합뉴스챗GPT를 비롯한 생성형 인공지능(AI) 챗봇이 어린이와 청소년 학습에 부정적 영향을 끼친다는 우려가 확산되고 있다. AI를 활용한 과제 해결이 잦아지면 결국 사고력 저하가 누적돼 인지능력을 크게 약화시키는 일명 \\'인지부채(cognitive debt)\\'를 유발한다는 것이다. 미국 당국에서도 AI 챗봇을 운용 중인 기업들에 어린이와 청소년들의 접근을 제한할 대책마련을 지시했지만, 이미 교육현장에 퍼진 AI의 영향력을 약화시키기에는 어려움이 클 것으로 예상되고 있다. AI 챗봇 사용, 뇌신경 연결성 83% 저하…인지부채 유발 미국 캘리포니아주의 한 고등학교에서 챗GPT를 이용한 수업 모습. AP연합뉴스미국의 융합기술 연구기관인 MIT 미디어랩의 지난 6월 조사에 따르면 챗GPT와 같은 AI 챗봇을 과제 작성에 이용할 때 인지능력에 악영향을 받을 수 있다는 연구 결과가 나왔다. MIT 미디어랩은 18~39세 나이의 참가자 54명을 대상으로 AI 챗봇을 활용해 에세이를 작성한 그룹과 스스로 작성한 그룹을 비교한 결과 AI 챗봇을 활용한 참가자들의 뇌신경간 연결성이 스스로 작성한 지원자보다 83% 낮게 나타났다고 밝혔다. 연구진은 참가자들의 뇌파를 측정해 뇌신경들의 움직임과 뇌 활동을 기록했다. AI 챗봇을 사용한 참가자들의 뇌신경은 스스로 작성한 그룹과 비교해 활성화 빈도도 크게 떨어졌으며 다른 뇌신경들과의 교류빈도도 약했다. 외부에서 주어진 정보가 많은만큼 스스로 판단하고 분석하는 활동이 적어졌기 때문으로 분석된다. 에세이 작성 후\\n \\n---\\n URL: https://n.news.naver.com/mnews/article/092/0002392777?sid=105\\nContent: 있다\"고 말했다.그러면서 \"AI가 고도화되면서 시스템에 넣기만 하면 쓸 수 있는 패키지 형태도 등장하고 있다. 공공 영역에서는 중앙부처, 지자체, 국방·방산, 국민 대상 서비스 등으로 초거대 AI 활용이 확산되고 있다\"라며 \"정부 차원의 준비도 활발하다. 다양한 사례를 접해 AI 네이티브 역량을 키우고, 업무 생산성을 높여 글로벌 경쟁력까지 확보하기를 기대한다\"라며 강연을 마쳤다. 이도원 기자(leespot@zdnet.co.kr) Copyright ⓒ ZDNet Korea. All rights reserved. 무단 전재 및 재배포 금지. 이 기사는 언론사에서 IT 섹션으로 분류했습니다. 기사 섹션 분류 안내 기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다. 닫기 기자 프로필 이도원 기자 이도원 기자 지디넷코리아 구독 구독중 엔씨소프트 \\'아이온2\\', 서버 및 캐릭터명 선점 이벤트 실시 [이기자의 게임픽] 4분기 신작 게임 쏟아진다...흥행 기대작은 구독 지디넷코리아 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 구독중 지디넷코리아 구독하고 메인에서 바로 만나보세요!구독하고 메인에서 만나보세요! 언론사홈 지디넷코리아 주요뉴스해당 언론사에서 선정하며 언론사(아웃링크)로 이동합니다. AI페스타, 공공·금융·제조 전방위 AI 혁신 제품 한자리에 AI페스타 2025 \\'AI 챔피언관\\'…AI 혁신 현장을 한눈에 [영상] \"대한민국 AI 혁신, 한눈에\"…AI페스타 2025 현장 한국문화정보원, AI페스타 기간 \\'AI와 문화의 만남\\' 알려 지디넷코리아 \\'홈페이지\\' QR 코드를 클릭하면 크게 볼 수 있어요. QR을 촬영해보세요. 지디넷코리아 \\'홈페이지\\' 닫기 네이버 채널 구독하기 지디넷코리아 언론사가 직접 선정한 이슈 이슈 트럼프 2.0시대 트럼프 행정부 AI 책임자, 앤트로픽 저격…\"공포로 좌파식 규제 유도\" 이슈 AI 핫트렌드 얀 르쿤 \"제 꾀에 넘어갔다\"…오픈AI,\\n \\n---\\n URL: https://n.news.naver.com/mnews/article/023/0003935615?sid=105\\nContent: 아니라, 예전 수학자가 풀어놨던 풀이법을 검색해 찾아낸 것이었습니다.이후 오픈AI 연구자들은 X에 올린 관련 글들을 지웠습니다. 단순 해프닝이지만, 테크 업계 내부에선 비판의 목소리가 나옵니다. 오픈AI 경쟁사인 구글 딥마인드의 데미스 허사비스 최고경영자(CEO)는 자신의 X에 해당 글을 링크하며 “당황스럽다”고 했고, 메타의 AI 수석과학자인 얀 르쾽은 “GPT가 판 함정에 스스로 걸려 넘어졌다”고 했습니다. 오픈AI가 자사 AI 성능을 강조하려다가 잘못된 과장 홍보를 했다는 겁니다.테크 업계에선 이를 최근 다양한 수익화에 나선 오픈AI의 행보와 연결 지어 봅니다. 테크 업계 관계자는 “최근 오픈AI는 챗봇 서비스, SNS, 웹브라우저 등 다양한 수익화를 추진하고 있다. 챗GPT 사용자 증가세가 정체된 상황에서 더 강력한 AI를 홍보할 필요가 있었을 것”이라고 말했습니다. 테크 업계에선 수십억 달러의 투자금이 오가는 뜨거운 AI 업계에서 기술 발전 소식을 전할 때는 철저한 검증이 필요하다는 목소리가 나옵니다.이번 사건을 단순 해프닝으로 취급하지 말아야 한다는 주장도 있습니다. GPT-5가 스스로 수학적 증명을 한 것은 아니지만, 잘 알려지지 않은 풀이법을 찾아낸 것에 주목해야 한다는 것입니다. 세바스티앵 부벡 오픈AI 연구원은 “이번 사건은 GPT-5가 ‘문헌 검색 도구’로서의 유용성을 입증한 사례”라고 했습니다. 김성민 기자 dori2381@chosun.com Copyright ⓒ 조선일보. All rights reserved. 무단 전재 및 재배포 금지. 이 기사는 언론사에서 IT 섹션으로 분류했습니다. 기사 섹션 분류 안내 기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다. 닫기 기자 프로필 김성민 기자 김성민 기자 조선일보 구독 구독중 삼성전자, 전직원에게 성과 연동 주식 준다...우수 인재 채용 목적 삼성전자 반도체 자존심 회복했다...수퍼사이클 올라타며 3분기 영업이익\\n \\n---\\n URL: https://n.news.naver.com/mnews/article/421/0008544124?sid=105\\nContent: XR 기기 \\'글라스\\'를 언급하며 \"AI가 사람의 목소리, 제스처, 시각을 직관적으로 이해하는 시대가 됐다\"며 \"AI 기반 인터페이스가 가능해지면서 구글 글라스 역시 완전히 새롭게 돌아올 것\"이라고 말했다. 마크 베니오프 세일즈포스 CEO. ⓒ AFP=뉴스1이날 구글은 제미나이 모델을 세일즈포스의 차세대 AI 플랫폼 \\'에이전트포스 360\\'에 탑재한다고 발표했다. 제미나이는 플랫폼 핵심 엔진인 \\'세일즈포스 아틀라스 추론 엔진\\'에서 멀티모달과 하이브리드 추론 기능을 제공한다.양사는 구글 워크스페이스(지메일·구글미트 등) 앱도 에이전트포스에 통합한다. 이용자는 제미나이 기반으로 △이메일 작성 △일정 예약 △고객관리(CRM) 데이터 분석 등을 처리할 수 있다. 슬랙의 실시간 검색 API에도 제미나이 엔터프라이즈 버전이 연동된다.피차이 CEO는 \"AI 에이전트를 안전하고 통제 가능한 방식으로 기업 환경에 통합하는 것이 핵심\"이라며 \"이번 세일즈포스와 협력으로 모든 기업이 실질적인 도움을 받게 될 것\"이라고 했다.<용어설명>■ 양자내성암호양자컴퓨팅 환경에서 안전하게 암호 기술을 이용할 수 있도록 하는 새로운 공개키 암호. 압도적인 연산 능력을 앞세운 양자컴퓨팅의 공격 시도라도 방어할 수 있는 알고리즘을 의미한다.■ XRXR(eXtended Reality·확장현실)은 가상현실(VR·Virtual Reality)·증강현실(AR·Augmented Reality)·혼합현실(MR·Mixed Reality) 등 현실과 가상을 융합한 모든 기술을 포괄하는 상위 개념이다. 현실 세계와 가상 세계를 다양한 방식으로 결합해 새로운 경험을 제공하는 기술군 전체를 의미한다.■ 초지능초지능(Super Intelligence)은 인간의 지능을 모든 분야에서 뛰어넘는 인공지능 시스템을 말한다. AGI 등장 시 스스로 초지능 단계로 진입할 것으로 전망한다. 과학·예술·의학·공학·사회·감정 등 모든 영역에서 인간보다 월등한 문제 해결 능력과 창의성·추론 능력을 갖출 것으로 보인다. 김민석 기자\\n',\n",
              " 'question': '인공지능의 최근 발전 방식은? 관련 링크도 보여주세요',\n",
              " 'answer': \"인공지능의 최근 발전 방식은 다음과 같습니다.\\n\\n- AI가 사람의 목소리, 제스처, 시각을 직관적으로 이해하는 AI 기반 인터페이스 기술이 발전하고 있습니다. 예를 들어, XR(확장현실) 기기인 '글라스'가 AI와 결합하여 완전히 새롭게 진화하고 있습니다.\\n- 구글은 제미나이(Gemini) 모델을 세일즈포스의 차세대 AI 플랫폼 '에이전트포스 360'에 탑재하여 멀티모달(다중 형태 데이터 처리)과 하이브리드 추론 기능을 제공하고 있습니다.\\n- 이를 통해 이메일 작성, 일정 예약, 고객관리(CRM) 데이터 분석 등 다양한 업무를 AI 에이전트가 지원하며, 슬랙 실시간 검색 API에도 연동하여 기업 환경에 AI를 안전하고 통제 가능하게 통합하는 데 중점을 두고 있습니다.\\n- 또한, AI 기술은 공공 영역, 국방, 금융, 제조업 등 다양한 분야로 확산되고 있으며 정부 차원의 준비도 활발히 이루어지고 있습니다.\\n\\n관련 내용은 다음 링크에서 확인할 수 있습니다.  \\nhttps://n.news.naver.com/mnews/article/421/0008544124?sid=105\\n\\n---\\n요약하면, 최근 AI 발전은 멀티모달 AI, AI 기반 인터페이스, 기업용 AI 플랫폼 통합, 그리고 공공·금융·제조 등 다양한 분야로의 확장에 집중되고 있습니다.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# assign : 결과를 받아서 새로운 인수 추가하고 원래 결과와 함께 전달\n",
        "\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "rag_chain_from_docs = (\n",
        "    prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain_with_source = RunnableParallel(\n",
        "    context = retriever | format_docs, question = RunnablePassthrough()).assign(answer=rag_chain_from_docs)\n",
        "\n",
        "rag_chain_with_source.invoke(\"인공지능의 최근 발전 방식은? 관련 링크도 보여주세요\")\n",
        "\n",
        "# retriever가 1번 실행됨\n",
        "# retriever의 실행 결과를 rag_chain_from_docs 에 넘겨주기 때문에\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgvIMLewKxFx"
      },
      "source": [
        "이번에는 오픈 모델을 사용합니다.   \n",
        "오픈 임베딩을 통해 구성한 DB와 원래 DB를 비교해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFt-e-9KKliX"
      },
      "outputs": [],
      "source": [
        "open_db = Chroma(embedding_function=open_embeddings,\n",
        "                           persist_directory=\"./chroma_open\", # 별도 폴더에 저장\n",
        "                           collection_name='Web', # 식별 이름\n",
        "                           collection_metadata={'hnsw:space':'l2'}\n",
        "                           )\n",
        "\n",
        "# 100개씩 추가\n",
        "for i in tqdm(range(0, len(chunks), 100)):\n",
        "    open_db.add_documents(chunks[i:min(i+100, len(chunks))])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이후는 동일합니다."
      ],
      "metadata": {
        "id": "R5nuBr-L1W1k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8927hrWqKr9L"
      },
      "outputs": [],
      "source": [
        "open_retriever = open_db.as_retriever(search_kwargs={'k':5})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6JyqTPOMhqZ"
      },
      "outputs": [],
      "source": [
        "open_retriever.invoke(\"도메인 특화 언어 모델\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clC38Qe7M5HE"
      },
      "outputs": [],
      "source": [
        "rag_chain_open = (\n",
        "    {\"context\": open_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예시 질문을 통해 정답과 검색 결과를 비교해 보겠습니다."
      ],
      "metadata": {
        "id": "OmW3beDZ1mxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksbVmdF9RFqJ"
      },
      "outputs": [],
      "source": [
        "questions = [\"도메인 특화 언어 모델이란 무엇입니까? 어떤 예시가 있나요?\",\n",
        "             \"인공지능의 최근 발전 방식은? 관련 링크도 보여주세요\",\n",
        "             \"알리바바의 언어 모델 이름은?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXBTmPqERFqK"
      },
      "outputs": [],
      "source": [
        "# Retriever 비교\n",
        "\n",
        "contexts_hf = open_retriever.batch(questions)\n",
        "contexts_openai = retriever.batch(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3M4SNrJRFqK"
      },
      "outputs": [],
      "source": [
        "for i in range(len(questions)):\n",
        "    print(f\"-- Question:{questions[i]}\")\n",
        "    oai_chunks = '\\n'.join([x.page_content[:30] for x in contexts_openai[i]])\n",
        "    hf_chunks = '\\n'.join([x.page_content[:30] for x in contexts_hf[i]])\n",
        "    print(f\"OpenAI: \\n{oai_chunks}\")\n",
        "    print(f\"Hf: \\n{hf_chunks}\")\n",
        "    print('----------')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxkSE3MnNBty"
      },
      "outputs": [],
      "source": [
        "# 최종 결과 비교\n",
        "oai_results = rag_chain.batch(questions)\n",
        "hf_results = rag_chain_open.batch(questions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(questions)):\n",
        "    print(f\"-- Question:{questions[i]}\")\n",
        "    print(f\"OpenAI: \\n{oai_results[i]}\")\n",
        "    print('--')\n",
        "    print(f\"Hf: \\n{hf_results[i]}\")\n",
        "    print('----------')\n"
      ],
      "metadata": {
        "id": "rJ3Oivky3FB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St3ziLyp4yfs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e065ad4a6bd248d99d0a4878fe4f9a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cc0610b5a6549438dbef03ebdce7254",
              "IPY_MODEL_69d00a869e954730840839260380f6fb",
              "IPY_MODEL_1d32165f92ea40eaa92031c6e3f80a06"
            ],
            "layout": "IPY_MODEL_9b652c5df1344009a967185187e67334"
          }
        },
        "3cc0610b5a6549438dbef03ebdce7254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed05235aaafe4706bd26c96dfb107876",
            "placeholder": "​",
            "style": "IPY_MODEL_3a1336dc671c4619abc5c553eaf5cd06",
            "value": "modules.json: 100%"
          }
        },
        "69d00a869e954730840839260380f6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6267c0291b44d88910badf61760ca7",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5852f9b4bc3048b9ac760924f105f7e9",
            "value": 349
          }
        },
        "1d32165f92ea40eaa92031c6e3f80a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38c7487f7c3948b59eb13a934f6eb09a",
            "placeholder": "​",
            "style": "IPY_MODEL_c2b6434ccc9a46cf8243e78022d4513e",
            "value": " 349/349 [00:00&lt;00:00, 39.1kB/s]"
          }
        },
        "9b652c5df1344009a967185187e67334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed05235aaafe4706bd26c96dfb107876": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1336dc671c4619abc5c553eaf5cd06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc6267c0291b44d88910badf61760ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5852f9b4bc3048b9ac760924f105f7e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38c7487f7c3948b59eb13a934f6eb09a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2b6434ccc9a46cf8243e78022d4513e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f1f3967abd74809be2ec4010ac40855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1594d031d5924109b4045530c5fbdb83",
              "IPY_MODEL_afe93cf083e0411a880fe54e7d319b91",
              "IPY_MODEL_a22a688b576a4d4db73aa3808705dca4"
            ],
            "layout": "IPY_MODEL_0140b187ca1045dcaab1ace86585985c"
          }
        },
        "1594d031d5924109b4045530c5fbdb83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00225e7899714ab4abad64e53beb06fa",
            "placeholder": "​",
            "style": "IPY_MODEL_2d25cae750cd43d88671942b55f4414f",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "afe93cf083e0411a880fe54e7d319b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99eb50177769461caaabd6baf43cb471",
            "max": 215,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68ae55891e794fcbbcb3aaf75ca312e0",
            "value": 215
          }
        },
        "a22a688b576a4d4db73aa3808705dca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3006ff9e3bc24beab77f7502abb9cdf5",
            "placeholder": "​",
            "style": "IPY_MODEL_cbfb8f3ab37e42a6b85d564301009283",
            "value": " 215/215 [00:00&lt;00:00, 25.2kB/s]"
          }
        },
        "0140b187ca1045dcaab1ace86585985c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00225e7899714ab4abad64e53beb06fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d25cae750cd43d88671942b55f4414f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99eb50177769461caaabd6baf43cb471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ae55891e794fcbbcb3aaf75ca312e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3006ff9e3bc24beab77f7502abb9cdf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfb8f3ab37e42a6b85d564301009283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "287707c9fb984499b9a1a6dc06509fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_253bc15954a24856ad1b8972d12e2b07",
              "IPY_MODEL_1d9d467a089846d8bb62c2f5b8ff3c8f",
              "IPY_MODEL_fd1814707df24081baec1fccaf9037cb"
            ],
            "layout": "IPY_MODEL_27666c8556854567b4b56feee24b274a"
          }
        },
        "253bc15954a24856ad1b8972d12e2b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_511ecabf6b824194aff9af31e568a14c",
            "placeholder": "​",
            "style": "IPY_MODEL_70d06964a9514413a2f57ae8788eebea",
            "value": "README.md: "
          }
        },
        "1d9d467a089846d8bb62c2f5b8ff3c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49d5a6e6394f4f888a3aca50e1a69063",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31cf5a8232a6423290ca445aa31d08a6",
            "value": 1
          }
        },
        "fd1814707df24081baec1fccaf9037cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2730ccb73ef74ac1853be2ea991de912",
            "placeholder": "​",
            "style": "IPY_MODEL_368155f8052c45cdafa729cd45f0cf37",
            "value": " 17.2k/? [00:00&lt;00:00, 1.33MB/s]"
          }
        },
        "27666c8556854567b4b56feee24b274a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511ecabf6b824194aff9af31e568a14c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d06964a9514413a2f57ae8788eebea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49d5a6e6394f4f888a3aca50e1a69063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "31cf5a8232a6423290ca445aa31d08a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2730ccb73ef74ac1853be2ea991de912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368155f8052c45cdafa729cd45f0cf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5717ae2f4f8047f78d8baac61d2e1403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d98809ab474c908dcc17a2f4e3d4ff",
              "IPY_MODEL_678c17cb4141413d9036c864dd3979ca",
              "IPY_MODEL_d7ec8242e4364abd91fdc3232424fa74"
            ],
            "layout": "IPY_MODEL_1278ca3c8b074c25b337eae010b0493d"
          }
        },
        "b5d98809ab474c908dcc17a2f4e3d4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d4290702c014b7ba4bec6aa18a40e2c",
            "placeholder": "​",
            "style": "IPY_MODEL_d3ea1c0fc964409dab573b8af99cfe09",
            "value": "config.json: 100%"
          }
        },
        "678c17cb4141413d9036c864dd3979ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616c786e0d444ef2974221d21dbffde8",
            "max": 727,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db9a38195280404e923825b56488a28f",
            "value": 727
          }
        },
        "d7ec8242e4364abd91fdc3232424fa74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a6aab1e62a149ddad8dade9ccc72dff",
            "placeholder": "​",
            "style": "IPY_MODEL_c4c8371b11f14c3596c1b7068ccaf33d",
            "value": " 727/727 [00:00&lt;00:00, 77.5kB/s]"
          }
        },
        "1278ca3c8b074c25b337eae010b0493d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d4290702c014b7ba4bec6aa18a40e2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ea1c0fc964409dab573b8af99cfe09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "616c786e0d444ef2974221d21dbffde8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9a38195280404e923825b56488a28f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a6aab1e62a149ddad8dade9ccc72dff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c8371b11f14c3596c1b7068ccaf33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55eef424495543b2948d0c37ea480375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_544f6f657a3640a3982b4a6b13ac849b",
              "IPY_MODEL_2987e783ab5648e2aced99de301528a3",
              "IPY_MODEL_21647f7f0e6543c1b73b3a3cdae69503"
            ],
            "layout": "IPY_MODEL_1214fa89f16c49d39b30fc042280bf92"
          }
        },
        "544f6f657a3640a3982b4a6b13ac849b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4cf366718e14ab5852af8e9701028f3",
            "placeholder": "​",
            "style": "IPY_MODEL_c83f8ba3cca14bb6b6fa2ee97d25da21",
            "value": "model.safetensors:   0%"
          }
        },
        "2987e783ab5648e2aced99de301528a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f07913972de4a6b914c73fba3641320",
            "max": 1191586416,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec69e7cd5a3c45919a3f5d3f71029221",
            "value": 0
          }
        },
        "21647f7f0e6543c1b73b3a3cdae69503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42cc533fd89245069db0b13d070c2dc9",
            "placeholder": "​",
            "style": "IPY_MODEL_fe60bef8d8bd46e8abc8300e908eb4aa",
            "value": " 0.00/1.19G [00:57&lt;?, ?B/s]"
          }
        },
        "1214fa89f16c49d39b30fc042280bf92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4cf366718e14ab5852af8e9701028f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83f8ba3cca14bb6b6fa2ee97d25da21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f07913972de4a6b914c73fba3641320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec69e7cd5a3c45919a3f5d3f71029221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "42cc533fd89245069db0b13d070c2dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe60bef8d8bd46e8abc8300e908eb4aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}